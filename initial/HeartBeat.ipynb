{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/alirezash97/Cardio/blob/master/HeartBeat.ipynb",
      "authorship_tag": "ABX9TyO/OLdyk44PoQk6I5SADOoT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Cardio/blob/master/HeartBeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUFDobFVvj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"alirezashafaei97\",\"key\":\"9cb262aa0c5658ffc4eb45857c41903c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat -p /content\n",
        "!unzip /content/heartbeat.zip -d /content/heartbeat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sio7SWAwWBLj",
        "colab_type": "code",
        "outputId": "5e70d484-5ea4-484f-8cab-11d7fa9be8ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, LeakyReLU, Softmax, InputLayer, concatenate, Conv1D, MaxPool1D, Add, MaxPooling1D\n",
        " , Flatten, Dropout, ReLU, BatchNormalization, GlobalAveragePooling1D)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from random import uniform \n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTudiQO8WEXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/heartbeat/mitbih_test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2SBJpgbi9WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_df = train_df[:186].astype('float16')\n",
        "# test_df = test_df[:186].astype('float16')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58wFx5vXQS7",
        "colab_type": "code",
        "outputId": "142bbe10-a1bf-4fde-96a2-85fa8d58209c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "counter=train_df[187].value_counts()\n",
        "print(counter)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQqNZG2q59y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=10000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=10000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=10000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=10000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=10000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomIXpkCrozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBctv4Tr58D",
        "colab_type": "code",
        "outputId": "31e5a711-6003-4415-bec1-d2ddf10c0969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    10000\n",
            "3    10000\n",
            "2    10000\n",
            "1    10000\n",
            "0    10000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3HJfHYr605",
        "colab_type": "code",
        "outputId": "9a34ad27-aafb-47d6-ff53-f8ccf06d5806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\n",
        "c"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14127</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.870558</td>\n",
              "      <td>0.253807</td>\n",
              "      <td>0.134518</td>\n",
              "      <td>0.187817</td>\n",
              "      <td>0.185279</td>\n",
              "      <td>0.190355</td>\n",
              "      <td>0.175127</td>\n",
              "      <td>0.197970</td>\n",
              "      <td>0.177665</td>\n",
              "      <td>0.192893</td>\n",
              "      <td>0.187817</td>\n",
              "      <td>0.208122</td>\n",
              "      <td>0.187817</td>\n",
              "      <td>0.213198</td>\n",
              "      <td>0.215736</td>\n",
              "      <td>0.228426</td>\n",
              "      <td>0.220812</td>\n",
              "      <td>0.251269</td>\n",
              "      <td>0.241117</td>\n",
              "      <td>0.263959</td>\n",
              "      <td>0.269036</td>\n",
              "      <td>0.281726</td>\n",
              "      <td>0.269036</td>\n",
              "      <td>0.307107</td>\n",
              "      <td>0.289340</td>\n",
              "      <td>0.312183</td>\n",
              "      <td>0.302030</td>\n",
              "      <td>0.322335</td>\n",
              "      <td>0.299492</td>\n",
              "      <td>0.294416</td>\n",
              "      <td>0.251269</td>\n",
              "      <td>0.225888</td>\n",
              "      <td>0.200508</td>\n",
              "      <td>0.190355</td>\n",
              "      <td>0.142132</td>\n",
              "      <td>0.152284</td>\n",
              "      <td>0.134518</td>\n",
              "      <td>0.124365</td>\n",
              "      <td>0.124365</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73435</th>\n",
              "      <td>0.915612</td>\n",
              "      <td>0.805907</td>\n",
              "      <td>0.168776</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084388</td>\n",
              "      <td>0.109705</td>\n",
              "      <td>0.092827</td>\n",
              "      <td>0.198312</td>\n",
              "      <td>0.215190</td>\n",
              "      <td>0.177215</td>\n",
              "      <td>0.177215</td>\n",
              "      <td>0.219409</td>\n",
              "      <td>0.274262</td>\n",
              "      <td>0.324895</td>\n",
              "      <td>0.350211</td>\n",
              "      <td>0.329114</td>\n",
              "      <td>0.316456</td>\n",
              "      <td>0.345992</td>\n",
              "      <td>0.358650</td>\n",
              "      <td>0.329114</td>\n",
              "      <td>0.350211</td>\n",
              "      <td>0.379747</td>\n",
              "      <td>0.375527</td>\n",
              "      <td>0.354430</td>\n",
              "      <td>0.362869</td>\n",
              "      <td>0.392405</td>\n",
              "      <td>0.396624</td>\n",
              "      <td>0.434599</td>\n",
              "      <td>0.455696</td>\n",
              "      <td>0.476793</td>\n",
              "      <td>0.514768</td>\n",
              "      <td>0.548523</td>\n",
              "      <td>0.573840</td>\n",
              "      <td>0.611814</td>\n",
              "      <td>0.624473</td>\n",
              "      <td>0.624473</td>\n",
              "      <td>0.599156</td>\n",
              "      <td>0.594937</td>\n",
              "      <td>0.561181</td>\n",
              "      <td>0.531646</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78419</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.929553</td>\n",
              "      <td>0.792096</td>\n",
              "      <td>0.570447</td>\n",
              "      <td>0.365979</td>\n",
              "      <td>0.274914</td>\n",
              "      <td>0.240550</td>\n",
              "      <td>0.218213</td>\n",
              "      <td>0.194158</td>\n",
              "      <td>0.170103</td>\n",
              "      <td>0.156357</td>\n",
              "      <td>0.152921</td>\n",
              "      <td>0.158076</td>\n",
              "      <td>0.147766</td>\n",
              "      <td>0.130584</td>\n",
              "      <td>0.115120</td>\n",
              "      <td>0.113402</td>\n",
              "      <td>0.104811</td>\n",
              "      <td>0.091065</td>\n",
              "      <td>0.079038</td>\n",
              "      <td>0.067010</td>\n",
              "      <td>0.051546</td>\n",
              "      <td>0.029210</td>\n",
              "      <td>0.022337</td>\n",
              "      <td>0.015464</td>\n",
              "      <td>0.008591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006873</td>\n",
              "      <td>0.022337</td>\n",
              "      <td>0.036082</td>\n",
              "      <td>0.046392</td>\n",
              "      <td>0.070447</td>\n",
              "      <td>0.101375</td>\n",
              "      <td>0.134021</td>\n",
              "      <td>0.159794</td>\n",
              "      <td>0.189003</td>\n",
              "      <td>0.211340</td>\n",
              "      <td>0.219931</td>\n",
              "      <td>0.226804</td>\n",
              "      <td>0.235395</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80626</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.878095</td>\n",
              "      <td>0.495238</td>\n",
              "      <td>0.253333</td>\n",
              "      <td>0.154286</td>\n",
              "      <td>0.118095</td>\n",
              "      <td>0.093333</td>\n",
              "      <td>0.081905</td>\n",
              "      <td>0.074286</td>\n",
              "      <td>0.072381</td>\n",
              "      <td>0.062857</td>\n",
              "      <td>0.059048</td>\n",
              "      <td>0.045714</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.032381</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.019048</td>\n",
              "      <td>0.015238</td>\n",
              "      <td>0.009524</td>\n",
              "      <td>0.007619</td>\n",
              "      <td>0.003810</td>\n",
              "      <td>0.009524</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015238</td>\n",
              "      <td>0.024762</td>\n",
              "      <td>0.041905</td>\n",
              "      <td>0.062857</td>\n",
              "      <td>0.091429</td>\n",
              "      <td>0.123810</td>\n",
              "      <td>0.150476</td>\n",
              "      <td>0.177143</td>\n",
              "      <td>0.192381</td>\n",
              "      <td>0.192381</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.182857</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.180952</td>\n",
              "      <td>0.184762</td>\n",
              "      <td>0.175238</td>\n",
              "      <td>0.175238</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86643</th>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.443548</td>\n",
              "      <td>0.408602</td>\n",
              "      <td>0.384409</td>\n",
              "      <td>0.362903</td>\n",
              "      <td>0.322581</td>\n",
              "      <td>0.298387</td>\n",
              "      <td>0.244624</td>\n",
              "      <td>0.217742</td>\n",
              "      <td>0.139785</td>\n",
              "      <td>0.061828</td>\n",
              "      <td>0.008065</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002688</td>\n",
              "      <td>0.021505</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.147849</td>\n",
              "      <td>0.220430</td>\n",
              "      <td>0.271505</td>\n",
              "      <td>0.309140</td>\n",
              "      <td>0.314516</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.344086</td>\n",
              "      <td>0.354839</td>\n",
              "      <td>0.349462</td>\n",
              "      <td>0.360215</td>\n",
              "      <td>0.376344</td>\n",
              "      <td>0.392473</td>\n",
              "      <td>0.387097</td>\n",
              "      <td>0.405914</td>\n",
              "      <td>0.408602</td>\n",
              "      <td>0.422043</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.419355</td>\n",
              "      <td>0.422043</td>\n",
              "      <td>0.432796</td>\n",
              "      <td>0.424731</td>\n",
              "      <td>0.440860</td>\n",
              "      <td>0.432796</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3    ...  184  185  186  187\n",
              "14127  1.000000  0.870558  0.253807  0.134518  ...  0.0  0.0  0.0    0\n",
              "73435  0.915612  0.805907  0.168776  0.000000  ...  0.0  0.0  0.0    1\n",
              "78419  1.000000  0.929553  0.792096  0.570447  ...  0.0  0.0  0.0    2\n",
              "80626  1.000000  0.878095  0.495238  0.253333  ...  0.0  0.0  0.0    3\n",
              "86643  0.516129  0.443548  0.408602  0.384409  ...  0.0  0.0  0.0    4\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie12gfa0cRQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB80IzMo1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_gaussian_noise(signal):\n",
        "    noise=np.random.normal(0,0.05,186)\n",
        "    return (signal+noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJB5fWu5sWNc",
        "colab_type": "code",
        "outputId": "0ce95d0e-46c2-4840-f4f8-2b6dd9b82332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tempo=c.iloc[0,:186]\n",
        "bruiter=add_gaussian_noise(tempo)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(c.iloc[0,:186])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(bruiter)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4fXuypr6vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUVlLpKPsQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.astype('float16')\n",
        "test_df = test_df.astype('float16')\n",
        "\n",
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values\n",
        "# X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
        "# X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexzfSPiD34D",
        "colab_type": "code",
        "outputId": "389ab1a9-6086-4fa4-b6cb-9f630d800043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 186)\n",
            "(21892, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPfQkUVfnTx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data augmentation\n",
        "\n",
        "def augmetation(X_train, y_train, chance):\n",
        "\n",
        "  augment_number = 0\n",
        "  XF_train = np.zeros((X_train.shape[0]*2, X_train.shape[1]))\n",
        "  yf_train = np.zeros((y_train.shape[0]*2, y_train.shape[1]))\n",
        "  pointer = 0\n",
        "  for index, row in enumerate(X_train):\n",
        "\n",
        "    XF_train[pointer, :] = row\n",
        "    yf_train[pointer, :] = y_train[index, :]\n",
        "    pointer += 1\n",
        "\n",
        "    rand_num = random.uniform(0, 1)      \n",
        "    if chance > rand_num :\n",
        "\n",
        "      augment_number += 1\n",
        "      noise = np.random.normal(0,0.05,186)\n",
        "      new_signal = row + noise  \n",
        "      XF_train[pointer, :] = new_signal\n",
        "      yf_train[pointer, :] = y_train[index, :]\n",
        "      pointer += 1\n",
        "\n",
        "      filled = X_train.shape[0] + augment_number\n",
        "      XFF_train = XF_train[:filled, :]\n",
        "      yff_train = yf_train[:filled, :]\n",
        "\n",
        "    \n",
        "  return XFF_train, yff_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dXhm8thnj1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = augmetation(X_train, y_train, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzROJp1Fr6q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "import pywt\n",
        "\n",
        "XF_train = np.zeros((X_train.shape[0], 9000))\n",
        "XF_test = np.zeros((X_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_train):\n",
        "  XF_train[index, :] = pywt.pad(row, 4407, 'periodic')\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_test):\n",
        "  XF_test[index, :] = pywt.pad(row, 4407, 'periodic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmANeCYtjmgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XF_train = XF_train.reshape((XF_train.shape[0], 9000, 1))\n",
        "XF_test = XF_test.reshape((XF_test.shape[0], 9000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNvkTDCjyoA",
        "colab_type": "code",
        "outputId": "eeec7109-224c-4337-ae8e-c119d3340e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train : \", XF_train.shape)\n",
        "print(\"Y_train : \", y_train.shape)\n",
        "print(\"X_test : \", XF_test.shape)\n",
        "print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train :  (55033, 9000, 1)\n",
            "Y_train :  (55033, 5)\n",
            "X_test :  (21892, 9000, 1)\n",
            "Y_test :  (21892, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvIW2sWkaoP",
        "colab_type": "code",
        "outputId": "c0250120-8f5f-4084-d120-a446e8ef0b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_input = Input(shape=(9000, 1))\n",
        "Conv = Conv1D(filters=64, kernel_size=5, strides=3)(X_input)\n",
        "\n",
        "\n",
        "### step 1 \n",
        "\n",
        "Conv1_1 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(Conv)\n",
        "Bn1_1 = BatchNormalization()(Conv1_1)\n",
        "Act1_1 = LeakyReLU()(Bn1_1)\n",
        "Conv1_2 = Conv1D(filters=64, kernel_size=7, strides=1, padding='same')(Act1_1)\n",
        "Bn1_2 = BatchNormalization()(Conv1_2)\n",
        "Act1_2 = LeakyReLU()(Bn1_2)\n",
        "DO1_1 = Dropout(0.2)(Act1_2)\n",
        "Conv1_3 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(DO1_1)\n",
        "Bn1_3 = BatchNormalization()(Conv1_3)\n",
        "shortcut1_1 = Add()([Bn1_3, Conv])\n",
        "Bn1_4 = BatchNormalization()(shortcut1_1)\n",
        "Act1_3 = LeakyReLU()(Bn1_4)\n",
        "##### auxiliary\n",
        "Conv1_4 = Conv1D(filters=128, kernel_size=7, strides=3, padding='same')(Act1_3)\n",
        "Bn1_5 = BatchNormalization()(Conv1_4)\n",
        "Act1_4 = LeakyReLU()(Bn1_5)\n",
        "###############\n",
        "Max1_1 = MaxPooling1D(pool_size=5, strides=2)(Act1_4)\n",
        "\n",
        "\n",
        "## step 2\n",
        "\n",
        "Conv2_1 = Conv1D(filters=256, kernel_size=3, strides=1, padding='same')(Max1_1)\n",
        "Bn2_1 = BatchNormalization()(Conv2_1)\n",
        "Act2_1 = LeakyReLU()(Bn2_1)\n",
        "Conv2_2 = Conv1D(filters=256, kernel_size=5, strides=1, padding='same')(Act2_1)\n",
        "Bn2_2 = BatchNormalization()(Conv2_2)\n",
        "Act2_2 = LeakyReLU()(Bn2_2)\n",
        "DO2_1 = Dropout(0.2)(Act2_2)\n",
        "Conv2_3 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same')(DO2_1)\n",
        "Bn2_3 = BatchNormalization()(Conv2_3)\n",
        "shortcut2_1 = Add()([Bn2_3, Max1_1])\n",
        "Bn2_4 = BatchNormalization()(shortcut2_1)\n",
        "Act2_3 = LeakyReLU()(Bn2_4)\n",
        "##### auxiliary\n",
        "Conv2_4 = Conv1D(filters=512, kernel_size=7, strides=2, padding='same')(Act2_3)\n",
        "Bn2_5 = BatchNormalization()(Conv2_4)\n",
        "Act2_4 = LeakyReLU()(Bn2_5)\n",
        "###############\n",
        "Max2_1 = MaxPooling1D(pool_size=5, strides=3)(Act2_4)\n",
        "\n",
        "\n",
        "\n",
        "Flat1 = Flatten()(Max2_1)\n",
        "\n",
        "D1 = Dense(256)(Flat1)\n",
        "A6 = LeakyReLU()(D1)\n",
        "D_O = Dropout(0.15)(A6)\n",
        "D2 = Dense(128)(D_O)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=A7)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 2999, 64)     384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 2999, 64)     36928       conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2999, 64)     256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 2999, 64)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 2999, 64)     28736       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 2999, 64)     256         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2999, 64)     0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 2999, 64)     36928       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2999, 64)     256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 2999, 64)     0           batch_normalization_2[0][0]      \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 2999, 64)     256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1000, 128)    57472       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1000, 128)    512         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 1000, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 498, 128)     0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 498, 256)     98560       max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 498, 256)     1024        conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 498, 256)     327936      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 498, 256)     1024        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 498, 256)     0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 498, 128)     98432       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 498, 128)     512         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 498, 128)     0           batch_normalization_7[0][0]      \n",
            "                                                                 max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 498, 128)     512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 498, 128)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 249, 512)     459264      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 249, 512)     2048        conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 249, 512)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 82, 512)      0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 41984)        0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          10748160    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5)            645         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 5)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,932,997\n",
            "Trainable params: 11,929,669\n",
            "Non-trainable params: 3,328\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSfZxMLK7xI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=1719,\n",
        "    decay_rate=0.7)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51SxpfQofzM",
        "colab_type": "code",
        "outputId": "c68dde1e-58cc-46a4-bbfb-079b76c62712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# overfitting so augment more data and decrease initial learning rate to 1e-3\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(XF_train, y_train, epochs=6, batch_size=64, validation_data=(XF_test, y_test), callbacks=[es_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "860/860 [==============================] - 7071s 8s/step - loss: 4.2049 - accuracy: 0.6377 - val_loss: 0.9458 - val_accuracy: 0.8428\n",
            "Epoch 2/6\n",
            "860/860 [==============================] - 7109s 8s/step - loss: 0.3608 - accuracy: 0.8763 - val_loss: 0.4492 - val_accuracy: 0.8518\n",
            "Epoch 3/6\n",
            "860/860 [==============================] - 7178s 8s/step - loss: 0.2508 - accuracy: 0.9151 - val_loss: 0.3316 - val_accuracy: 0.8908\n",
            "Epoch 4/6\n",
            "860/860 [==============================] - 7210s 8s/step - loss: 0.1854 - accuracy: 0.9357 - val_loss: 0.3050 - val_accuracy: 0.9056\n",
            "Epoch 5/6\n",
            "860/860 [==============================] - 7172s 8s/step - loss: 0.1939 - accuracy: 0.9393 - val_loss: 0.3331 - val_accuracy: 0.9111\n",
            "Epoch 6/6\n",
            "113/860 [==>...........................] - ETA: 1:34:13 - loss: 0.1415 - accuracy: 0.9519"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUPC94zqTiE",
        "colab_type": "code",
        "outputId": "15e76721-375a-4993-e207-30055522d4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(XF_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"/content/drive/My Drive/Cardio/HeartBeat.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-78fb4bd29953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXF_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# save model and architecture to single file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCecYVrhtbNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht3ltnGvtjlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
