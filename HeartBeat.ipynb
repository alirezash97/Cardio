{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/alirezash97/Cardio/blob/master/HeartBeat.ipynb",
      "authorship_tag": "ABX9TyO9d3CKR+1UiHXcwurlpVZ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Cardio/blob/master/HeartBeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUFDobFVvj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"alirezashafaei97\",\"key\":\"9cb262aa0c5658ffc4eb45857c41903c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat -p /content\n",
        "!unzip /content/heartbeat.zip -d /content/heartbeat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sio7SWAwWBLj",
        "colab_type": "code",
        "outputId": "cc76b2da-3697-4800-dbd3-ddfd6fcd9c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, LeakyReLU, Softmax, InputLayer, concatenate, Conv1D, MaxPool1D, Add, MaxPooling1D\n",
        " , Flatten, Dropout, ReLU, BatchNormalization, GlobalAveragePooling1D)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from random import uniform \n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTudiQO8WEXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/heartbeat/mitbih_test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfWxem7CTc50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del train_df\n",
        "# del test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58wFx5vXQS7",
        "colab_type": "code",
        "outputId": "a62596ba-3811-41fd-c778-e6226de07dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "counter=train_df[187].value_counts()\n",
        "print(counter)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQqNZG2q59y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=10000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=10000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=10000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=10000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=10000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomIXpkCrozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBctv4Tr58D",
        "colab_type": "code",
        "outputId": "ab63ae94-f0e6-4617-e1aa-c6497de5bb45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    10000\n",
            "3    10000\n",
            "2    10000\n",
            "1    10000\n",
            "0    10000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3HJfHYr605",
        "colab_type": "code",
        "outputId": "6468a983-a168-4239-bccb-f6f7397ffc4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\n",
        "c"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64753</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.758197</td>\n",
              "      <td>0.323770</td>\n",
              "      <td>0.032787</td>\n",
              "      <td>0.106557</td>\n",
              "      <td>0.184426</td>\n",
              "      <td>0.196721</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.266393</td>\n",
              "      <td>0.241803</td>\n",
              "      <td>0.233607</td>\n",
              "      <td>0.241803</td>\n",
              "      <td>0.254098</td>\n",
              "      <td>0.225410</td>\n",
              "      <td>0.225410</td>\n",
              "      <td>0.229508</td>\n",
              "      <td>0.237705</td>\n",
              "      <td>0.229508</td>\n",
              "      <td>0.221311</td>\n",
              "      <td>0.217213</td>\n",
              "      <td>0.221311</td>\n",
              "      <td>0.209016</td>\n",
              "      <td>0.192623</td>\n",
              "      <td>0.188525</td>\n",
              "      <td>0.180328</td>\n",
              "      <td>0.176230</td>\n",
              "      <td>0.180328</td>\n",
              "      <td>0.188525</td>\n",
              "      <td>0.192623</td>\n",
              "      <td>0.188525</td>\n",
              "      <td>0.196721</td>\n",
              "      <td>0.213115</td>\n",
              "      <td>0.237705</td>\n",
              "      <td>0.245902</td>\n",
              "      <td>0.282787</td>\n",
              "      <td>0.323770</td>\n",
              "      <td>0.356557</td>\n",
              "      <td>0.397541</td>\n",
              "      <td>0.426230</td>\n",
              "      <td>0.459016</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72909</th>\n",
              "      <td>0.944223</td>\n",
              "      <td>0.812749</td>\n",
              "      <td>0.191235</td>\n",
              "      <td>0.055777</td>\n",
              "      <td>0.151394</td>\n",
              "      <td>0.159363</td>\n",
              "      <td>0.143426</td>\n",
              "      <td>0.223108</td>\n",
              "      <td>0.250996</td>\n",
              "      <td>0.195219</td>\n",
              "      <td>0.195219</td>\n",
              "      <td>0.243028</td>\n",
              "      <td>0.314741</td>\n",
              "      <td>0.334661</td>\n",
              "      <td>0.334661</td>\n",
              "      <td>0.334661</td>\n",
              "      <td>0.330677</td>\n",
              "      <td>0.322709</td>\n",
              "      <td>0.318725</td>\n",
              "      <td>0.318725</td>\n",
              "      <td>0.342629</td>\n",
              "      <td>0.322709</td>\n",
              "      <td>0.338645</td>\n",
              "      <td>0.358566</td>\n",
              "      <td>0.358566</td>\n",
              "      <td>0.338645</td>\n",
              "      <td>0.366534</td>\n",
              "      <td>0.402390</td>\n",
              "      <td>0.426295</td>\n",
              "      <td>0.430279</td>\n",
              "      <td>0.458167</td>\n",
              "      <td>0.486056</td>\n",
              "      <td>0.498008</td>\n",
              "      <td>0.509960</td>\n",
              "      <td>0.533865</td>\n",
              "      <td>0.553785</td>\n",
              "      <td>0.541833</td>\n",
              "      <td>0.549801</td>\n",
              "      <td>0.525896</td>\n",
              "      <td>0.490040</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76987</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044828</td>\n",
              "      <td>0.162069</td>\n",
              "      <td>0.265517</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.422414</td>\n",
              "      <td>0.472414</td>\n",
              "      <td>0.513793</td>\n",
              "      <td>0.562069</td>\n",
              "      <td>0.644828</td>\n",
              "      <td>0.718966</td>\n",
              "      <td>0.767241</td>\n",
              "      <td>0.781034</td>\n",
              "      <td>0.803448</td>\n",
              "      <td>0.815517</td>\n",
              "      <td>0.829310</td>\n",
              "      <td>0.844828</td>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.877586</td>\n",
              "      <td>0.896552</td>\n",
              "      <td>0.906897</td>\n",
              "      <td>0.925862</td>\n",
              "      <td>0.929310</td>\n",
              "      <td>0.939655</td>\n",
              "      <td>0.941379</td>\n",
              "      <td>0.943103</td>\n",
              "      <td>0.931035</td>\n",
              "      <td>0.924138</td>\n",
              "      <td>0.905172</td>\n",
              "      <td>0.896552</td>\n",
              "      <td>0.863793</td>\n",
              "      <td>0.844828</td>\n",
              "      <td>0.825862</td>\n",
              "      <td>0.805172</td>\n",
              "      <td>0.777586</td>\n",
              "      <td>0.758621</td>\n",
              "      <td>0.737931</td>\n",
              "      <td>0.725862</td>\n",
              "      <td>0.703448</td>\n",
              "      <td>0.698276</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80775</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.898077</td>\n",
              "      <td>0.571154</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.228846</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0.180769</td>\n",
              "      <td>0.176923</td>\n",
              "      <td>0.163462</td>\n",
              "      <td>0.144231</td>\n",
              "      <td>0.148077</td>\n",
              "      <td>0.136538</td>\n",
              "      <td>0.123077</td>\n",
              "      <td>0.117308</td>\n",
              "      <td>0.111538</td>\n",
              "      <td>0.111538</td>\n",
              "      <td>0.103846</td>\n",
              "      <td>0.086538</td>\n",
              "      <td>0.096154</td>\n",
              "      <td>0.094231</td>\n",
              "      <td>0.080769</td>\n",
              "      <td>0.069231</td>\n",
              "      <td>0.061538</td>\n",
              "      <td>0.057692</td>\n",
              "      <td>0.046154</td>\n",
              "      <td>0.028846</td>\n",
              "      <td>0.026923</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003846</td>\n",
              "      <td>0.013462</td>\n",
              "      <td>0.011538</td>\n",
              "      <td>0.023077</td>\n",
              "      <td>0.034615</td>\n",
              "      <td>0.061538</td>\n",
              "      <td>0.088462</td>\n",
              "      <td>0.107692</td>\n",
              "      <td>0.140385</td>\n",
              "      <td>0.169231</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82520</th>\n",
              "      <td>0.948626</td>\n",
              "      <td>0.878136</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.746714</td>\n",
              "      <td>0.681004</td>\n",
              "      <td>0.596177</td>\n",
              "      <td>0.499403</td>\n",
              "      <td>0.414576</td>\n",
              "      <td>0.328554</td>\n",
              "      <td>0.254480</td>\n",
              "      <td>0.219833</td>\n",
              "      <td>0.192354</td>\n",
              "      <td>0.127838</td>\n",
              "      <td>0.071685</td>\n",
              "      <td>0.038232</td>\n",
              "      <td>0.076464</td>\n",
              "      <td>0.158901</td>\n",
              "      <td>0.223417</td>\n",
              "      <td>0.244922</td>\n",
              "      <td>0.270012</td>\n",
              "      <td>0.271207</td>\n",
              "      <td>0.281959</td>\n",
              "      <td>0.321386</td>\n",
              "      <td>0.345281</td>\n",
              "      <td>0.385902</td>\n",
              "      <td>0.430108</td>\n",
              "      <td>0.467145</td>\n",
              "      <td>0.477897</td>\n",
              "      <td>0.493429</td>\n",
              "      <td>0.498208</td>\n",
              "      <td>0.513740</td>\n",
              "      <td>0.524492</td>\n",
              "      <td>0.543608</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.579450</td>\n",
              "      <td>0.598566</td>\n",
              "      <td>0.627240</td>\n",
              "      <td>0.653525</td>\n",
              "      <td>0.684588</td>\n",
              "      <td>0.709677</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3    ...  184  185  186  187\n",
              "64753  1.000000  0.758197  0.323770  0.032787  ...  0.0  0.0  0.0    0\n",
              "72909  0.944223  0.812749  0.191235  0.055777  ...  0.0  0.0  0.0    1\n",
              "76987  0.000000  0.044828  0.162069  0.265517  ...  0.0  0.0  0.0    2\n",
              "80775  1.000000  0.898077  0.571154  0.323077  ...  0.0  0.0  0.0    3\n",
              "82520  0.948626  0.878136  0.806452  0.746714  ...  0.0  0.0  0.0    4\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB80IzMo1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_gaussian_noise(signal):\n",
        "    noise=np.random.normal(0,0.05,186)\n",
        "    return (signal+noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJB5fWu5sWNc",
        "colab_type": "code",
        "outputId": "1a91f47d-08c3-4f72-8564-d52f6b3fad75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tempo=c.iloc[0,:186]\n",
        "bruiter=add_gaussian_noise(tempo)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(c.iloc[0,:186])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(bruiter)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4fXuypr6vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUVlLpKPsQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values\n",
        "# X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
        "# X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexzfSPiD34D",
        "colab_type": "code",
        "outputId": "9e3a6fb6-7f19-4db6-95ed-cac08d50acc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 186)\n",
            "(21892, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzROJp1Fr6q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "import pywt\n",
        "\n",
        "XF_train = np.zeros((X_train.shape[0], 9000))\n",
        "XF_test = np.zeros((X_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_train):\n",
        "  XF_train[index, :] = pywt.pad(row, 4407, 'periodic')\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_test):\n",
        "  XF_test[index, :] = pywt.pad(row, 4407, 'periodic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0aEgkhXamJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = train_df.values\n",
        "# testset = test_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Yu65s0adg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def split(dataset, number_of_sample_per_category):\n",
        "  \n",
        "#   new_dataset = np.zeros((np.sum(number_of_sample_per_category), dataset.shape[1]))\n",
        "#   pointer = 0\n",
        "  \n",
        "#   for row in dataset :\n",
        "    \n",
        "#     row_label = int(row[-1])\n",
        "    \n",
        "#     if number_of_sample_per_category[row_label] > 0 :\n",
        "      \n",
        "#       number_of_sample_per_category[row_label] -= 1\n",
        "#       new_dataset[pointer , :] = row\n",
        "#       pointer += 1\n",
        "\n",
        "#     else:\n",
        "\n",
        "#       pass\n",
        "    \n",
        "  \n",
        "#   return new_dataset\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTg8U_rCecMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# temp_trainset = split(trainset, [5500, 2223, 5500, 641, 5500])\n",
        "# temp_testset = split(testset, [500, 500, 500, 500, 500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VixGjo-J1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented = 0\n",
        "# def data_augmentation(dataset, chance):\n",
        "  \n",
        "#   augmented = 0\n",
        "#   number_of_rows = int(dataset.shape[0] + (dataset.shape[0] * (chance*2)))\n",
        "#   new_dataset = np.zeros((number_of_rows, dataset.shape[1]))\n",
        "#   pointer = 0 \n",
        "\n",
        "#   for row in dataset:\n",
        "    \n",
        "#     rand_num = random.uniform(0, 1)\n",
        "#     if rand_num < chance:\n",
        "      \n",
        "#       augmented += 1\n",
        "#       noise = np.random.normal(scale=0.01, size=187)\n",
        "#       new_signal = np.zeros((1, 188))\n",
        "#       new_signal[:, :187] = row[:187] + noise\n",
        "#       new_signal[:, -1:] = row[-1:] \n",
        "#       new_dataset[pointer:pointer+1, :] = new_signal\n",
        "#       pointer += 1\n",
        "\n",
        "#     else :\n",
        "#       pass\n",
        "\n",
        "#     new_dataset[pointer, :] = row \n",
        "#     pointer += 1\n",
        "\n",
        "#   return augmented, new_dataset  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-WNJJaSNYR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented, trainset = data_augmentation(temp_trainset, 0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEkQ1k_zRnYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filled = augmented + temp_trainset.shape[0]\n",
        "# trainset = trainset[:filled , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULVB16ONXuex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = np.take(trainset,np.random.permutation(trainset.shape[0]),axis=0,out=trainset)\n",
        "# testset = np.take(temp_testset,np.random.permutation(temp_testset.shape[0]),axis=0,out=temp_testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXpOUPpHYPQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_temp_train = trainset[:, :-1]\n",
        "# Y_train = trainset[:, -1:]\n",
        "# X_temp_test = testset[:, :-1]\n",
        "# Y_test = testset[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wSnYvXY6AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", XF_train.shape)\n",
        "# print(\"Y_train : \", y_train.shape)\n",
        "# print(\"X_test : \", XF_test.shape)\n",
        "# print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQP8dTlBZw6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# One Hot enoding for target labels \n",
        "# ohe = OneHotEncoder()\n",
        "# Y_train = ohe.fit_transform(Y_train.reshape(-1,1))\n",
        "# Y_test = ohe.transform(Y_test.reshape(-1,1))\n",
        "\n",
        "# # handle sparse matrix for keras \n",
        "# Y_train = csr_matrix.toarray(Y_train)\n",
        "# Y_test = csr_matrix.toarray(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBhFohZUarKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", X_temp_train.shape)\n",
        "# print(\"Y_train : \", Y_train.shape)\n",
        "# print(\"X_test : \", X_temp_test.shape)\n",
        "# print(\"Y_test : \", Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E525NqY3aGSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "# import pywt\n",
        "\n",
        "# XF_train = np.zeros((X_temp_train.shape[0], 9000))\n",
        "# XF_test = np.zeros((X_temp_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_train):\n",
        "#   XF_train[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_train[index, -1:] = 0\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   XF_test[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_test[index, -1:] = 0\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCEcchWo3cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index, row in enumerate(X_temp_train):\n",
        "#   X_temp_train[index] = add_gaussian_noise(row)\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   X_temp_test[index] = add_gaussian_noise(row)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmANeCYtjmgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XF_train = XF_train.reshape((50000, 9000, 1))\n",
        "XF_test = XF_test.reshape((21892, 9000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNvkTDCjyoA",
        "colab_type": "code",
        "outputId": "086696bb-228f-4455-9fe0-a2fdc75495a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train : \", XF_train.shape)\n",
        "print(\"Y_train : \", y_train.shape)\n",
        "print(\"X_test : \", XF_test.shape)\n",
        "print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train :  (50000, 9000, 1)\n",
            "Y_train :  (50000, 5)\n",
            "X_test :  (21892, 9000, 1)\n",
            "Y_test :  (21892, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvIW2sWkaoP",
        "colab_type": "code",
        "outputId": "4df981dc-8e74-4561-f2d5-c2743fb86ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_input = Input(shape=(9000, 1))\n",
        "Conv = Conv1D(filters=64, kernel_size=5, strides=3)(X_input)\n",
        "\n",
        "\n",
        "### step 1 \n",
        "\n",
        "Conv1_1 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(Conv)\n",
        "Bn1_1 = BatchNormalization()(Conv1_1)\n",
        "Act1_1 = LeakyReLU()(Bn1_1)\n",
        "Conv1_2 = Conv1D(filters=32, kernel_size=7, strides=1, padding='same')(Act1_1)\n",
        "Bn1_2 = BatchNormalization()(Conv1_2)\n",
        "Act1_2 = LeakyReLU()(Bn1_2)\n",
        "DO1_1 = Dropout(0.2)(Act1_2)\n",
        "Conv1_3 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(DO1_1)\n",
        "Bn1_3 = BatchNormalization()(Conv1_3)\n",
        "shortcut1_1 = Add()([Bn1_3, Conv])\n",
        "Bn1_4 = BatchNormalization()(shortcut1_1)\n",
        "Act1_3 = LeakyReLU()(Bn1_4)\n",
        "##### auxiliary\n",
        "Conv1_4 = Conv1D(filters=128, kernel_size=7, strides=3, padding='same')(Act1_3)\n",
        "Bn1_5 = BatchNormalization()(Conv1_4)\n",
        "Act1_4 = LeakyReLU()(Bn1_5)\n",
        "###############\n",
        "Max1_1 = MaxPooling1D(pool_size=5, strides=2)(Act1_4)\n",
        "\n",
        "\n",
        "## step 2\n",
        "\n",
        "Conv2_1 = Conv1D(filters=256, kernel_size=3, strides=1, padding='same')(Max1_1)\n",
        "Bn2_1 = BatchNormalization()(Conv2_1)\n",
        "Act2_1 = LeakyReLU()(Bn2_1)\n",
        "Conv2_2 = Conv1D(filters=256, kernel_size=5, strides=1, padding='same')(Act2_1)\n",
        "Bn2_2 = BatchNormalization()(Conv2_2)\n",
        "Act2_2 = LeakyReLU()(Bn2_2)\n",
        "DO2_1 = Dropout(0.2)(Act2_2)\n",
        "Conv2_3 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same')(DO2_1)\n",
        "Bn2_3 = BatchNormalization()(Conv2_3)\n",
        "shortcut2_1 = Add()([Bn2_3, Max1_1])\n",
        "Bn2_4 = BatchNormalization()(shortcut2_1)\n",
        "Act2_3 = LeakyReLU()(Bn2_4)\n",
        "##### auxiliary\n",
        "Conv2_4 = Conv1D(filters=512, kernel_size=7, strides=2, padding='same')(Act2_3)\n",
        "Bn2_5 = BatchNormalization()(Conv2_4)\n",
        "Act2_4 = LeakyReLU()(Bn2_5)\n",
        "###############\n",
        "Max2_1 = MaxPooling1D(pool_size=5, strides=3)(Act2_4)\n",
        "\n",
        "\n",
        "\n",
        "Flat1 = Flatten()(Max2_1)\n",
        "\n",
        "D1 = Dense(256)(Flat1)\n",
        "A6 = LeakyReLU()(D1)\n",
        "D_O = Dropout(0.15)(A6)\n",
        "D2 = Dense(128)(D_O)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=A7)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 2999, 64)     384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 2999, 64)     36928       conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2999, 64)     256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 2999, 64)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 2999, 32)     14368       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 2999, 32)     128         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 2999, 32)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2999, 32)     0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 2999, 64)     18496       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2999, 64)     256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 2999, 64)     0           batch_normalization_2[0][0]      \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 2999, 64)     256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1000, 128)    57472       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1000, 128)    512         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 1000, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 498, 128)     0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 498, 256)     98560       max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 498, 256)     1024        conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 498, 256)     327936      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 498, 256)     1024        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 498, 256)     0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 498, 128)     98432       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 498, 128)     512         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 498, 128)     0           batch_normalization_7[0][0]      \n",
            "                                                                 max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 498, 128)     512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 498, 128)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 249, 512)     459264      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 249, 512)     2048        conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 249, 512)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 82, 512)      0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 41984)        0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          10748160    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5)            645         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 5)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,900,069\n",
            "Trainable params: 11,896,805\n",
            "Non-trainable params: 3,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSfZxMLK7xI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-5,\n",
        "    decay_steps=2346,\n",
        "    decay_rate=0.8)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51SxpfQofzM",
        "colab_type": "code",
        "outputId": "26be7e92-3413-4d88-df2d-dabb1e1ea7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# overfitting so augment more data and decrease initial learning rate to 1e-3\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(XF_train, y_train, epochs=10, batch_size=64, validation_data=(XF_test, y_test), callbacks=[es_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 5890s 8s/step - loss: 0.6207 - accuracy: 0.7742 - val_loss: 1.4446 - val_accuracy: 0.4834\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 5930s 8s/step - loss: 0.3712 - accuracy: 0.8652 - val_loss: 0.7907 - val_accuracy: 0.7295\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 5877s 8s/step - loss: 0.2976 - accuracy: 0.8920 - val_loss: 1.0336 - val_accuracy: 0.6605\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 5878s 8s/step - loss: 0.2561 - accuracy: 0.9066 - val_loss: 0.6822 - val_accuracy: 0.7824\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 5846s 7s/step - loss: 0.2252 - accuracy: 0.9181 - val_loss: 0.7042 - val_accuracy: 0.7820\n",
            "Epoch 6/10\n",
            " 64/782 [=>............................] - ETA: 1:20:24 - loss: 0.2160 - accuracy: 0.9282"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUPC94zqTiE",
        "colab_type": "code",
        "outputId": "1db5eee5-aa5b-4b8e-c835-31440c378940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(XF_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"/content/drive/My Drive/Cardio/HeartBeat.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 87.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCecYVrhtbNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht3ltnGvtjlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}