{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/alirezash97/Cardio/blob/master/HeartBeat.ipynb",
      "authorship_tag": "ABX9TyMrEW5Ihp1lzQ2ne1IGQtGM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Cardio/blob/master/HeartBeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUFDobFVvj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"alirezashafaei97\",\"key\":\"9cb262aa0c5658ffc4eb45857c41903c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat -p /content\n",
        "!unzip /content/heartbeat.zip -d /content/heartbeat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sio7SWAwWBLj",
        "colab_type": "code",
        "outputId": "f8e18d20-3c3a-48a0-fd04-cb1b9092bd1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, LeakyReLU, Softmax, InputLayer, concatenate, Conv1D, MaxPool1D, Add, MaxPooling1D\n",
        " , Flatten, Dropout, ReLU, BatchNormalization, GlobalAveragePooling1D)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from random import uniform \n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTudiQO8WEXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/heartbeat/mitbih_test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2SBJpgbi9WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_df = train_df[:186].astype('float16')\n",
        "# test_df = test_df[:186].astype('float16')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58wFx5vXQS7",
        "colab_type": "code",
        "outputId": "1c424c30-5bf4-41de-fa11-b22415ccd0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "counter=train_df[187].value_counts()\n",
        "print(counter)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQqNZG2q59y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=10000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=10000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=10000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=10000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=10000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomIXpkCrozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBctv4Tr58D",
        "colab_type": "code",
        "outputId": "c5505387-ea55-48c1-a060-9ffcf6e3e879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    10000\n",
            "3    10000\n",
            "2    10000\n",
            "1    10000\n",
            "0    10000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3HJfHYr605",
        "colab_type": "code",
        "outputId": "596cefa5-79c2-4964-e8eb-4cbf877ac4ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\n",
        "c"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23029</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.791925</td>\n",
              "      <td>0.611801</td>\n",
              "      <td>0.307453</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.055901</td>\n",
              "      <td>0.118012</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.161491</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.161491</td>\n",
              "      <td>0.158385</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.161491</td>\n",
              "      <td>0.180124</td>\n",
              "      <td>0.167702</td>\n",
              "      <td>0.192547</td>\n",
              "      <td>0.189441</td>\n",
              "      <td>0.211180</td>\n",
              "      <td>0.201863</td>\n",
              "      <td>0.232919</td>\n",
              "      <td>0.236025</td>\n",
              "      <td>0.270186</td>\n",
              "      <td>0.279503</td>\n",
              "      <td>0.307453</td>\n",
              "      <td>0.316770</td>\n",
              "      <td>0.354037</td>\n",
              "      <td>0.354037</td>\n",
              "      <td>0.397516</td>\n",
              "      <td>0.406832</td>\n",
              "      <td>0.456522</td>\n",
              "      <td>0.450311</td>\n",
              "      <td>0.447205</td>\n",
              "      <td>0.397516</td>\n",
              "      <td>0.354037</td>\n",
              "      <td>0.307453</td>\n",
              "      <td>0.291925</td>\n",
              "      <td>0.245342</td>\n",
              "      <td>0.248447</td>\n",
              "      <td>0.226708</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74608</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.971014</td>\n",
              "      <td>0.289855</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.091787</td>\n",
              "      <td>0.120773</td>\n",
              "      <td>0.053140</td>\n",
              "      <td>0.125604</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.169082</td>\n",
              "      <td>0.154589</td>\n",
              "      <td>0.207729</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.367150</td>\n",
              "      <td>0.357488</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.386473</td>\n",
              "      <td>0.400966</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.357488</td>\n",
              "      <td>0.400966</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.367150</td>\n",
              "      <td>0.376812</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.425121</td>\n",
              "      <td>0.415459</td>\n",
              "      <td>0.449275</td>\n",
              "      <td>0.502415</td>\n",
              "      <td>0.516908</td>\n",
              "      <td>0.516908</td>\n",
              "      <td>0.541063</td>\n",
              "      <td>0.570048</td>\n",
              "      <td>0.589372</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.642512</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.574879</td>\n",
              "      <td>0.545894</td>\n",
              "      <td>...</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.294686</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.299517</td>\n",
              "      <td>0.280193</td>\n",
              "      <td>0.323671</td>\n",
              "      <td>0.31401</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.323671</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.323671</td>\n",
              "      <td>0.309179</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.299517</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.294686</td>\n",
              "      <td>0.31401</td>\n",
              "      <td>0.338164</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.323671</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.31401</td>\n",
              "      <td>0.323671</td>\n",
              "      <td>0.342995</td>\n",
              "      <td>0.338164</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.31401</td>\n",
              "      <td>0.352657</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.285024</td>\n",
              "      <td>0.285024</td>\n",
              "      <td>0.31401</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.342995</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78364</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.967675</td>\n",
              "      <td>0.687174</td>\n",
              "      <td>0.286757</td>\n",
              "      <td>0.162669</td>\n",
              "      <td>0.172054</td>\n",
              "      <td>0.133472</td>\n",
              "      <td>0.117831</td>\n",
              "      <td>0.133472</td>\n",
              "      <td>0.136601</td>\n",
              "      <td>0.118874</td>\n",
              "      <td>0.103233</td>\n",
              "      <td>0.096976</td>\n",
              "      <td>0.093848</td>\n",
              "      <td>0.079249</td>\n",
              "      <td>0.068822</td>\n",
              "      <td>0.064651</td>\n",
              "      <td>0.050052</td>\n",
              "      <td>0.037539</td>\n",
              "      <td>0.026069</td>\n",
              "      <td>0.016684</td>\n",
              "      <td>0.012513</td>\n",
              "      <td>0.006257</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.015641</td>\n",
              "      <td>0.020855</td>\n",
              "      <td>0.038582</td>\n",
              "      <td>0.065693</td>\n",
              "      <td>0.098019</td>\n",
              "      <td>0.118874</td>\n",
              "      <td>0.139729</td>\n",
              "      <td>0.160584</td>\n",
              "      <td>0.183525</td>\n",
              "      <td>0.191867</td>\n",
              "      <td>0.197080</td>\n",
              "      <td>0.204380</td>\n",
              "      <td>0.212722</td>\n",
              "      <td>0.211679</td>\n",
              "      <td>0.207508</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80617</th>\n",
              "      <td>0.966216</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.603041</td>\n",
              "      <td>0.253378</td>\n",
              "      <td>0.173986</td>\n",
              "      <td>0.140203</td>\n",
              "      <td>0.114865</td>\n",
              "      <td>0.104730</td>\n",
              "      <td>0.091216</td>\n",
              "      <td>0.096284</td>\n",
              "      <td>0.081081</td>\n",
              "      <td>0.087838</td>\n",
              "      <td>0.072635</td>\n",
              "      <td>0.076014</td>\n",
              "      <td>0.060811</td>\n",
              "      <td>0.070946</td>\n",
              "      <td>0.059122</td>\n",
              "      <td>0.054054</td>\n",
              "      <td>0.037162</td>\n",
              "      <td>0.043919</td>\n",
              "      <td>0.033784</td>\n",
              "      <td>0.037162</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.028716</td>\n",
              "      <td>0.035473</td>\n",
              "      <td>0.054054</td>\n",
              "      <td>0.064189</td>\n",
              "      <td>0.086149</td>\n",
              "      <td>0.091216</td>\n",
              "      <td>0.119932</td>\n",
              "      <td>0.140203</td>\n",
              "      <td>0.170608</td>\n",
              "      <td>0.175676</td>\n",
              "      <td>0.180743</td>\n",
              "      <td>0.165541</td>\n",
              "      <td>0.182432</td>\n",
              "      <td>0.173986</td>\n",
              "      <td>0.172297</td>\n",
              "      <td>0.157095</td>\n",
              "      <td>0.167230</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83287</th>\n",
              "      <td>0.743922</td>\n",
              "      <td>0.648298</td>\n",
              "      <td>0.542950</td>\n",
              "      <td>0.410049</td>\n",
              "      <td>0.280389</td>\n",
              "      <td>0.149109</td>\n",
              "      <td>0.082658</td>\n",
              "      <td>0.022690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008104</td>\n",
              "      <td>0.082658</td>\n",
              "      <td>0.170178</td>\n",
              "      <td>0.309562</td>\n",
              "      <td>0.361426</td>\n",
              "      <td>0.434360</td>\n",
              "      <td>0.491086</td>\n",
              "      <td>0.555916</td>\n",
              "      <td>0.578606</td>\n",
              "      <td>0.609400</td>\n",
              "      <td>0.615883</td>\n",
              "      <td>0.633712</td>\n",
              "      <td>0.635332</td>\n",
              "      <td>0.654781</td>\n",
              "      <td>0.656402</td>\n",
              "      <td>0.680713</td>\n",
              "      <td>0.680713</td>\n",
              "      <td>0.703404</td>\n",
              "      <td>0.701783</td>\n",
              "      <td>0.726094</td>\n",
              "      <td>0.734198</td>\n",
              "      <td>0.761750</td>\n",
              "      <td>0.771475</td>\n",
              "      <td>0.800648</td>\n",
              "      <td>0.811994</td>\n",
              "      <td>0.839546</td>\n",
              "      <td>0.850891</td>\n",
              "      <td>0.871961</td>\n",
              "      <td>0.883306</td>\n",
              "      <td>0.904376</td>\n",
              "      <td>0.899514</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3    ...      184       185       186  187\n",
              "23029  1.000000  0.791925  0.611801  0.307453  ...  0.00000  0.000000  0.000000    0\n",
              "74608  1.000000  0.971014  0.289855  0.000000  ...  0.31401  0.347826  0.342995    1\n",
              "78364  1.000000  0.967675  0.687174  0.286757  ...  0.00000  0.000000  0.000000    2\n",
              "80617  0.966216  1.000000  0.603041  0.253378  ...  0.00000  0.000000  0.000000    3\n",
              "83287  0.743922  0.648298  0.542950  0.410049  ...  0.00000  0.000000  0.000000    4\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie12gfa0cRQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB80IzMo1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_gaussian_noise(signal):\n",
        "    noise=np.random.normal(0,0.05,186)\n",
        "    return (signal+noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJB5fWu5sWNc",
        "colab_type": "code",
        "outputId": "00e3e5a6-75c8-497e-84a8-e0b1cadb1ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tempo=c.iloc[0,:186]\n",
        "bruiter=add_gaussian_noise(tempo)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(c.iloc[0,:186])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(bruiter)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4fXuypr6vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUVlLpKPsQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.astype('float16')\n",
        "test_df = test_df.astype('float16')\n",
        "\n",
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values\n",
        "# X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
        "# X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexzfSPiD34D",
        "colab_type": "code",
        "outputId": "ebec4817-855d-4d39-d4ca-2f098bd6f92a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 186)\n",
            "(21892, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPfQkUVfnTx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data augmentation\n",
        "\n",
        "def augmetation(X_train, y_train, chance):\n",
        "\n",
        "  augment_number = 0\n",
        "  XF_train = np.zeros((X_train.shape[0]*2, X_train.shape[1]))\n",
        "  yf_train = np.zeros((y_train.shape[0]*2, y_train.shape[1]))\n",
        "  pointer = 0\n",
        "  for index, row in enumerate(X_train):\n",
        "\n",
        "    XF_train[pointer, :] = row\n",
        "    yf_train[pointer, :] = y_train[index, :]\n",
        "    pointer += 1\n",
        "\n",
        "    rand_num = random.uniform(0, 1)      \n",
        "    if chance > rand_num :\n",
        "\n",
        "      augment_number += 1\n",
        "      noise = np.random.normal(0,0.05,186)\n",
        "      new_signal = row + noise  \n",
        "      XF_train[pointer, :] = new_signal\n",
        "      yf_train[pointer, :] = y_train[index, :]\n",
        "      pointer += 1\n",
        "\n",
        "      filled = X_train.shape[0] + augment_number\n",
        "      XFF_train = XF_train[:filled, :]\n",
        "      yff_train = yf_train[:filled, :]\n",
        "\n",
        "    \n",
        "  return XFF_train, yff_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dXhm8thnj1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = augmetation(X_train, y_train, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzROJp1Fr6q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "import pywt\n",
        "\n",
        "XF_train = np.zeros((X_train.shape[0], 9000))\n",
        "XF_test = np.zeros((X_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_train):\n",
        "  XF_train[index, :] = pywt.pad(row, 4407, 'periodic')\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_test):\n",
        "  XF_test[index, :] = pywt.pad(row, 4407, 'periodic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmANeCYtjmgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XF_train = XF_train.reshape((XF_train.shape[0], 9000, 1))\n",
        "XF_test = XF_test.reshape((XF_test.shape[0], 9000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNvkTDCjyoA",
        "colab_type": "code",
        "outputId": "02ccee86-c159-4e4e-ec42-3dfe427563a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train : \", XF_train.shape)\n",
        "print(\"Y_train : \", y_train.shape)\n",
        "print(\"X_test : \", XF_test.shape)\n",
        "print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train :  (54991, 9000, 1)\n",
            "Y_train :  (54991, 5)\n",
            "X_test :  (21892, 9000, 1)\n",
            "Y_test :  (21892, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvIW2sWkaoP",
        "colab_type": "code",
        "outputId": "b4dbbc26-975f-4548-9458-2312da4f0a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_input = Input(shape=(9000, 1))\n",
        "Conv = Conv1D(filters=64, kernel_size=5, strides=3)(X_input)\n",
        "\n",
        "\n",
        "### step 1 \n",
        "\n",
        "Conv1_1 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(Conv)\n",
        "Bn1_1 = BatchNormalization()(Conv1_1)\n",
        "Act1_1 = LeakyReLU()(Bn1_1)\n",
        "Conv1_2 = Conv1D(filters=64, kernel_size=7, strides=1, padding='same')(Act1_1)\n",
        "Bn1_2 = BatchNormalization()(Conv1_2)\n",
        "Act1_2 = LeakyReLU()(Bn1_2)\n",
        "DO1_1 = Dropout(0.2)(Act1_2)\n",
        "Conv1_3 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(DO1_1)\n",
        "Bn1_3 = BatchNormalization()(Conv1_3)\n",
        "shortcut1_1 = Add()([Bn1_3, Conv])\n",
        "Bn1_4 = BatchNormalization()(shortcut1_1)\n",
        "Act1_3 = LeakyReLU()(Bn1_4)\n",
        "##### auxiliary\n",
        "Conv1_4 = Conv1D(filters=128, kernel_size=7, strides=3, padding='same')(Act1_3)\n",
        "Bn1_5 = BatchNormalization()(Conv1_4)\n",
        "Act1_4 = LeakyReLU()(Bn1_5)\n",
        "###############\n",
        "Max1_1 = MaxPooling1D(pool_size=5, strides=2)(Act1_4)\n",
        "\n",
        "\n",
        "## step 2\n",
        "\n",
        "Conv2_1 = Conv1D(filters=256, kernel_size=3, strides=1, padding='same')(Max1_1)\n",
        "Bn2_1 = BatchNormalization()(Conv2_1)\n",
        "Act2_1 = LeakyReLU()(Bn2_1)\n",
        "Conv2_2 = Conv1D(filters=256, kernel_size=5, strides=1, padding='same')(Act2_1)\n",
        "Bn2_2 = BatchNormalization()(Conv2_2)\n",
        "Act2_2 = LeakyReLU()(Bn2_2)\n",
        "DO2_1 = Dropout(0.2)(Act2_2)\n",
        "Conv2_3 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same')(DO2_1)\n",
        "Bn2_3 = BatchNormalization()(Conv2_3)\n",
        "shortcut2_1 = Add()([Bn2_3, Max1_1])\n",
        "Bn2_4 = BatchNormalization()(shortcut2_1)\n",
        "Act2_3 = LeakyReLU()(Bn2_4)\n",
        "##### auxiliary\n",
        "Conv2_4 = Conv1D(filters=512, kernel_size=7, strides=2, padding='same')(Act2_3)\n",
        "Bn2_5 = BatchNormalization()(Conv2_4)\n",
        "Act2_4 = LeakyReLU()(Bn2_5)\n",
        "###############\n",
        "Max2_1 = MaxPooling1D(pool_size=5, strides=3)(Act2_4)\n",
        "\n",
        "\n",
        "\n",
        "Flat1 = Flatten()(Max2_1)\n",
        "\n",
        "D1 = Dense(256)(Flat1)\n",
        "A6 = LeakyReLU()(D1)\n",
        "D_O = Dropout(0.15)(A6)\n",
        "D2 = Dense(128)(D_O)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=A7)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 2999, 64)     384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 2999, 64)     36928       conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2999, 64)     256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 2999, 64)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 2999, 64)     28736       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 2999, 64)     256         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2999, 64)     0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 2999, 64)     36928       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2999, 64)     256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 2999, 64)     0           batch_normalization_2[0][0]      \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 2999, 64)     256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1000, 128)    57472       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1000, 128)    512         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 1000, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 498, 128)     0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 498, 256)     98560       max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 498, 256)     1024        conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 498, 256)     327936      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 498, 256)     1024        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 498, 256)     0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 498, 128)     98432       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 498, 128)     512         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 498, 128)     0           batch_normalization_7[0][0]      \n",
            "                                                                 max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 498, 128)     512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 498, 128)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 249, 512)     459264      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 249, 512)     2048        conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 249, 512)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 82, 512)      0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 41984)        0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          10748160    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5)            645         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 5)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,932,997\n",
            "Trainable params: 11,929,669\n",
            "Non-trainable params: 3,328\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSfZxMLK7xI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=1719,\n",
        "    decay_rate=0.7)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51SxpfQofzM",
        "colab_type": "code",
        "outputId": "2763ad2f-481c-4ee8-be81-10007d2567c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# overfitting so augment more data and decrease initial learning rate to 1e-3\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(XF_train, y_train, epochs=7, batch_size=64, validation_data=(XF_test, y_test), callbacks=[es_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "860/860 [==============================] - 7778s 9s/step - loss: 3.8281 - accuracy: 0.6426 - val_loss: 0.3030 - val_accuracy: 0.9246\n",
            "Epoch 2/7\n",
            "860/860 [==============================] - 8050s 9s/step - loss: 0.3551 - accuracy: 0.8814 - val_loss: 0.3695 - val_accuracy: 0.8722\n",
            "Epoch 3/7\n",
            "860/860 [==============================] - 8033s 9s/step - loss: 0.2365 - accuracy: 0.9176 - val_loss: 0.2716 - val_accuracy: 0.9079\n",
            "Epoch 4/7\n",
            "860/860 [==============================] - 8097s 9s/step - loss: 0.2672 - accuracy: 0.9205 - val_loss: 0.2414 - val_accuracy: 0.9203\n",
            "Epoch 5/7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUPC94zqTiE",
        "colab_type": "code",
        "outputId": "15e76721-375a-4993-e207-30055522d4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(XF_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"/content/drive/My Drive/Cardio/HeartBeat.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-78fb4bd29953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXF_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# save model and architecture to single file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCecYVrhtbNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht3ltnGvtjlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}