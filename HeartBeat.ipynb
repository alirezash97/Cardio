{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/alirezash97/Cardio/blob/master/HeartBeat.ipynb",
      "authorship_tag": "ABX9TyNgfjyq6JKntqfxfRvgPzj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Cardio/blob/master/HeartBeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUFDobFVvj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"alirezashafaei97\",\"key\":\"9cb262aa0c5658ffc4eb45857c41903c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat -p /content\n",
        "!unzip /content/heartbeat.zip -d /content/heartbeat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sio7SWAwWBLj",
        "colab_type": "code",
        "outputId": "bce824f6-8949-4cbb-ce9a-05cbcb4cac2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, LeakyReLU, Softmax, InputLayer, concatenate, Conv1D, MaxPool1D, Add, MaxPooling1D\n",
        " , Flatten, Dropout, ReLU, BatchNormalization, GlobalAveragePooling1D)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from random import uniform \n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTudiQO8WEXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/heartbeat/mitbih_test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfWxem7CTc50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del train_df\n",
        "# del test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58wFx5vXQS7",
        "colab_type": "code",
        "outputId": "4917c972-5db1-4cef-cc35-c1bbb38361b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "counter=train_df[187].value_counts()\n",
        "print(counter)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQqNZG2q59y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=10000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=10000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=10000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=10000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=10000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomIXpkCrozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBctv4Tr58D",
        "colab_type": "code",
        "outputId": "a5a105d8-a7ab-4973-f23a-081c9924a8a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    10000\n",
            "3    10000\n",
            "2    10000\n",
            "1    10000\n",
            "0    10000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3HJfHYr605",
        "colab_type": "code",
        "outputId": "4a35ee49-d9f2-4a10-9e73-0e8a86d7784b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\n",
        "c"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31557</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.832891</td>\n",
              "      <td>0.668435</td>\n",
              "      <td>0.408488</td>\n",
              "      <td>0.302387</td>\n",
              "      <td>0.161804</td>\n",
              "      <td>0.092838</td>\n",
              "      <td>0.042440</td>\n",
              "      <td>0.023873</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026525</td>\n",
              "      <td>0.029178</td>\n",
              "      <td>0.031830</td>\n",
              "      <td>0.026525</td>\n",
              "      <td>0.037135</td>\n",
              "      <td>0.031830</td>\n",
              "      <td>0.050398</td>\n",
              "      <td>0.031830</td>\n",
              "      <td>0.047745</td>\n",
              "      <td>0.037135</td>\n",
              "      <td>0.045093</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.037135</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.047745</td>\n",
              "      <td>0.039788</td>\n",
              "      <td>0.063660</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.100796</td>\n",
              "      <td>0.111406</td>\n",
              "      <td>0.145889</td>\n",
              "      <td>0.167109</td>\n",
              "      <td>0.193634</td>\n",
              "      <td>0.196286</td>\n",
              "      <td>0.220159</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>0.214854</td>\n",
              "      <td>0.183024</td>\n",
              "      <td>0.177719</td>\n",
              "      <td>0.164456</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74608</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.971014</td>\n",
              "      <td>0.289855</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.091787</td>\n",
              "      <td>0.120773</td>\n",
              "      <td>0.053140</td>\n",
              "      <td>0.125604</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.169082</td>\n",
              "      <td>0.154589</td>\n",
              "      <td>0.207729</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.367150</td>\n",
              "      <td>0.357488</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.386473</td>\n",
              "      <td>0.400966</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.357488</td>\n",
              "      <td>0.400966</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.367150</td>\n",
              "      <td>0.376812</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.425121</td>\n",
              "      <td>0.415459</td>\n",
              "      <td>0.449275</td>\n",
              "      <td>0.502415</td>\n",
              "      <td>0.516908</td>\n",
              "      <td>0.516908</td>\n",
              "      <td>0.541063</td>\n",
              "      <td>0.570048</td>\n",
              "      <td>0.589372</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.642512</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.574879</td>\n",
              "      <td>0.545894</td>\n",
              "      <td>...</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.294686</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.299517</td>\n",
              "      <td>0.280193</td>\n",
              "      <td>0.323671</td>\n",
              "      <td>0.31401</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.323671</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.323671</td>\n",
              "      <td>0.309179</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.299517</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.294686</td>\n",
              "      <td>0.31401</td>\n",
              "      <td>0.338164</td>\n",
              "      <td>0.328502</td>\n",
              "      <td>0.323671</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.31401</td>\n",
              "      <td>0.323671</td>\n",
              "      <td>0.342995</td>\n",
              "      <td>0.338164</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.31401</td>\n",
              "      <td>0.352657</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.285024</td>\n",
              "      <td>0.285024</td>\n",
              "      <td>0.31401</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.342995</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79657</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.988611</td>\n",
              "      <td>0.955581</td>\n",
              "      <td>0.936219</td>\n",
              "      <td>0.891800</td>\n",
              "      <td>0.776765</td>\n",
              "      <td>0.553531</td>\n",
              "      <td>0.358770</td>\n",
              "      <td>0.266515</td>\n",
              "      <td>0.192483</td>\n",
              "      <td>0.134396</td>\n",
              "      <td>0.125285</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.097950</td>\n",
              "      <td>0.080866</td>\n",
              "      <td>0.061503</td>\n",
              "      <td>0.047836</td>\n",
              "      <td>0.028474</td>\n",
              "      <td>0.009112</td>\n",
              "      <td>0.002278</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005695</td>\n",
              "      <td>0.012528</td>\n",
              "      <td>0.026196</td>\n",
              "      <td>0.055809</td>\n",
              "      <td>0.082005</td>\n",
              "      <td>0.113895</td>\n",
              "      <td>0.148064</td>\n",
              "      <td>0.190205</td>\n",
              "      <td>0.233485</td>\n",
              "      <td>0.263098</td>\n",
              "      <td>0.296128</td>\n",
              "      <td>0.323462</td>\n",
              "      <td>0.324601</td>\n",
              "      <td>0.333713</td>\n",
              "      <td>0.334852</td>\n",
              "      <td>0.339408</td>\n",
              "      <td>0.334852</td>\n",
              "      <td>0.318907</td>\n",
              "      <td>0.315490</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80564</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.816739</td>\n",
              "      <td>0.529582</td>\n",
              "      <td>0.243867</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0.089466</td>\n",
              "      <td>0.102453</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.037518</td>\n",
              "      <td>0.028860</td>\n",
              "      <td>0.028860</td>\n",
              "      <td>0.021645</td>\n",
              "      <td>0.008658</td>\n",
              "      <td>0.012987</td>\n",
              "      <td>0.007215</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014430</td>\n",
              "      <td>0.021645</td>\n",
              "      <td>0.044733</td>\n",
              "      <td>0.051948</td>\n",
              "      <td>0.066378</td>\n",
              "      <td>0.108225</td>\n",
              "      <td>0.137085</td>\n",
              "      <td>0.167388</td>\n",
              "      <td>0.203463</td>\n",
              "      <td>0.239538</td>\n",
              "      <td>0.282828</td>\n",
              "      <td>0.304473</td>\n",
              "      <td>0.317460</td>\n",
              "      <td>0.347763</td>\n",
              "      <td>0.354978</td>\n",
              "      <td>0.354978</td>\n",
              "      <td>0.349206</td>\n",
              "      <td>0.337662</td>\n",
              "      <td>0.339105</td>\n",
              "      <td>0.318903</td>\n",
              "      <td>0.297258</td>\n",
              "      <td>0.287157</td>\n",
              "      <td>0.262626</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85958</th>\n",
              "      <td>0.680441</td>\n",
              "      <td>0.460055</td>\n",
              "      <td>0.435262</td>\n",
              "      <td>0.399449</td>\n",
              "      <td>0.371901</td>\n",
              "      <td>0.319559</td>\n",
              "      <td>0.297521</td>\n",
              "      <td>0.245179</td>\n",
              "      <td>0.201102</td>\n",
              "      <td>0.093664</td>\n",
              "      <td>0.046832</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013774</td>\n",
              "      <td>0.024793</td>\n",
              "      <td>0.052342</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.184573</td>\n",
              "      <td>0.239669</td>\n",
              "      <td>0.311295</td>\n",
              "      <td>0.341598</td>\n",
              "      <td>0.371901</td>\n",
              "      <td>0.369146</td>\n",
              "      <td>0.402204</td>\n",
              "      <td>0.388430</td>\n",
              "      <td>0.402204</td>\n",
              "      <td>0.399449</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.429752</td>\n",
              "      <td>0.446281</td>\n",
              "      <td>0.451791</td>\n",
              "      <td>0.449036</td>\n",
              "      <td>0.451791</td>\n",
              "      <td>0.468320</td>\n",
              "      <td>0.460055</td>\n",
              "      <td>0.479339</td>\n",
              "      <td>0.468320</td>\n",
              "      <td>0.479339</td>\n",
              "      <td>0.473829</td>\n",
              "      <td>0.490358</td>\n",
              "      <td>0.487603</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3    ...      184       185       186  187\n",
              "31557  1.000000  0.832891  0.668435  0.408488  ...  0.00000  0.000000  0.000000    0\n",
              "74608  1.000000  0.971014  0.289855  0.000000  ...  0.31401  0.347826  0.342995    1\n",
              "79657  1.000000  0.988611  0.955581  0.936219  ...  0.00000  0.000000  0.000000    2\n",
              "80564  1.000000  0.816739  0.529582  0.243867  ...  0.00000  0.000000  0.000000    3\n",
              "85958  0.680441  0.460055  0.435262  0.399449  ...  0.00000  0.000000  0.000000    4\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB80IzMo1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_gaussian_noise(signal):\n",
        "    noise=np.random.normal(0,0.05,186)\n",
        "    return (signal+noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJB5fWu5sWNc",
        "colab_type": "code",
        "outputId": "9c28d515-4478-4623-b033-fd7619f64374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tempo=c.iloc[0,:186]\n",
        "bruiter=add_gaussian_noise(tempo)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(c.iloc[0,:186])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(bruiter)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4fXuypr6vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUVlLpKPsQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values\n",
        "# X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
        "# X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexzfSPiD34D",
        "colab_type": "code",
        "outputId": "69d63319-07dc-47b1-97e2-ae6d0f199eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 186)\n",
            "(21892, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPfQkUVfnTx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data augmentation\n",
        "\n",
        "def augmetation(X_train, y_train, chance):\n",
        "\n",
        "  augment_number = 0\n",
        "  XF_train = np.zeros((X_train.shape[0]*2, X_train.shape[1]))\n",
        "  yf_train = np.zeros((y_train.shape[0]*2, y_train.shape[1]))\n",
        "  pointer = 0\n",
        "  for index, row in enumerate(X_train):\n",
        "\n",
        "    XF_train[pointer, :] = row\n",
        "    yf_train[pointer, :] = y_train[index, :]\n",
        "    pointer += 1\n",
        "\n",
        "    rand_num = random.uniform(0, 1)      \n",
        "    if chance > rand_num :\n",
        "\n",
        "      augment_number += 1\n",
        "      noise = np.random.normal(0,0.05,186)\n",
        "      new_signal = row + noise  \n",
        "      XF_train[pointer, :] = new_signal\n",
        "      yf_train[pointer, :] = y_train[index, :]\n",
        "      pointer += 1\n",
        "\n",
        "      filled = X_train.shape[0] + augment_number\n",
        "      XFF_train = XF_train[:filled, :]\n",
        "      yff_train = yf_train[:filled, :]\n",
        "\n",
        "    \n",
        "  return XFF_train, yff_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dXhm8thnj1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = augmetation(X_train, y_train, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzROJp1Fr6q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "import pywt\n",
        "\n",
        "XF_train = np.zeros((X_train.shape[0], 9000))\n",
        "XF_test = np.zeros((X_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_train):\n",
        "  XF_train[index, :] = pywt.pad(row, 4407, 'periodic')\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_test):\n",
        "  XF_test[index, :] = pywt.pad(row, 4407, 'periodic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0aEgkhXamJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = train_df.values\n",
        "# testset = test_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Yu65s0adg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def split(dataset, number_of_sample_per_category):\n",
        "  \n",
        "#   new_dataset = np.zeros((np.sum(number_of_sample_per_category), dataset.shape[1]))\n",
        "#   pointer = 0\n",
        "  \n",
        "#   for row in dataset :\n",
        "    \n",
        "#     row_label = int(row[-1])\n",
        "    \n",
        "#     if number_of_sample_per_category[row_label] > 0 :\n",
        "      \n",
        "#       number_of_sample_per_category[row_label] -= 1\n",
        "#       new_dataset[pointer , :] = row\n",
        "#       pointer += 1\n",
        "\n",
        "#     else:\n",
        "\n",
        "#       pass\n",
        "    \n",
        "  \n",
        "#   return new_dataset\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTg8U_rCecMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# temp_trainset = split(trainset, [5500, 2223, 5500, 641, 5500])\n",
        "# temp_testset = split(testset, [500, 500, 500, 500, 500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VixGjo-J1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented = 0\n",
        "# def data_augmentation(dataset, chance):\n",
        "  \n",
        "#   augmented = 0\n",
        "#   number_of_rows = int(dataset.shape[0] + (dataset.shape[0] * (chance*2)))\n",
        "#   new_dataset = np.zeros((number_of_rows, dataset.shape[1]))\n",
        "#   pointer = 0 \n",
        "\n",
        "#   for row in dataset:\n",
        "    \n",
        "#     rand_num = random.uniform(0, 1)\n",
        "#     if rand_num < chance:\n",
        "      \n",
        "#       augmented += 1\n",
        "#       noise = np.random.normal(scale=0.01, size=187)\n",
        "#       new_signal = np.zeros((1, 188))\n",
        "#       new_signal[:, :187] = row[:187] + noise\n",
        "#       new_signal[:, -1:] = row[-1:] \n",
        "#       new_dataset[pointer:pointer+1, :] = new_signal\n",
        "#       pointer += 1\n",
        "\n",
        "#     else :\n",
        "#       pass\n",
        "\n",
        "#     new_dataset[pointer, :] = row \n",
        "#     pointer += 1\n",
        "\n",
        "#   return augmented, new_dataset  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-WNJJaSNYR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented, trainset = data_augmentation(temp_trainset, 0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEkQ1k_zRnYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filled = augmented + temp_trainset.shape[0]\n",
        "# trainset = trainset[:filled , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULVB16ONXuex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = np.take(trainset,np.random.permutation(trainset.shape[0]),axis=0,out=trainset)\n",
        "# testset = np.take(temp_testset,np.random.permutation(temp_testset.shape[0]),axis=0,out=temp_testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXpOUPpHYPQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_temp_train = trainset[:, :-1]\n",
        "# Y_train = trainset[:, -1:]\n",
        "# X_temp_test = testset[:, :-1]\n",
        "# Y_test = testset[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wSnYvXY6AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", XF_train.shape)\n",
        "# print(\"Y_train : \", y_train.shape)\n",
        "# print(\"X_test : \", XF_test.shape)\n",
        "# print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQP8dTlBZw6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# One Hot enoding for target labels \n",
        "# ohe = OneHotEncoder()\n",
        "# Y_train = ohe.fit_transform(Y_train.reshape(-1,1))\n",
        "# Y_test = ohe.transform(Y_test.reshape(-1,1))\n",
        "\n",
        "# # handle sparse matrix for keras \n",
        "# Y_train = csr_matrix.toarray(Y_train)\n",
        "# Y_test = csr_matrix.toarray(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBhFohZUarKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", X_temp_train.shape)\n",
        "# print(\"Y_train : \", Y_train.shape)\n",
        "# print(\"X_test : \", X_temp_test.shape)\n",
        "# print(\"Y_test : \", Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E525NqY3aGSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "# import pywt\n",
        "\n",
        "# XF_train = np.zeros((X_temp_train.shape[0], 9000))\n",
        "# XF_test = np.zeros((X_temp_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_train):\n",
        "#   XF_train[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_train[index, -1:] = 0\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   XF_test[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_test[index, -1:] = 0\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCEcchWo3cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index, row in enumerate(X_temp_train):\n",
        "#   X_temp_train[index] = add_gaussian_noise(row)\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   X_temp_test[index] = add_gaussian_noise(row)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sj8_kDXn85E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb8693a7-4fc7-45ec-80e4-504b74e5645f"
      },
      "source": [
        "print(XF_train.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54917, 9000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmANeCYtjmgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XF_train = XF_train.reshape((XF_train.shape[0], 9000, 1))\n",
        "XF_test = XF_test.reshape((21892, 9000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNvkTDCjyoA",
        "colab_type": "code",
        "outputId": "854345ca-637c-4b47-bf8a-98685d1d4065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train : \", XF_train.shape)\n",
        "print(\"Y_train : \", y_train.shape)\n",
        "print(\"X_test : \", XF_test.shape)\n",
        "print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train :  (54917, 9000, 1)\n",
            "Y_train :  (54917, 5)\n",
            "X_test :  (21892, 9000, 1)\n",
            "Y_test :  (21892, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvIW2sWkaoP",
        "colab_type": "code",
        "outputId": "0807ba34-60eb-4c72-c3cd-bfcdc1aecf3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_input = Input(shape=(9000, 1))\n",
        "Conv = Conv1D(filters=64, kernel_size=5, strides=3)(X_input)\n",
        "\n",
        "\n",
        "### step 1 \n",
        "\n",
        "Conv1_1 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(Conv)\n",
        "Bn1_1 = BatchNormalization()(Conv1_1)\n",
        "Act1_1 = LeakyReLU()(Bn1_1)\n",
        "Conv1_2 = Conv1D(filters=32, kernel_size=7, strides=1, padding='same')(Act1_1)\n",
        "Bn1_2 = BatchNormalization()(Conv1_2)\n",
        "Act1_2 = LeakyReLU()(Bn1_2)\n",
        "DO1_1 = Dropout(0.2)(Act1_2)\n",
        "Conv1_3 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(DO1_1)\n",
        "Bn1_3 = BatchNormalization()(Conv1_3)\n",
        "shortcut1_1 = Add()([Bn1_3, Conv])\n",
        "Bn1_4 = BatchNormalization()(shortcut1_1)\n",
        "Act1_3 = LeakyReLU()(Bn1_4)\n",
        "##### auxiliary\n",
        "Conv1_4 = Conv1D(filters=128, kernel_size=7, strides=3, padding='same')(Act1_3)\n",
        "Bn1_5 = BatchNormalization()(Conv1_4)\n",
        "Act1_4 = LeakyReLU()(Bn1_5)\n",
        "###############\n",
        "Max1_1 = MaxPooling1D(pool_size=5, strides=2)(Act1_4)\n",
        "\n",
        "\n",
        "## step 2\n",
        "\n",
        "Conv2_1 = Conv1D(filters=256, kernel_size=3, strides=1, padding='same')(Max1_1)\n",
        "Bn2_1 = BatchNormalization()(Conv2_1)\n",
        "Act2_1 = LeakyReLU()(Bn2_1)\n",
        "Conv2_2 = Conv1D(filters=256, kernel_size=5, strides=1, padding='same')(Act2_1)\n",
        "Bn2_2 = BatchNormalization()(Conv2_2)\n",
        "Act2_2 = LeakyReLU()(Bn2_2)\n",
        "DO2_1 = Dropout(0.2)(Act2_2)\n",
        "Conv2_3 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same')(DO2_1)\n",
        "Bn2_3 = BatchNormalization()(Conv2_3)\n",
        "shortcut2_1 = Add()([Bn2_3, Max1_1])\n",
        "Bn2_4 = BatchNormalization()(shortcut2_1)\n",
        "Act2_3 = LeakyReLU()(Bn2_4)\n",
        "##### auxiliary\n",
        "Conv2_4 = Conv1D(filters=512, kernel_size=7, strides=2, padding='same')(Act2_3)\n",
        "Bn2_5 = BatchNormalization()(Conv2_4)\n",
        "Act2_4 = LeakyReLU()(Bn2_5)\n",
        "###############\n",
        "Max2_1 = MaxPooling1D(pool_size=5, strides=3)(Act2_4)\n",
        "\n",
        "\n",
        "\n",
        "Flat1 = Flatten()(Max2_1)\n",
        "\n",
        "D1 = Dense(256)(Flat1)\n",
        "A6 = LeakyReLU()(D1)\n",
        "D_O = Dropout(0.15)(A6)\n",
        "D2 = Dense(128)(D_O)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=A7)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 2999, 64)     384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 2999, 64)     36928       conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2999, 64)     256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 2999, 64)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 2999, 32)     14368       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 2999, 32)     128         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 2999, 32)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2999, 32)     0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 2999, 64)     18496       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2999, 64)     256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 2999, 64)     0           batch_normalization_2[0][0]      \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 2999, 64)     256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1000, 128)    57472       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1000, 128)    512         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 1000, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 498, 128)     0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 498, 256)     98560       max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 498, 256)     1024        conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 498, 256)     327936      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 498, 256)     1024        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 498, 256)     0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 498, 128)     98432       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 498, 128)     512         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 498, 128)     0           batch_normalization_7[0][0]      \n",
            "                                                                 max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 498, 128)     512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 498, 128)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 249, 512)     459264      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 249, 512)     2048        conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 249, 512)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 82, 512)      0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 41984)        0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          10748160    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5)            645         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 5)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,900,069\n",
            "Trainable params: 11,896,805\n",
            "Non-trainable params: 3,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSfZxMLK7xI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=1716,\n",
        "    decay_rate=0.6)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51SxpfQofzM",
        "colab_type": "code",
        "outputId": "f938f8b8-da42-4a70-eb9c-9cef1d9cad9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# overfitting so augment more data and decrease initial learning rate to 1e-3\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(XF_train, y_train, epochs=8, batch_size=64, validation_data=(XF_test, y_test), callbacks=[es_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "859/859 [==============================] - 7152s 8s/step - loss: 3.2613 - accuracy: 0.6755 - val_loss: 0.8381 - val_accuracy: 0.7604\n",
            "Epoch 2/8\n",
            "859/859 [==============================] - 7221s 8s/step - loss: 0.3369 - accuracy: 0.8850 - val_loss: 0.5860 - val_accuracy: 0.8089\n",
            "Epoch 3/8\n",
            "859/859 [==============================] - 8122s 9s/step - loss: 0.2603 - accuracy: 0.9135 - val_loss: 0.3346 - val_accuracy: 0.8747\n",
            "Epoch 4/8\n",
            "395/859 [============>.................] - ETA: 1:10:24 - loss: 0.2145 - accuracy: 0.9317"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUPC94zqTiE",
        "colab_type": "code",
        "outputId": "1db5eee5-aa5b-4b8e-c835-31440c378940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(XF_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"/content/drive/My Drive/Cardio/HeartBeat.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 87.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCecYVrhtbNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht3ltnGvtjlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}