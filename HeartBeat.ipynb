{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/alirezash97/Cardio/blob/master/HeartBeat.ipynb",
      "authorship_tag": "ABX9TyPxG5RvsUOsA6MP+8vl4Zg8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Cardio/blob/master/HeartBeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUFDobFVvj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"alirezashafaei97\",\"key\":\"9cb262aa0c5658ffc4eb45857c41903c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat -p /content\n",
        "!unzip /content/heartbeat.zip -d /content/heartbeat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sio7SWAwWBLj",
        "colab_type": "code",
        "outputId": "d1d438ff-c88f-4853-997d-2efb61842b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, LeakyReLU, Softmax, InputLayer, concatenate, Conv1D, MaxPool1D, Add, MaxPooling1D\n",
        " , Flatten, Dropout, ReLU, BatchNormalization, GlobalAveragePooling1D)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from random import uniform \n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTudiQO8WEXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/heartbeat/mitbih_test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfWxem7CTc50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del train_df\n",
        "# del test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58wFx5vXQS7",
        "colab_type": "code",
        "outputId": "3247438e-cf82-4a15-f4be-1ec6f3d1fd02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "counter=train_df[187].value_counts()\n",
        "print(counter)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQqNZG2q59y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=12000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=12000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=12000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=12000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=12000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomIXpkCrozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBctv4Tr58D",
        "colab_type": "code",
        "outputId": "83bd5e98-2661-45ef-9d1d-50d9aebd77dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    12000\n",
            "3    12000\n",
            "2    12000\n",
            "1    12000\n",
            "0    12000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3HJfHYr605",
        "colab_type": "code",
        "outputId": "28df7ed7-b391-4ce6-c906-201dd77c45fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\n",
        "c"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41749</th>\n",
              "      <td>0.934454</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.556303</td>\n",
              "      <td>0.166387</td>\n",
              "      <td>0.062185</td>\n",
              "      <td>0.015126</td>\n",
              "      <td>0.023529</td>\n",
              "      <td>0.026891</td>\n",
              "      <td>0.077311</td>\n",
              "      <td>0.203361</td>\n",
              "      <td>0.357983</td>\n",
              "      <td>0.431933</td>\n",
              "      <td>0.445378</td>\n",
              "      <td>0.462185</td>\n",
              "      <td>0.477311</td>\n",
              "      <td>0.472269</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.477311</td>\n",
              "      <td>0.468908</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.438655</td>\n",
              "      <td>0.438655</td>\n",
              "      <td>0.431933</td>\n",
              "      <td>0.413445</td>\n",
              "      <td>0.396639</td>\n",
              "      <td>0.394958</td>\n",
              "      <td>0.389916</td>\n",
              "      <td>0.378151</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.383193</td>\n",
              "      <td>0.393277</td>\n",
              "      <td>0.403361</td>\n",
              "      <td>0.415126</td>\n",
              "      <td>0.443697</td>\n",
              "      <td>0.465546</td>\n",
              "      <td>0.467227</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.504202</td>\n",
              "      <td>0.512605</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73611</th>\n",
              "      <td>0.907080</td>\n",
              "      <td>0.845133</td>\n",
              "      <td>0.243363</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048673</td>\n",
              "      <td>0.128319</td>\n",
              "      <td>0.132743</td>\n",
              "      <td>0.181416</td>\n",
              "      <td>0.163717</td>\n",
              "      <td>0.159292</td>\n",
              "      <td>0.207965</td>\n",
              "      <td>0.225664</td>\n",
              "      <td>0.296460</td>\n",
              "      <td>0.318584</td>\n",
              "      <td>0.300885</td>\n",
              "      <td>0.314159</td>\n",
              "      <td>0.340708</td>\n",
              "      <td>0.327434</td>\n",
              "      <td>0.323009</td>\n",
              "      <td>0.340708</td>\n",
              "      <td>0.323009</td>\n",
              "      <td>0.323009</td>\n",
              "      <td>0.340708</td>\n",
              "      <td>0.349558</td>\n",
              "      <td>0.336283</td>\n",
              "      <td>0.367257</td>\n",
              "      <td>0.402655</td>\n",
              "      <td>0.362832</td>\n",
              "      <td>0.393805</td>\n",
              "      <td>0.464602</td>\n",
              "      <td>0.477876</td>\n",
              "      <td>0.482301</td>\n",
              "      <td>0.508850</td>\n",
              "      <td>0.544248</td>\n",
              "      <td>0.570796</td>\n",
              "      <td>0.584071</td>\n",
              "      <td>0.575221</td>\n",
              "      <td>0.548673</td>\n",
              "      <td>0.535398</td>\n",
              "      <td>0.513274</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75447</th>\n",
              "      <td>0.759748</td>\n",
              "      <td>0.646541</td>\n",
              "      <td>0.353459</td>\n",
              "      <td>0.154717</td>\n",
              "      <td>0.064151</td>\n",
              "      <td>0.002516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045283</td>\n",
              "      <td>0.129560</td>\n",
              "      <td>0.194969</td>\n",
              "      <td>0.252830</td>\n",
              "      <td>0.337107</td>\n",
              "      <td>0.405031</td>\n",
              "      <td>0.432704</td>\n",
              "      <td>0.503145</td>\n",
              "      <td>0.591195</td>\n",
              "      <td>0.612579</td>\n",
              "      <td>0.597484</td>\n",
              "      <td>0.603774</td>\n",
              "      <td>0.610063</td>\n",
              "      <td>0.612579</td>\n",
              "      <td>0.626415</td>\n",
              "      <td>0.632704</td>\n",
              "      <td>0.638994</td>\n",
              "      <td>0.652830</td>\n",
              "      <td>0.665409</td>\n",
              "      <td>0.670440</td>\n",
              "      <td>0.685535</td>\n",
              "      <td>0.696855</td>\n",
              "      <td>0.708176</td>\n",
              "      <td>0.722013</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.742138</td>\n",
              "      <td>0.738365</td>\n",
              "      <td>0.728302</td>\n",
              "      <td>0.709434</td>\n",
              "      <td>0.696855</td>\n",
              "      <td>0.671698</td>\n",
              "      <td>0.642767</td>\n",
              "      <td>0.613836</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80819</th>\n",
              "      <td>0.852998</td>\n",
              "      <td>0.938104</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.980658</td>\n",
              "      <td>0.568665</td>\n",
              "      <td>0.284333</td>\n",
              "      <td>0.158607</td>\n",
              "      <td>0.123791</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.083172</td>\n",
              "      <td>0.065764</td>\n",
              "      <td>0.067698</td>\n",
              "      <td>0.054159</td>\n",
              "      <td>0.061896</td>\n",
              "      <td>0.046422</td>\n",
              "      <td>0.048356</td>\n",
              "      <td>0.027079</td>\n",
              "      <td>0.023211</td>\n",
              "      <td>0.015474</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.007737</td>\n",
              "      <td>0.001934</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.025145</td>\n",
              "      <td>0.046422</td>\n",
              "      <td>0.058027</td>\n",
              "      <td>0.083172</td>\n",
              "      <td>0.108317</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.166344</td>\n",
              "      <td>0.185687</td>\n",
              "      <td>0.172147</td>\n",
              "      <td>0.187621</td>\n",
              "      <td>0.177950</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.185687</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85399</th>\n",
              "      <td>0.728549</td>\n",
              "      <td>0.622465</td>\n",
              "      <td>0.505460</td>\n",
              "      <td>0.379095</td>\n",
              "      <td>0.251170</td>\n",
              "      <td>0.126365</td>\n",
              "      <td>0.056162</td>\n",
              "      <td>0.012480</td>\n",
              "      <td>0.026521</td>\n",
              "      <td>0.056162</td>\n",
              "      <td>0.176287</td>\n",
              "      <td>0.304212</td>\n",
              "      <td>0.347894</td>\n",
              "      <td>0.402496</td>\n",
              "      <td>0.477379</td>\n",
              "      <td>0.535101</td>\n",
              "      <td>0.588144</td>\n",
              "      <td>0.609984</td>\n",
              "      <td>0.642746</td>\n",
              "      <td>0.659906</td>\n",
              "      <td>0.670827</td>\n",
              "      <td>0.675507</td>\n",
              "      <td>0.681747</td>\n",
              "      <td>0.681747</td>\n",
              "      <td>0.694228</td>\n",
              "      <td>0.695788</td>\n",
              "      <td>0.712949</td>\n",
              "      <td>0.717629</td>\n",
              "      <td>0.734789</td>\n",
              "      <td>0.741030</td>\n",
              "      <td>0.764431</td>\n",
              "      <td>0.772231</td>\n",
              "      <td>0.800312</td>\n",
              "      <td>0.812793</td>\n",
              "      <td>0.843994</td>\n",
              "      <td>0.864275</td>\n",
              "      <td>0.892356</td>\n",
              "      <td>0.904836</td>\n",
              "      <td>0.909516</td>\n",
              "      <td>0.909516</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3    ...  184  185  186  187\n",
              "41749  0.934454  1.000000  0.556303  0.166387  ...  0.0  0.0  0.0    0\n",
              "73611  0.907080  0.845133  0.243363  0.000000  ...  0.0  0.0  0.0    1\n",
              "75447  0.759748  0.646541  0.353459  0.154717  ...  0.0  0.0  0.0    2\n",
              "80819  0.852998  0.938104  1.000000  0.980658  ...  0.0  0.0  0.0    3\n",
              "85399  0.728549  0.622465  0.505460  0.379095  ...  0.0  0.0  0.0    4\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB80IzMo1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_gaussian_noise(signal):\n",
        "    noise=np.random.normal(0,0.05,186)\n",
        "    return (signal+noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJB5fWu5sWNc",
        "colab_type": "code",
        "outputId": "7226fb1b-c9da-479b-8994-5ccee73ed70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tempo=c.iloc[0,:186]\n",
        "bruiter=add_gaussian_noise(tempo)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(c.iloc[0,:186])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(bruiter)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4fXuypr6vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUVlLpKPsQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values\n",
        "# X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
        "# X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexzfSPiD34D",
        "colab_type": "code",
        "outputId": "d340fb8c-8052-44dc-a1c6-6d9ebab53512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 186)\n",
            "(21892, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzROJp1Fr6q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "import pywt\n",
        "\n",
        "XF_train = np.zeros((X_train.shape[0], 9000))\n",
        "XF_test = np.zeros((X_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_train):\n",
        "  XF_train[index, :] = pywt.pad(row, 4407, 'periodic')\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_test):\n",
        "  XF_test[index, :] = pywt.pad(row, 4407, 'periodic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0aEgkhXamJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = train_df.values\n",
        "# testset = test_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Yu65s0adg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def split(dataset, number_of_sample_per_category):\n",
        "  \n",
        "#   new_dataset = np.zeros((np.sum(number_of_sample_per_category), dataset.shape[1]))\n",
        "#   pointer = 0\n",
        "  \n",
        "#   for row in dataset :\n",
        "    \n",
        "#     row_label = int(row[-1])\n",
        "    \n",
        "#     if number_of_sample_per_category[row_label] > 0 :\n",
        "      \n",
        "#       number_of_sample_per_category[row_label] -= 1\n",
        "#       new_dataset[pointer , :] = row\n",
        "#       pointer += 1\n",
        "\n",
        "#     else:\n",
        "\n",
        "#       pass\n",
        "    \n",
        "  \n",
        "#   return new_dataset\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTg8U_rCecMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# temp_trainset = split(trainset, [5500, 2223, 5500, 641, 5500])\n",
        "# temp_testset = split(testset, [500, 500, 500, 500, 500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VixGjo-J1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented = 0\n",
        "# def data_augmentation(dataset, chance):\n",
        "  \n",
        "#   augmented = 0\n",
        "#   number_of_rows = int(dataset.shape[0] + (dataset.shape[0] * (chance*2)))\n",
        "#   new_dataset = np.zeros((number_of_rows, dataset.shape[1]))\n",
        "#   pointer = 0 \n",
        "\n",
        "#   for row in dataset:\n",
        "    \n",
        "#     rand_num = random.uniform(0, 1)\n",
        "#     if rand_num < chance:\n",
        "      \n",
        "#       augmented += 1\n",
        "#       noise = np.random.normal(scale=0.01, size=187)\n",
        "#       new_signal = np.zeros((1, 188))\n",
        "#       new_signal[:, :187] = row[:187] + noise\n",
        "#       new_signal[:, -1:] = row[-1:] \n",
        "#       new_dataset[pointer:pointer+1, :] = new_signal\n",
        "#       pointer += 1\n",
        "\n",
        "#     else :\n",
        "#       pass\n",
        "\n",
        "#     new_dataset[pointer, :] = row \n",
        "#     pointer += 1\n",
        "\n",
        "#   return augmented, new_dataset  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-WNJJaSNYR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented, trainset = data_augmentation(temp_trainset, 0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEkQ1k_zRnYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filled = augmented + temp_trainset.shape[0]\n",
        "# trainset = trainset[:filled , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULVB16ONXuex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = np.take(trainset,np.random.permutation(trainset.shape[0]),axis=0,out=trainset)\n",
        "# testset = np.take(temp_testset,np.random.permutation(temp_testset.shape[0]),axis=0,out=temp_testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXpOUPpHYPQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_temp_train = trainset[:, :-1]\n",
        "# Y_train = trainset[:, -1:]\n",
        "# X_temp_test = testset[:, :-1]\n",
        "# Y_test = testset[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wSnYvXY6AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", XF_train.shape)\n",
        "# print(\"Y_train : \", y_train.shape)\n",
        "# print(\"X_test : \", XF_test.shape)\n",
        "# print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQP8dTlBZw6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# One Hot enoding for target labels \n",
        "# ohe = OneHotEncoder()\n",
        "# Y_train = ohe.fit_transform(Y_train.reshape(-1,1))\n",
        "# Y_test = ohe.transform(Y_test.reshape(-1,1))\n",
        "\n",
        "# # handle sparse matrix for keras \n",
        "# Y_train = csr_matrix.toarray(Y_train)\n",
        "# Y_test = csr_matrix.toarray(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBhFohZUarKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", X_temp_train.shape)\n",
        "# print(\"Y_train : \", Y_train.shape)\n",
        "# print(\"X_test : \", X_temp_test.shape)\n",
        "# print(\"Y_test : \", Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E525NqY3aGSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "# import pywt\n",
        "\n",
        "# XF_train = np.zeros((X_temp_train.shape[0], 9000))\n",
        "# XF_test = np.zeros((X_temp_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_train):\n",
        "#   XF_train[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_train[index, -1:] = 0\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   XF_test[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_test[index, -1:] = 0\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCEcchWo3cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index, row in enumerate(X_temp_train):\n",
        "#   X_temp_train[index] = add_gaussian_noise(row)\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   X_temp_test[index] = add_gaussian_noise(row)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmANeCYtjmgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XF_train = XF_train.reshape((60000, 9000, 1))\n",
        "XF_test = XF_test.reshape((21892, 9000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNvkTDCjyoA",
        "colab_type": "code",
        "outputId": "2ce8b1a9-4878-4820-8fe1-e4dc23063973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train : \", XF_train.shape)\n",
        "print(\"Y_train : \", y_train.shape)\n",
        "print(\"X_test : \", XF_test.shape)\n",
        "print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train :  (60000, 9000, 1)\n",
            "Y_train :  (60000, 5)\n",
            "X_test :  (21892, 9000, 1)\n",
            "Y_test :  (21892, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvIW2sWkaoP",
        "colab_type": "code",
        "outputId": "928524f0-debd-435e-b60d-5cc66d328f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_input = Input(shape=(9000, 1))\n",
        "Conv = Conv1D(filters=64, kernel_size=5, strides=3)(X_input)\n",
        "\n",
        "\n",
        "### step 1 \n",
        "\n",
        "Conv1_1 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(Conv)\n",
        "Bn1_1 = BatchNormalization()(Conv1_1)\n",
        "Act1_1 = LeakyReLU()(Bn1_1)\n",
        "Conv1_2 = Conv1D(filters=32, kernel_size=7, strides=1, padding='same')(Act1_1)\n",
        "Bn1_2 = BatchNormalization()(Conv1_2)\n",
        "Act1_2 = LeakyReLU()(Bn1_2)\n",
        "DO1_1 = Dropout(0.2)(Act1_2)\n",
        "Conv1_3 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(DO1_1)\n",
        "Bn1_3 = BatchNormalization()(Conv1_3)\n",
        "shortcut1_1 = Add()([Bn1_3, Conv])\n",
        "Bn1_4 = BatchNormalization()(shortcut1_1)\n",
        "Act1_3 = LeakyReLU()(Bn1_4)\n",
        "##### auxiliary\n",
        "Conv1_4 = Conv1D(filters=128, kernel_size=7, strides=3, padding='same')(Act1_3)\n",
        "Bn1_5 = BatchNormalization()(Conv1_4)\n",
        "Act1_4 = LeakyReLU()(Bn1_5)\n",
        "###############\n",
        "Max1_1 = MaxPooling1D(pool_size=5, strides=2)(Act1_4)\n",
        "\n",
        "\n",
        "## step 2\n",
        "\n",
        "Conv2_1 = Conv1D(filters=256, kernel_size=3, strides=1, padding='same')(Max1_1)\n",
        "Bn2_1 = BatchNormalization()(Conv2_1)\n",
        "Act2_1 = LeakyReLU()(Bn2_1)\n",
        "Conv2_2 = Conv1D(filters=256, kernel_size=5, strides=1, padding='same')(Act2_1)\n",
        "Bn2_2 = BatchNormalization()(Conv2_2)\n",
        "Act2_2 = LeakyReLU()(Bn2_2)\n",
        "DO2_1 = Dropout(0.2)(Act2_2)\n",
        "Conv2_3 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same')(DO2_1)\n",
        "Bn2_3 = BatchNormalization()(Conv2_3)\n",
        "shortcut2_1 = Add()([Bn2_3, Max1_1])\n",
        "Bn2_4 = BatchNormalization()(shortcut2_1)\n",
        "Act2_3 = LeakyReLU()(Bn2_4)\n",
        "##### auxiliary\n",
        "Conv2_4 = Conv1D(filters=512, kernel_size=7, strides=2, padding='same')(Act2_3)\n",
        "Bn2_5 = BatchNormalization()(Conv2_4)\n",
        "Act2_4 = LeakyReLU()(Bn2_5)\n",
        "###############\n",
        "Max2_1 = MaxPooling1D(pool_size=5, strides=3)(Act2_4)\n",
        "\n",
        "\n",
        "\n",
        "Flat1 = Flatten()(Max2_1)\n",
        "\n",
        "D1 = Dense(256)(Flat1)\n",
        "A6 = LeakyReLU()(D1)\n",
        "D_O = Dropout(0.15)(A6)\n",
        "D2 = Dense(128)(D_O)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=A7)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 2999, 64)     384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 2999, 64)     36928       conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2999, 64)     256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 2999, 64)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 2999, 32)     14368       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 2999, 32)     128         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 2999, 32)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2999, 32)     0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 2999, 64)     18496       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2999, 64)     256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 2999, 64)     0           batch_normalization_2[0][0]      \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 2999, 64)     256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1000, 128)    57472       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1000, 128)    512         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 1000, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 498, 128)     0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 498, 256)     98560       max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 498, 256)     1024        conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 498, 256)     327936      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 498, 256)     1024        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 498, 256)     0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 498, 128)     98432       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 498, 128)     512         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 498, 128)     0           batch_normalization_7[0][0]      \n",
            "                                                                 max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 498, 128)     512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 498, 128)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 249, 512)     459264      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 249, 512)     2048        conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 249, 512)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 82, 512)      0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 41984)        0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          10748160    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5)            645         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 5)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,900,069\n",
            "Trainable params: 11,896,805\n",
            "Non-trainable params: 3,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSfZxMLK7xI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=1407,\n",
        "    decay_rate=0.8)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51SxpfQofzM",
        "colab_type": "code",
        "outputId": "eeb90289-d518-414f-e651-22a8a046bf6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# overfitting so augment more data and decrease initial learning rate to 1e-3\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(XF_train, y_train, epochs=10, batch_size=64, validation_data=(XF_test, y_test), callbacks=[es_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 7035s 7s/step - loss: 2.9440 - accuracy: 0.7039 - val_loss: 0.2537 - val_accuracy: 0.9215\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 7004s 7s/step - loss: 0.3100 - accuracy: 0.8920 - val_loss: 0.5702 - val_accuracy: 0.7953\n",
            "Epoch 3/10\n",
            "933/938 [============================>.] - ETA: 34s - loss: 0.2649 - accuracy: 0.9150"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUPC94zqTiE",
        "colab_type": "code",
        "outputId": "1db5eee5-aa5b-4b8e-c835-31440c378940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(XF_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"/content/drive/My Drive/Cardio/HeartBeat.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 87.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCecYVrhtbNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht3ltnGvtjlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}