{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/alirezash97/Cardio/blob/master/HeartBeat.ipynb",
      "authorship_tag": "ABX9TyM7BZXvF9iUqVKnBWIeuaGu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Cardio/blob/master/HeartBeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUFDobFVvj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"alirezashafaei97\",\"key\":\"9cb262aa0c5658ffc4eb45857c41903c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat -p /content\n",
        "!unzip /content/heartbeat.zip -d /content/heartbeat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sio7SWAwWBLj",
        "colab_type": "code",
        "outputId": "d3f3bfaf-f3e9-4466-fa1d-db69345d8afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, LeakyReLU, Softmax, InputLayer, concatenate, Conv1D, MaxPool1D, Add, MaxPooling1D\n",
        " , Flatten, Dropout, ReLU, BatchNormalization, GlobalAveragePooling1D)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from random import uniform \n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTudiQO8WEXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/heartbeat/mitbih_test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfWxem7CTc50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del train_df\n",
        "# del test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58wFx5vXQS7",
        "colab_type": "code",
        "outputId": "9d11e6da-257e-4f05-a6f8-e5ad36797e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "counter=train_df[187].value_counts()\n",
        "print(counter)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQqNZG2q59y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=10000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=10000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=10000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=10000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=10000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomIXpkCrozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBctv4Tr58D",
        "colab_type": "code",
        "outputId": "84bfb2a4-47d2-4a8f-f59b-5141e3451e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    10000\n",
            "3    10000\n",
            "2    10000\n",
            "1    10000\n",
            "0    10000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3HJfHYr605",
        "colab_type": "code",
        "outputId": "2ab68eb5-0a51-4d67-a2fd-35bbbbbf1131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\n",
        "c"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5510</th>\n",
              "      <td>0.894231</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.525641</td>\n",
              "      <td>0.330128</td>\n",
              "      <td>0.368590</td>\n",
              "      <td>0.368590</td>\n",
              "      <td>0.336538</td>\n",
              "      <td>0.413462</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>0.195513</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.227564</td>\n",
              "      <td>0.227564</td>\n",
              "      <td>0.237179</td>\n",
              "      <td>0.272436</td>\n",
              "      <td>0.298077</td>\n",
              "      <td>0.323718</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.381410</td>\n",
              "      <td>0.391026</td>\n",
              "      <td>0.480769</td>\n",
              "      <td>0.522436</td>\n",
              "      <td>0.544872</td>\n",
              "      <td>0.519231</td>\n",
              "      <td>0.544872</td>\n",
              "      <td>0.535256</td>\n",
              "      <td>0.522436</td>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.471154</td>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.490385</td>\n",
              "      <td>0.378205</td>\n",
              "      <td>0.464744</td>\n",
              "      <td>0.439103</td>\n",
              "      <td>0.323718</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.477564</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73836</th>\n",
              "      <td>0.990017</td>\n",
              "      <td>0.737105</td>\n",
              "      <td>0.098170</td>\n",
              "      <td>0.108153</td>\n",
              "      <td>0.299501</td>\n",
              "      <td>0.312812</td>\n",
              "      <td>0.326123</td>\n",
              "      <td>0.327787</td>\n",
              "      <td>0.322795</td>\n",
              "      <td>0.319468</td>\n",
              "      <td>0.311148</td>\n",
              "      <td>0.314476</td>\n",
              "      <td>0.321131</td>\n",
              "      <td>0.321131</td>\n",
              "      <td>0.312812</td>\n",
              "      <td>0.324459</td>\n",
              "      <td>0.327787</td>\n",
              "      <td>0.322795</td>\n",
              "      <td>0.329451</td>\n",
              "      <td>0.337770</td>\n",
              "      <td>0.351082</td>\n",
              "      <td>0.349418</td>\n",
              "      <td>0.342762</td>\n",
              "      <td>0.357737</td>\n",
              "      <td>0.382695</td>\n",
              "      <td>0.407654</td>\n",
              "      <td>0.417637</td>\n",
              "      <td>0.424293</td>\n",
              "      <td>0.440932</td>\n",
              "      <td>0.435940</td>\n",
              "      <td>0.407654</td>\n",
              "      <td>0.396007</td>\n",
              "      <td>0.399334</td>\n",
              "      <td>0.399334</td>\n",
              "      <td>0.399334</td>\n",
              "      <td>0.399334</td>\n",
              "      <td>0.391015</td>\n",
              "      <td>0.371048</td>\n",
              "      <td>0.351082</td>\n",
              "      <td>0.341098</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77360</th>\n",
              "      <td>0.982097</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.716113</td>\n",
              "      <td>0.396419</td>\n",
              "      <td>0.281330</td>\n",
              "      <td>0.296675</td>\n",
              "      <td>0.212276</td>\n",
              "      <td>0.107417</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025575</td>\n",
              "      <td>0.056266</td>\n",
              "      <td>0.132992</td>\n",
              "      <td>0.166240</td>\n",
              "      <td>0.222506</td>\n",
              "      <td>0.230179</td>\n",
              "      <td>0.271100</td>\n",
              "      <td>0.245524</td>\n",
              "      <td>0.265985</td>\n",
              "      <td>0.301790</td>\n",
              "      <td>0.329923</td>\n",
              "      <td>0.322251</td>\n",
              "      <td>0.355499</td>\n",
              "      <td>0.329923</td>\n",
              "      <td>0.327366</td>\n",
              "      <td>0.332481</td>\n",
              "      <td>0.322251</td>\n",
              "      <td>0.301790</td>\n",
              "      <td>0.324808</td>\n",
              "      <td>0.306905</td>\n",
              "      <td>0.306905</td>\n",
              "      <td>0.324808</td>\n",
              "      <td>0.324808</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.276215</td>\n",
              "      <td>0.245524</td>\n",
              "      <td>0.255754</td>\n",
              "      <td>0.237852</td>\n",
              "      <td>0.263427</td>\n",
              "      <td>0.222506</td>\n",
              "      <td>0.237852</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80980</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.856742</td>\n",
              "      <td>0.632023</td>\n",
              "      <td>0.331461</td>\n",
              "      <td>0.091292</td>\n",
              "      <td>0.091292</td>\n",
              "      <td>0.098315</td>\n",
              "      <td>0.066011</td>\n",
              "      <td>0.057584</td>\n",
              "      <td>0.040730</td>\n",
              "      <td>0.030899</td>\n",
              "      <td>0.030899</td>\n",
              "      <td>0.014045</td>\n",
              "      <td>0.005618</td>\n",
              "      <td>0.005618</td>\n",
              "      <td>0.001404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001404</td>\n",
              "      <td>0.004213</td>\n",
              "      <td>0.022472</td>\n",
              "      <td>0.030899</td>\n",
              "      <td>0.036517</td>\n",
              "      <td>0.067416</td>\n",
              "      <td>0.089888</td>\n",
              "      <td>0.120787</td>\n",
              "      <td>0.155899</td>\n",
              "      <td>0.189607</td>\n",
              "      <td>0.224719</td>\n",
              "      <td>0.251404</td>\n",
              "      <td>0.271067</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.320225</td>\n",
              "      <td>0.327247</td>\n",
              "      <td>0.328652</td>\n",
              "      <td>0.320225</td>\n",
              "      <td>0.317416</td>\n",
              "      <td>0.297753</td>\n",
              "      <td>0.273876</td>\n",
              "      <td>0.269663</td>\n",
              "      <td>0.241573</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83491</th>\n",
              "      <td>0.880546</td>\n",
              "      <td>0.532423</td>\n",
              "      <td>0.518771</td>\n",
              "      <td>0.491468</td>\n",
              "      <td>0.457338</td>\n",
              "      <td>0.406143</td>\n",
              "      <td>0.365188</td>\n",
              "      <td>0.303754</td>\n",
              "      <td>0.232082</td>\n",
              "      <td>0.095563</td>\n",
              "      <td>0.037543</td>\n",
              "      <td>0.010239</td>\n",
              "      <td>0.030717</td>\n",
              "      <td>0.030717</td>\n",
              "      <td>0.088737</td>\n",
              "      <td>0.160410</td>\n",
              "      <td>0.245734</td>\n",
              "      <td>0.317406</td>\n",
              "      <td>0.365188</td>\n",
              "      <td>0.385666</td>\n",
              "      <td>0.430034</td>\n",
              "      <td>0.443686</td>\n",
              "      <td>0.443686</td>\n",
              "      <td>0.467577</td>\n",
              "      <td>0.494881</td>\n",
              "      <td>0.501706</td>\n",
              "      <td>0.511945</td>\n",
              "      <td>0.501706</td>\n",
              "      <td>0.501706</td>\n",
              "      <td>0.501706</td>\n",
              "      <td>0.505119</td>\n",
              "      <td>0.505119</td>\n",
              "      <td>0.515358</td>\n",
              "      <td>0.511945</td>\n",
              "      <td>0.518771</td>\n",
              "      <td>0.522184</td>\n",
              "      <td>0.535836</td>\n",
              "      <td>0.539249</td>\n",
              "      <td>0.549488</td>\n",
              "      <td>0.542662</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3    ...  184  185  186  187\n",
              "5510   0.894231  0.788462  0.525641  0.330128  ...  0.0  0.0  0.0    0\n",
              "73836  0.990017  0.737105  0.098170  0.108153  ...  0.0  0.0  0.0    1\n",
              "77360  0.982097  1.000000  0.716113  0.396419  ...  0.0  0.0  0.0    2\n",
              "80980  1.000000  0.856742  0.632023  0.331461  ...  0.0  0.0  0.0    3\n",
              "83491  0.880546  0.532423  0.518771  0.491468  ...  0.0  0.0  0.0    4\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB80IzMo1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_gaussian_noise(signal):\n",
        "    noise=np.random.normal(0,0.05,186)\n",
        "    return (signal+noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJB5fWu5sWNc",
        "colab_type": "code",
        "outputId": "3dd8c261-24ac-4611-d9cc-67a276d863a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tempo=c.iloc[0,:186]\n",
        "bruiter=add_gaussian_noise(tempo)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(c.iloc[0,:186])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(bruiter)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4fXuypr6vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUVlLpKPsQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values\n",
        "# X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
        "# X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexzfSPiD34D",
        "colab_type": "code",
        "outputId": "6a3158ae-bce0-4267-b415-e0e967a40c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 186)\n",
            "(21892, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPfQkUVfnTx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data augmentation\n",
        "\n",
        "def augmetation(X_train, y_train, chance):\n",
        "\n",
        "  augment_number = 0\n",
        "  XF_train = np.zeros((X_train.shape[0]*2, X_train.shape[1]))\n",
        "  yf_train = np.zeros((y_train.shape[0]*2, y_train.shape[1]))\n",
        "  pointer = 0\n",
        "  for index, row in enumerate(X_train):\n",
        "\n",
        "    XF_train[pointer, :] = row\n",
        "    yf_train[pointer, :] = y_train[index, :]\n",
        "    pointer += 1\n",
        "\n",
        "    rand_num = random.uniform(0, 1)      \n",
        "    if chance > rand_num :\n",
        "\n",
        "      augment_number += 1\n",
        "      noise = np.random.normal(0,0.05,186)\n",
        "      new_signal = row + noise  \n",
        "      XF_train[pointer, :] = new_signal\n",
        "      yf_train[pointer, :] = y_train[index, :]\n",
        "      pointer += 1\n",
        "\n",
        "      filled = X_train.shape[0] + augment_number\n",
        "      XFF_train = XF_train[:filled, :]\n",
        "      yff_train = yf_train[:filled, :]\n",
        "\n",
        "    \n",
        "  return XFF_train, yff_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dXhm8thnj1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = augmetation(X_train, y_train, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzROJp1Fr6q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "import pywt\n",
        "\n",
        "XF_train = np.zeros((X_train.shape[0], 9000))\n",
        "XF_test = np.zeros((X_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_train):\n",
        "  XF_train[index, :] = pywt.pad(row, 4407, 'periodic')\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_test):\n",
        "  XF_test[index, :] = pywt.pad(row, 4407, 'periodic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0aEgkhXamJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = train_df.values\n",
        "# testset = test_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Yu65s0adg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def split(dataset, number_of_sample_per_category):\n",
        "  \n",
        "#   new_dataset = np.zeros((np.sum(number_of_sample_per_category), dataset.shape[1]))\n",
        "#   pointer = 0\n",
        "  \n",
        "#   for row in dataset :\n",
        "    \n",
        "#     row_label = int(row[-1])\n",
        "    \n",
        "#     if number_of_sample_per_category[row_label] > 0 :\n",
        "      \n",
        "#       number_of_sample_per_category[row_label] -= 1\n",
        "#       new_dataset[pointer , :] = row\n",
        "#       pointer += 1\n",
        "\n",
        "#     else:\n",
        "\n",
        "#       pass\n",
        "    \n",
        "  \n",
        "#   return new_dataset\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTg8U_rCecMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# temp_trainset = split(trainset, [5500, 2223, 5500, 641, 5500])\n",
        "# temp_testset = split(testset, [500, 500, 500, 500, 500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VixGjo-J1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented = 0\n",
        "# def data_augmentation(dataset, chance):\n",
        "  \n",
        "#   augmented = 0\n",
        "#   number_of_rows = int(dataset.shape[0] + (dataset.shape[0] * (chance*2)))\n",
        "#   new_dataset = np.zeros((number_of_rows, dataset.shape[1]))\n",
        "#   pointer = 0 \n",
        "\n",
        "#   for row in dataset:\n",
        "    \n",
        "#     rand_num = random.uniform(0, 1)\n",
        "#     if rand_num < chance:\n",
        "      \n",
        "#       augmented += 1\n",
        "#       noise = np.random.normal(scale=0.01, size=187)\n",
        "#       new_signal = np.zeros((1, 188))\n",
        "#       new_signal[:, :187] = row[:187] + noise\n",
        "#       new_signal[:, -1:] = row[-1:] \n",
        "#       new_dataset[pointer:pointer+1, :] = new_signal\n",
        "#       pointer += 1\n",
        "\n",
        "#     else :\n",
        "#       pass\n",
        "\n",
        "#     new_dataset[pointer, :] = row \n",
        "#     pointer += 1\n",
        "\n",
        "#   return augmented, new_dataset  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-WNJJaSNYR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented, trainset = data_augmentation(temp_trainset, 0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEkQ1k_zRnYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filled = augmented + temp_trainset.shape[0]\n",
        "# trainset = trainset[:filled , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULVB16ONXuex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = np.take(trainset,np.random.permutation(trainset.shape[0]),axis=0,out=trainset)\n",
        "# testset = np.take(temp_testset,np.random.permutation(temp_testset.shape[0]),axis=0,out=temp_testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXpOUPpHYPQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_temp_train = trainset[:, :-1]\n",
        "# Y_train = trainset[:, -1:]\n",
        "# X_temp_test = testset[:, :-1]\n",
        "# Y_test = testset[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wSnYvXY6AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", XF_train.shape)\n",
        "# print(\"Y_train : \", y_train.shape)\n",
        "# print(\"X_test : \", XF_test.shape)\n",
        "# print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQP8dTlBZw6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# One Hot enoding for target labels \n",
        "# ohe = OneHotEncoder()\n",
        "# Y_train = ohe.fit_transform(Y_train.reshape(-1,1))\n",
        "# Y_test = ohe.transform(Y_test.reshape(-1,1))\n",
        "\n",
        "# # handle sparse matrix for keras \n",
        "# Y_train = csr_matrix.toarray(Y_train)\n",
        "# Y_test = csr_matrix.toarray(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBhFohZUarKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", X_temp_train.shape)\n",
        "# print(\"Y_train : \", Y_train.shape)\n",
        "# print(\"X_test : \", X_temp_test.shape)\n",
        "# print(\"Y_test : \", Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E525NqY3aGSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "# import pywt\n",
        "\n",
        "# XF_train = np.zeros((X_temp_train.shape[0], 9000))\n",
        "# XF_test = np.zeros((X_temp_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_train):\n",
        "#   XF_train[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_train[index, -1:] = 0\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   XF_test[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_test[index, -1:] = 0\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCEcchWo3cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index, row in enumerate(X_temp_train):\n",
        "#   X_temp_train[index] = add_gaussian_noise(row)\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   X_temp_test[index] = add_gaussian_noise(row)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmANeCYtjmgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XF_train = XF_train.reshape((XF_train.shape[0], 9000, 1))\n",
        "XF_test = XF_test.reshape((21892, 9000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNvkTDCjyoA",
        "colab_type": "code",
        "outputId": "39980388-6687-4d2d-fa60-3b1f1a382b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train : \", XF_train.shape)\n",
        "print(\"Y_train : \", y_train.shape)\n",
        "print(\"X_test : \", XF_test.shape)\n",
        "print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train :  (55012, 9000, 1)\n",
            "Y_train :  (55012, 5)\n",
            "X_test :  (21892, 9000, 1)\n",
            "Y_test :  (21892, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvIW2sWkaoP",
        "colab_type": "code",
        "outputId": "b4dbbc26-975f-4548-9458-2312da4f0a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_input = Input(shape=(9000, 1))\n",
        "Conv = Conv1D(filters=64, kernel_size=5, strides=3)(X_input)\n",
        "\n",
        "\n",
        "### step 1 \n",
        "\n",
        "Conv1_1 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(Conv)\n",
        "Bn1_1 = BatchNormalization()(Conv1_1)\n",
        "Act1_1 = LeakyReLU()(Bn1_1)\n",
        "Conv1_2 = Conv1D(filters=64, kernel_size=7, strides=1, padding='same')(Act1_1)\n",
        "Bn1_2 = BatchNormalization()(Conv1_2)\n",
        "Act1_2 = LeakyReLU()(Bn1_2)\n",
        "DO1_1 = Dropout(0.2)(Act1_2)\n",
        "Conv1_3 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(DO1_1)\n",
        "Bn1_3 = BatchNormalization()(Conv1_3)\n",
        "shortcut1_1 = Add()([Bn1_3, Conv])\n",
        "Bn1_4 = BatchNormalization()(shortcut1_1)\n",
        "Act1_3 = LeakyReLU()(Bn1_4)\n",
        "##### auxiliary\n",
        "Conv1_4 = Conv1D(filters=128, kernel_size=7, strides=3, padding='same')(Act1_3)\n",
        "Bn1_5 = BatchNormalization()(Conv1_4)\n",
        "Act1_4 = LeakyReLU()(Bn1_5)\n",
        "###############\n",
        "Max1_1 = MaxPooling1D(pool_size=5, strides=2)(Act1_4)\n",
        "\n",
        "\n",
        "## step 2\n",
        "\n",
        "Conv2_1 = Conv1D(filters=256, kernel_size=3, strides=1, padding='same')(Max1_1)\n",
        "Bn2_1 = BatchNormalization()(Conv2_1)\n",
        "Act2_1 = LeakyReLU()(Bn2_1)\n",
        "Conv2_2 = Conv1D(filters=256, kernel_size=5, strides=1, padding='same')(Act2_1)\n",
        "Bn2_2 = BatchNormalization()(Conv2_2)\n",
        "Act2_2 = LeakyReLU()(Bn2_2)\n",
        "DO2_1 = Dropout(0.2)(Act2_2)\n",
        "Conv2_3 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same')(DO2_1)\n",
        "Bn2_3 = BatchNormalization()(Conv2_3)\n",
        "shortcut2_1 = Add()([Bn2_3, Max1_1])\n",
        "Bn2_4 = BatchNormalization()(shortcut2_1)\n",
        "Act2_3 = LeakyReLU()(Bn2_4)\n",
        "##### auxiliary\n",
        "Conv2_4 = Conv1D(filters=512, kernel_size=7, strides=2, padding='same')(Act2_3)\n",
        "Bn2_5 = BatchNormalization()(Conv2_4)\n",
        "Act2_4 = LeakyReLU()(Bn2_5)\n",
        "###############\n",
        "Max2_1 = MaxPooling1D(pool_size=5, strides=3)(Act2_4)\n",
        "\n",
        "\n",
        "\n",
        "Flat1 = Flatten()(Max2_1)\n",
        "\n",
        "D1 = Dense(256)(Flat1)\n",
        "A6 = LeakyReLU()(D1)\n",
        "D_O = Dropout(0.15)(A6)\n",
        "D2 = Dense(128)(D_O)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=A7)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 2999, 64)     384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 2999, 64)     36928       conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2999, 64)     256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 2999, 64)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 2999, 64)     28736       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 2999, 64)     256         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2999, 64)     0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 2999, 64)     36928       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2999, 64)     256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 2999, 64)     0           batch_normalization_2[0][0]      \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 2999, 64)     256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1000, 128)    57472       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1000, 128)    512         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 1000, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 498, 128)     0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 498, 256)     98560       max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 498, 256)     1024        conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 498, 256)     327936      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 498, 256)     1024        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 498, 256)     0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 498, 128)     98432       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 498, 128)     512         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 498, 128)     0           batch_normalization_7[0][0]      \n",
            "                                                                 max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 498, 128)     512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 498, 128)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 249, 512)     459264      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 249, 512)     2048        conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 249, 512)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 82, 512)      0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 41984)        0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          10748160    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5)            645         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 5)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,932,997\n",
            "Trainable params: 11,929,669\n",
            "Non-trainable params: 3,328\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSfZxMLK7xI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=1719,\n",
        "    decay_rate=0.7)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51SxpfQofzM",
        "colab_type": "code",
        "outputId": "2763ad2f-481c-4ee8-be81-10007d2567c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# overfitting so augment more data and decrease initial learning rate to 1e-3\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(XF_train, y_train, epochs=7, batch_size=64, validation_data=(XF_test, y_test), callbacks=[es_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "860/860 [==============================] - 7778s 9s/step - loss: 3.8281 - accuracy: 0.6426 - val_loss: 0.3030 - val_accuracy: 0.9246\n",
            "Epoch 2/7\n",
            "860/860 [==============================] - 8050s 9s/step - loss: 0.3551 - accuracy: 0.8814 - val_loss: 0.3695 - val_accuracy: 0.8722\n",
            "Epoch 3/7\n",
            "860/860 [==============================] - 8033s 9s/step - loss: 0.2365 - accuracy: 0.9176 - val_loss: 0.2716 - val_accuracy: 0.9079\n",
            "Epoch 4/7\n",
            "860/860 [==============================] - 8097s 9s/step - loss: 0.2672 - accuracy: 0.9205 - val_loss: 0.2414 - val_accuracy: 0.9203\n",
            "Epoch 5/7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUPC94zqTiE",
        "colab_type": "code",
        "outputId": "15e76721-375a-4993-e207-30055522d4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(XF_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"/content/drive/My Drive/Cardio/HeartBeat.h5\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-78fb4bd29953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXF_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# save model and architecture to single file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCecYVrhtbNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht3ltnGvtjlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}