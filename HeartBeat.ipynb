{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOGM1M+RE3MTuQMMjCiRf7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Cardio/blob/master/HeartBeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUFDobFVvj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"alirezashafaei97\",\"key\":\"9cb262aa0c5658ffc4eb45857c41903c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat -p /content\n",
        "!unzip /content/heartbeat.zip -d /content/heartbeat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sio7SWAwWBLj",
        "colab_type": "code",
        "outputId": "11ec05df-7bb1-4ab1-8d19-43b3408c2cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, LeakyReLU, Softmax, InputLayer, concatenate, Conv1D, MaxPool1D, Add, MaxPooling1D\n",
        " , Flatten, Dropout, ReLU, BatchNormalization, GlobalAveragePooling1D)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from random import uniform \n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTudiQO8WEXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/heartbeat/mitbih_test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58wFx5vXQS7",
        "colab_type": "code",
        "outputId": "c862c344-6e99-4420-b4ef-6bb8b2327e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "counter=train_df[187].value_counts()\n",
        "print(counter)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQqNZG2q59y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=10000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=10000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=10000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=10000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=10000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomIXpkCrozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBctv4Tr58D",
        "colab_type": "code",
        "outputId": "c788f278-9d6e-4c26-9397-afcc16d48d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    10000\n",
            "3    10000\n",
            "2    10000\n",
            "1    10000\n",
            "0    10000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3HJfHYr605",
        "colab_type": "code",
        "outputId": "af7a3ee7-fbf0-446d-fb7d-f5c687b5183d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\n",
        "c"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39645</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860082</td>\n",
              "      <td>0.493827</td>\n",
              "      <td>0.078189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.172840</td>\n",
              "      <td>0.242798</td>\n",
              "      <td>0.271605</td>\n",
              "      <td>0.288066</td>\n",
              "      <td>0.275720</td>\n",
              "      <td>0.267490</td>\n",
              "      <td>0.279835</td>\n",
              "      <td>0.292181</td>\n",
              "      <td>0.275720</td>\n",
              "      <td>0.246914</td>\n",
              "      <td>0.271605</td>\n",
              "      <td>0.259259</td>\n",
              "      <td>0.255144</td>\n",
              "      <td>0.238683</td>\n",
              "      <td>0.255144</td>\n",
              "      <td>0.263374</td>\n",
              "      <td>0.251029</td>\n",
              "      <td>0.226337</td>\n",
              "      <td>0.242798</td>\n",
              "      <td>0.246914</td>\n",
              "      <td>0.209877</td>\n",
              "      <td>0.218107</td>\n",
              "      <td>0.230453</td>\n",
              "      <td>0.226337</td>\n",
              "      <td>0.226337</td>\n",
              "      <td>0.218107</td>\n",
              "      <td>0.251029</td>\n",
              "      <td>0.267490</td>\n",
              "      <td>0.288066</td>\n",
              "      <td>0.308642</td>\n",
              "      <td>0.362140</td>\n",
              "      <td>0.411523</td>\n",
              "      <td>0.436214</td>\n",
              "      <td>0.456790</td>\n",
              "      <td>0.502058</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74350</th>\n",
              "      <td>0.867188</td>\n",
              "      <td>0.746094</td>\n",
              "      <td>0.191406</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054688</td>\n",
              "      <td>0.121094</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.066406</td>\n",
              "      <td>0.148438</td>\n",
              "      <td>0.140625</td>\n",
              "      <td>0.164062</td>\n",
              "      <td>0.183594</td>\n",
              "      <td>0.234375</td>\n",
              "      <td>0.277344</td>\n",
              "      <td>0.300781</td>\n",
              "      <td>0.304688</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.304688</td>\n",
              "      <td>0.339844</td>\n",
              "      <td>0.332031</td>\n",
              "      <td>0.285156</td>\n",
              "      <td>0.269531</td>\n",
              "      <td>0.320312</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.332031</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.351562</td>\n",
              "      <td>0.351562</td>\n",
              "      <td>0.351562</td>\n",
              "      <td>0.402344</td>\n",
              "      <td>0.445312</td>\n",
              "      <td>0.421875</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.546875</td>\n",
              "      <td>0.546875</td>\n",
              "      <td>0.507812</td>\n",
              "      <td>0.507812</td>\n",
              "      <td>0.507812</td>\n",
              "      <td>...</td>\n",
              "      <td>0.316406</td>\n",
              "      <td>0.3125</td>\n",
              "      <td>0.335938</td>\n",
              "      <td>0.332031</td>\n",
              "      <td>0.34375</td>\n",
              "      <td>0.324219</td>\n",
              "      <td>0.300781</td>\n",
              "      <td>0.320312</td>\n",
              "      <td>0.324219</td>\n",
              "      <td>0.347656</td>\n",
              "      <td>0.347656</td>\n",
              "      <td>0.316406</td>\n",
              "      <td>0.308594</td>\n",
              "      <td>0.320312</td>\n",
              "      <td>0.355469</td>\n",
              "      <td>0.359375</td>\n",
              "      <td>0.324219</td>\n",
              "      <td>0.320312</td>\n",
              "      <td>0.332031</td>\n",
              "      <td>0.335938</td>\n",
              "      <td>0.316406</td>\n",
              "      <td>0.335938</td>\n",
              "      <td>0.339844</td>\n",
              "      <td>0.320312</td>\n",
              "      <td>0.316406</td>\n",
              "      <td>0.347656</td>\n",
              "      <td>0.339844</td>\n",
              "      <td>0.3125</td>\n",
              "      <td>0.316406</td>\n",
              "      <td>0.335938</td>\n",
              "      <td>0.347656</td>\n",
              "      <td>0.355469</td>\n",
              "      <td>0.300781</td>\n",
              "      <td>0.324219</td>\n",
              "      <td>0.351562</td>\n",
              "      <td>0.347656</td>\n",
              "      <td>0.347656</td>\n",
              "      <td>0.347656</td>\n",
              "      <td>0.339844</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76751</th>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.919328</td>\n",
              "      <td>0.621849</td>\n",
              "      <td>0.189916</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043697</td>\n",
              "      <td>0.107563</td>\n",
              "      <td>0.168067</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>0.302521</td>\n",
              "      <td>0.289076</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.304202</td>\n",
              "      <td>0.300840</td>\n",
              "      <td>0.297479</td>\n",
              "      <td>0.290756</td>\n",
              "      <td>0.299160</td>\n",
              "      <td>0.300840</td>\n",
              "      <td>0.295798</td>\n",
              "      <td>0.287395</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.289076</td>\n",
              "      <td>0.280672</td>\n",
              "      <td>0.280672</td>\n",
              "      <td>0.302521</td>\n",
              "      <td>0.299160</td>\n",
              "      <td>0.297479</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.334454</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.368067</td>\n",
              "      <td>0.373109</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.389916</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.378151</td>\n",
              "      <td>0.373109</td>\n",
              "      <td>0.366387</td>\n",
              "      <td>0.361345</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81080</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.938406</td>\n",
              "      <td>0.527174</td>\n",
              "      <td>0.240942</td>\n",
              "      <td>0.148551</td>\n",
              "      <td>0.115942</td>\n",
              "      <td>0.106884</td>\n",
              "      <td>0.077899</td>\n",
              "      <td>0.077899</td>\n",
              "      <td>0.067029</td>\n",
              "      <td>0.074275</td>\n",
              "      <td>0.059783</td>\n",
              "      <td>0.065217</td>\n",
              "      <td>0.057971</td>\n",
              "      <td>0.063406</td>\n",
              "      <td>0.045290</td>\n",
              "      <td>0.048913</td>\n",
              "      <td>0.027174</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.019928</td>\n",
              "      <td>0.032609</td>\n",
              "      <td>0.025362</td>\n",
              "      <td>0.036232</td>\n",
              "      <td>0.036232</td>\n",
              "      <td>0.059783</td>\n",
              "      <td>0.057971</td>\n",
              "      <td>0.088768</td>\n",
              "      <td>0.099638</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.141304</td>\n",
              "      <td>0.168478</td>\n",
              "      <td>0.161232</td>\n",
              "      <td>0.170290</td>\n",
              "      <td>0.153986</td>\n",
              "      <td>0.163043</td>\n",
              "      <td>0.155797</td>\n",
              "      <td>0.159420</td>\n",
              "      <td>0.150362</td>\n",
              "      <td>0.159420</td>\n",
              "      <td>0.153986</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85773</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.940414</td>\n",
              "      <td>0.873057</td>\n",
              "      <td>0.812176</td>\n",
              "      <td>0.731865</td>\n",
              "      <td>0.623057</td>\n",
              "      <td>0.515544</td>\n",
              "      <td>0.413212</td>\n",
              "      <td>0.325130</td>\n",
              "      <td>0.283679</td>\n",
              "      <td>0.244819</td>\n",
              "      <td>0.161917</td>\n",
              "      <td>0.072539</td>\n",
              "      <td>0.014249</td>\n",
              "      <td>0.090674</td>\n",
              "      <td>0.183938</td>\n",
              "      <td>0.237047</td>\n",
              "      <td>0.251295</td>\n",
              "      <td>0.266839</td>\n",
              "      <td>0.272021</td>\n",
              "      <td>0.306995</td>\n",
              "      <td>0.351036</td>\n",
              "      <td>0.380829</td>\n",
              "      <td>0.426166</td>\n",
              "      <td>0.470207</td>\n",
              "      <td>0.506477</td>\n",
              "      <td>0.511658</td>\n",
              "      <td>0.528497</td>\n",
              "      <td>0.534974</td>\n",
              "      <td>0.546632</td>\n",
              "      <td>0.564767</td>\n",
              "      <td>0.577720</td>\n",
              "      <td>0.594560</td>\n",
              "      <td>0.611399</td>\n",
              "      <td>0.632124</td>\n",
              "      <td>0.645078</td>\n",
              "      <td>0.665803</td>\n",
              "      <td>0.681347</td>\n",
              "      <td>0.696891</td>\n",
              "      <td>0.705959</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2    ...       185       186  187\n",
              "39645  1.000000  0.860082  0.493827  ...  0.000000  0.000000    0\n",
              "74350  0.867188  0.746094  0.191406  ...  0.347656  0.339844    1\n",
              "76751  0.971429  0.919328  0.621849  ...  0.000000  0.000000    2\n",
              "81080  1.000000  0.938406  0.527174  ...  0.000000  0.000000    3\n",
              "85773  1.000000  0.940414  0.873057  ...  0.000000  0.000000    4\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB80IzMo1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_gaussian_noise(signal):\n",
        "    noise=np.random.normal(0,0.05,186)\n",
        "    return (signal+noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJB5fWu5sWNc",
        "colab_type": "code",
        "outputId": "7e373a1e-c430-41dd-a0a4-590f9e09d26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tempo=c.iloc[0,:186]\n",
        "bruiter=add_gaussian_noise(tempo)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(c.iloc[0,:186])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(bruiter)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4fXuypr6vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUVlLpKPsQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values\n",
        "# X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
        "# X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexzfSPiD34D",
        "colab_type": "code",
        "outputId": "debcee61-a9d4-4c71-a106-930fe47e9586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 186)\n",
            "(21892, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzROJp1Fr6q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "import pywt\n",
        "\n",
        "XF_train = np.zeros((X_train.shape[0], 9000))\n",
        "XF_test = np.zeros((X_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_train):\n",
        "  XF_train[index, :] = pywt.pad(row, 4407, 'periodic')\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_test):\n",
        "  XF_test[index, :] = pywt.pad(row, 4407, 'periodic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOzIlNPzr6kY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHbRK3GDr6bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0aEgkhXamJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = train_df.values\n",
        "# testset = test_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Yu65s0adg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def split(dataset, number_of_sample_per_category):\n",
        "  \n",
        "#   new_dataset = np.zeros((np.sum(number_of_sample_per_category), dataset.shape[1]))\n",
        "#   pointer = 0\n",
        "  \n",
        "#   for row in dataset :\n",
        "    \n",
        "#     row_label = int(row[-1])\n",
        "    \n",
        "#     if number_of_sample_per_category[row_label] > 0 :\n",
        "      \n",
        "#       number_of_sample_per_category[row_label] -= 1\n",
        "#       new_dataset[pointer , :] = row\n",
        "#       pointer += 1\n",
        "\n",
        "#     else:\n",
        "\n",
        "#       pass\n",
        "    \n",
        "  \n",
        "#   return new_dataset\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTg8U_rCecMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# temp_trainset = split(trainset, [5500, 2223, 5500, 641, 5500])\n",
        "# temp_testset = split(testset, [500, 500, 500, 500, 500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VixGjo-J1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented = 0\n",
        "# def data_augmentation(dataset, chance):\n",
        "  \n",
        "#   augmented = 0\n",
        "#   number_of_rows = int(dataset.shape[0] + (dataset.shape[0] * (chance*2)))\n",
        "#   new_dataset = np.zeros((number_of_rows, dataset.shape[1]))\n",
        "#   pointer = 0 \n",
        "\n",
        "#   for row in dataset:\n",
        "    \n",
        "#     rand_num = random.uniform(0, 1)\n",
        "#     if rand_num < chance:\n",
        "      \n",
        "#       augmented += 1\n",
        "#       noise = np.random.normal(scale=0.01, size=187)\n",
        "#       new_signal = np.zeros((1, 188))\n",
        "#       new_signal[:, :187] = row[:187] + noise\n",
        "#       new_signal[:, -1:] = row[-1:] \n",
        "#       new_dataset[pointer:pointer+1, :] = new_signal\n",
        "#       pointer += 1\n",
        "\n",
        "#     else :\n",
        "#       pass\n",
        "\n",
        "#     new_dataset[pointer, :] = row \n",
        "#     pointer += 1\n",
        "\n",
        "#   return augmented, new_dataset  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-WNJJaSNYR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented, trainset = data_augmentation(temp_trainset, 0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEkQ1k_zRnYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filled = augmented + temp_trainset.shape[0]\n",
        "# trainset = trainset[:filled , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULVB16ONXuex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = np.take(trainset,np.random.permutation(trainset.shape[0]),axis=0,out=trainset)\n",
        "# testset = np.take(temp_testset,np.random.permutation(temp_testset.shape[0]),axis=0,out=temp_testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXpOUPpHYPQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_temp_train = trainset[:, :-1]\n",
        "# Y_train = trainset[:, -1:]\n",
        "# X_temp_test = testset[:, :-1]\n",
        "# Y_test = testset[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wSnYvXY6AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", XF_train.shape)\n",
        "# print(\"Y_train : \", y_train.shape)\n",
        "# print(\"X_test : \", XF_test.shape)\n",
        "# print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQP8dTlBZw6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# One Hot enoding for target labels \n",
        "# ohe = OneHotEncoder()\n",
        "# Y_train = ohe.fit_transform(Y_train.reshape(-1,1))\n",
        "# Y_test = ohe.transform(Y_test.reshape(-1,1))\n",
        "\n",
        "# # handle sparse matrix for keras \n",
        "# Y_train = csr_matrix.toarray(Y_train)\n",
        "# Y_test = csr_matrix.toarray(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBhFohZUarKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", X_temp_train.shape)\n",
        "# print(\"Y_train : \", Y_train.shape)\n",
        "# print(\"X_test : \", X_temp_test.shape)\n",
        "# print(\"Y_test : \", Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E525NqY3aGSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "# import pywt\n",
        "\n",
        "# XF_train = np.zeros((X_temp_train.shape[0], 9000))\n",
        "# XF_test = np.zeros((X_temp_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_train):\n",
        "#   XF_train[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_train[index, -1:] = 0\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   XF_test[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_test[index, -1:] = 0\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCEcchWo3cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index, row in enumerate(X_temp_train):\n",
        "#   X_temp_train[index] = add_gaussian_noise(row)\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   X_temp_test[index] = add_gaussian_noise(row)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmANeCYtjmgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XF_train = XF_train.reshape((50000, 9000, 1))\n",
        "XF_test = XF_test.reshape((21892, 9000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNvkTDCjyoA",
        "colab_type": "code",
        "outputId": "675ed4e5-6aab-4957-d2b5-3a2c5a0ac9b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train : \", XF_train.shape)\n",
        "print(\"Y_train : \", y_train.shape)\n",
        "print(\"X_test : \", XF_test.shape)\n",
        "print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train :  (50000, 9000, 1)\n",
            "Y_train :  (50000, 5)\n",
            "X_test :  (21892, 9000, 1)\n",
            "Y_test :  (21892, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvIW2sWkaoP",
        "colab_type": "code",
        "outputId": "d2622dcf-934d-46ed-8258-5e6624eba512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_input = Input(shape=(9000, 1))\n",
        "Conv = Conv1D(filters=64, kernel_size=5, strides=3)(X_input)\n",
        "\n",
        "\n",
        "### step 1 \n",
        "\n",
        "Conv1_1 = Conv1D(filters=32, kernel_size=9, strides=1, padding='same')(Conv)\n",
        "Bn1_1 = BatchNormalization()(Conv1_1)\n",
        "Act1_1 = LeakyReLU()(Bn1_1)\n",
        "Conv1_2 = Conv1D(filters=32, kernel_size=7, strides=1, padding='same')(Act1_1)\n",
        "Bn1_2 = BatchNormalization()(Conv1_2)\n",
        "Act1_2 = LeakyReLU()(Bn1_2)\n",
        "DO1_1 = Dropout(0.2)(Act1_2)\n",
        "Conv1_3 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(DO1_1)\n",
        "Bn1_3 = BatchNormalization()(Conv1_3)\n",
        "shortcut1_1 = Add()([Bn1_3, Conv])\n",
        "Bn1_4 = BatchNormalization()(shortcut1_1)\n",
        "Act1_3 = LeakyReLU()(Bn1_4)\n",
        "##### auxiliary\n",
        "Conv1_4 = Conv1D(filters=128, kernel_size=7, strides=3, padding='same')(Act1_3)\n",
        "Bn1_4 = BatchNormalization()(Conv1_4)\n",
        "Act1_4 = LeakyReLU()(Bn1_4)\n",
        "###############\n",
        "Max1_1 = MaxPooling1D(pool_size=5, strides=2)(Act1_4)\n",
        "\n",
        "\n",
        "## step 2\n",
        "\n",
        "Conv2_1 = Conv1D(filters=64, kernel_size=3, strides=1, padding='same')(Max1_1)\n",
        "Bn2_1 = BatchNormalization()(Conv2_1)\n",
        "Act2_1 = LeakyReLU()(Bn2_1)\n",
        "Conv2_2 = Conv1D(filters=64, kernel_size=5, strides=1, padding='same')(Act2_1)\n",
        "Bn2_2 = BatchNormalization()(Conv2_2)\n",
        "Act2_2 = LeakyReLU()(Bn2_2)\n",
        "DO2_1 = Dropout(0.2)(Act2_2)\n",
        "Conv2_3 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same')(DO2_1)\n",
        "Bn2_3 = BatchNormalization()(Conv2_3)\n",
        "shortcut2_1 = Add()([Bn2_3, Max1_1])\n",
        "Bn2_4 = BatchNormalization()(shortcut2_1)\n",
        "Act2_3 = LeakyReLU()(Bn2_4)\n",
        "##### auxiliary\n",
        "Conv2_4 = Conv1D(filters=512, kernel_size=7, strides=2, padding='same')(Act2_3)\n",
        "Bn2_4 = BatchNormalization()(Conv2_4)\n",
        "Act2_4 = LeakyReLU()(Bn2_4)\n",
        "###############\n",
        "Max2_1 = MaxPooling1D(pool_size=5, strides=3)(Act2_4)\n",
        "\n",
        "\n",
        "\n",
        "Flat1 = Flatten()(Max2_1)\n",
        "\n",
        "D1 = Dense(256)(Flat1)\n",
        "A6 = LeakyReLU()(D1)\n",
        "D_O = Dropout(0.15)(A6)\n",
        "D2 = Dense(128)(D_O)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=A7)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 9000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 2999, 64)     384         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 2999, 32)     18464       conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 2999, 32)     128         conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 2999, 32)     0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 2999, 32)     7200        leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 2999, 32)     128         conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 2999, 32)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 2999, 32)     0           leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 2999, 64)     18496       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 2999, 64)     256         conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 2999, 64)     0           batch_normalization_12[0][0]     \n",
            "                                                                 conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 2999, 64)     256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 2999, 64)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 1000, 128)    57472       leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 1000, 128)    512         conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 1000, 128)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 498, 128)     0           leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 498, 64)      24640       max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 498, 64)      256         conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 498, 64)      0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 498, 64)      20544       leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 498, 64)      256         conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 498, 64)      0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 498, 64)      0           leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 498, 128)     24704       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 498, 128)     512         conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 498, 128)     0           batch_normalization_17[0][0]     \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 498, 128)     512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 498, 128)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_17 (Conv1D)              (None, 249, 512)     459264      leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 249, 512)     2048        conv1d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 249, 512)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 82, 512)      0           leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 41984)        0           max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 256)          10748160    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 256)          0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 256)          0           leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          32896       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 5)            645         dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax_1 (Softmax)             (None, 5)            0           dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,417,733\n",
            "Trainable params: 11,415,301\n",
            "Non-trainable params: 2,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51SxpfQofzM",
        "colab_type": "code",
        "outputId": "2e6b8e1e-d7ab-4269-a691-5b461f65832c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(XF_train, y_train, epochs=15, batch_size=128, validation_data=(XF_test, y_test), callbacks=[es_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "391/391 [==============================] - 3778s 10s/step - loss: 5.6295 - accuracy: 0.5721 - val_loss: 2.4061 - val_accuracy: 0.0543\n",
            "Epoch 2/15\n",
            "391/391 [==============================] - 3779s 10s/step - loss: 0.6053 - accuracy: 0.8330 - val_loss: 0.3996 - val_accuracy: 0.9051\n",
            "Epoch 3/15\n",
            "391/391 [==============================] - 3739s 10s/step - loss: 0.3301 - accuracy: 0.8908 - val_loss: 1.0345 - val_accuracy: 0.6496\n",
            "Epoch 4/15\n",
            "391/391 [==============================] - 3761s 10s/step - loss: 0.2412 - accuracy: 0.9154 - val_loss: 0.5951 - val_accuracy: 0.8505\n",
            "Epoch 5/15\n",
            "391/391 [==============================] - 3780s 10s/step - loss: 0.2186 - accuracy: 0.9271 - val_loss: 0.1303 - val_accuracy: 0.9606\n",
            "Epoch 6/15\n",
            "391/391 [==============================] - 3797s 10s/step - loss: 0.1718 - accuracy: 0.9422 - val_loss: 0.2753 - val_accuracy: 0.9121\n",
            "Epoch 7/15\n",
            "391/391 [==============================] - 4011s 10s/step - loss: 1.0559 - accuracy: 0.8404 - val_loss: 0.7848 - val_accuracy: 0.7215\n",
            "Epoch 8/15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUPC94zqTiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/*"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}