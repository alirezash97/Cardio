{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/alirezash97/Cardio/blob/master/HeartBeat.ipynb",
      "authorship_tag": "ABX9TyPwZ5Uey7EqxQHSecurFmf1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Cardio/blob/master/HeartBeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUFDobFVvj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"alirezashafaei97\",\"key\":\"9cb262aa0c5658ffc4eb45857c41903c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat -p /content\n",
        "!unzip /content/heartbeat.zip -d /content/heartbeat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sio7SWAwWBLj",
        "colab_type": "code",
        "outputId": "332ae177-1757-4e83-e117-6c4735d15c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, LeakyReLU, Softmax, InputLayer, concatenate, Conv1D, MaxPool1D, Add, MaxPooling1D\n",
        " , Flatten, Dropout, ReLU, BatchNormalization, GlobalAveragePooling1D)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from random import uniform \n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTudiQO8WEXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/heartbeat/mitbih_test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfWxem7CTc50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del train_df\n",
        "# del test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58wFx5vXQS7",
        "colab_type": "code",
        "outputId": "c0a85761-0f10-400a-afc2-08c3fe976948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "counter=train_df[187].value_counts()\n",
        "print(counter)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQqNZG2q59y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=10000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=10000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=10000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=10000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=10000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomIXpkCrozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBctv4Tr58D",
        "colab_type": "code",
        "outputId": "a57c9457-f6fe-482c-adfb-f80cee8db82a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    10000\n",
            "3    10000\n",
            "2    10000\n",
            "1    10000\n",
            "0    10000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3HJfHYr605",
        "colab_type": "code",
        "outputId": "cc257b4a-3ae3-4639-a3aa-91213f98f885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\n",
        "c"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69668</th>\n",
              "      <td>0.996830</td>\n",
              "      <td>0.938193</td>\n",
              "      <td>0.679873</td>\n",
              "      <td>0.437401</td>\n",
              "      <td>0.364501</td>\n",
              "      <td>0.329636</td>\n",
              "      <td>0.301109</td>\n",
              "      <td>0.301109</td>\n",
              "      <td>0.293185</td>\n",
              "      <td>0.275753</td>\n",
              "      <td>0.277338</td>\n",
              "      <td>0.286846</td>\n",
              "      <td>0.274168</td>\n",
              "      <td>0.266244</td>\n",
              "      <td>0.272583</td>\n",
              "      <td>0.264659</td>\n",
              "      <td>0.261490</td>\n",
              "      <td>0.256735</td>\n",
              "      <td>0.256735</td>\n",
              "      <td>0.253566</td>\n",
              "      <td>0.231379</td>\n",
              "      <td>0.215531</td>\n",
              "      <td>0.213946</td>\n",
              "      <td>0.201268</td>\n",
              "      <td>0.180666</td>\n",
              "      <td>0.171157</td>\n",
              "      <td>0.160063</td>\n",
              "      <td>0.144216</td>\n",
              "      <td>0.141046</td>\n",
              "      <td>0.139461</td>\n",
              "      <td>0.145800</td>\n",
              "      <td>0.156894</td>\n",
              "      <td>0.172742</td>\n",
              "      <td>0.204437</td>\n",
              "      <td>0.234548</td>\n",
              "      <td>0.264659</td>\n",
              "      <td>0.293185</td>\n",
              "      <td>0.316957</td>\n",
              "      <td>0.347068</td>\n",
              "      <td>0.345483</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74226</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.978182</td>\n",
              "      <td>0.374545</td>\n",
              "      <td>0.047273</td>\n",
              "      <td>0.087273</td>\n",
              "      <td>0.170909</td>\n",
              "      <td>0.174545</td>\n",
              "      <td>0.203636</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.229091</td>\n",
              "      <td>0.276364</td>\n",
              "      <td>0.345455</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.345455</td>\n",
              "      <td>0.345455</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.352727</td>\n",
              "      <td>0.349091</td>\n",
              "      <td>0.352727</td>\n",
              "      <td>0.370909</td>\n",
              "      <td>0.374545</td>\n",
              "      <td>0.367273</td>\n",
              "      <td>0.374545</td>\n",
              "      <td>0.392727</td>\n",
              "      <td>0.392727</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.429091</td>\n",
              "      <td>0.461818</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.487273</td>\n",
              "      <td>0.516364</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.570909</td>\n",
              "      <td>0.563636</td>\n",
              "      <td>0.578182</td>\n",
              "      <td>0.578182</td>\n",
              "      <td>0.541818</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80027</th>\n",
              "      <td>0.517751</td>\n",
              "      <td>0.482249</td>\n",
              "      <td>0.301775</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029586</td>\n",
              "      <td>0.056213</td>\n",
              "      <td>0.071006</td>\n",
              "      <td>0.094675</td>\n",
              "      <td>0.100592</td>\n",
              "      <td>0.065089</td>\n",
              "      <td>0.097633</td>\n",
              "      <td>0.224852</td>\n",
              "      <td>0.343195</td>\n",
              "      <td>0.363905</td>\n",
              "      <td>0.393491</td>\n",
              "      <td>0.402367</td>\n",
              "      <td>0.420118</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.428994</td>\n",
              "      <td>0.440828</td>\n",
              "      <td>0.464497</td>\n",
              "      <td>0.485207</td>\n",
              "      <td>0.526627</td>\n",
              "      <td>0.544379</td>\n",
              "      <td>0.582840</td>\n",
              "      <td>0.591716</td>\n",
              "      <td>0.642012</td>\n",
              "      <td>0.656805</td>\n",
              "      <td>0.677515</td>\n",
              "      <td>0.701183</td>\n",
              "      <td>0.739645</td>\n",
              "      <td>0.751479</td>\n",
              "      <td>0.775148</td>\n",
              "      <td>0.778107</td>\n",
              "      <td>0.781065</td>\n",
              "      <td>0.748521</td>\n",
              "      <td>0.718935</td>\n",
              "      <td>0.656805</td>\n",
              "      <td>0.594675</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80899</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833102</td>\n",
              "      <td>0.556328</td>\n",
              "      <td>0.254520</td>\n",
              "      <td>0.090403</td>\n",
              "      <td>0.104312</td>\n",
              "      <td>0.101530</td>\n",
              "      <td>0.069541</td>\n",
              "      <td>0.055633</td>\n",
              "      <td>0.044506</td>\n",
              "      <td>0.027816</td>\n",
              "      <td>0.029207</td>\n",
              "      <td>0.018081</td>\n",
              "      <td>0.004172</td>\n",
              "      <td>0.006954</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005563</td>\n",
              "      <td>0.012517</td>\n",
              "      <td>0.009736</td>\n",
              "      <td>0.036161</td>\n",
              "      <td>0.052851</td>\n",
              "      <td>0.079277</td>\n",
              "      <td>0.116829</td>\n",
              "      <td>0.147427</td>\n",
              "      <td>0.176634</td>\n",
              "      <td>0.218359</td>\n",
              "      <td>0.255911</td>\n",
              "      <td>0.301808</td>\n",
              "      <td>0.324061</td>\n",
              "      <td>0.336579</td>\n",
              "      <td>0.368567</td>\n",
              "      <td>0.388039</td>\n",
              "      <td>0.386648</td>\n",
              "      <td>0.386648</td>\n",
              "      <td>0.375522</td>\n",
              "      <td>0.368567</td>\n",
              "      <td>0.356050</td>\n",
              "      <td>0.331015</td>\n",
              "      <td>0.312935</td>\n",
              "      <td>0.297636</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82331</th>\n",
              "      <td>0.481586</td>\n",
              "      <td>0.389518</td>\n",
              "      <td>0.291785</td>\n",
              "      <td>0.202550</td>\n",
              "      <td>0.103399</td>\n",
              "      <td>0.052408</td>\n",
              "      <td>0.004249</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004249</td>\n",
              "      <td>0.036827</td>\n",
              "      <td>0.092068</td>\n",
              "      <td>0.177054</td>\n",
              "      <td>0.203966</td>\n",
              "      <td>0.232295</td>\n",
              "      <td>0.269122</td>\n",
              "      <td>0.325779</td>\n",
              "      <td>0.362606</td>\n",
              "      <td>0.406516</td>\n",
              "      <td>0.415014</td>\n",
              "      <td>0.441926</td>\n",
              "      <td>0.443343</td>\n",
              "      <td>0.458924</td>\n",
              "      <td>0.453258</td>\n",
              "      <td>0.474504</td>\n",
              "      <td>0.474504</td>\n",
              "      <td>0.490085</td>\n",
              "      <td>0.490085</td>\n",
              "      <td>0.504249</td>\n",
              "      <td>0.508499</td>\n",
              "      <td>0.532578</td>\n",
              "      <td>0.536827</td>\n",
              "      <td>0.560907</td>\n",
              "      <td>0.570822</td>\n",
              "      <td>0.590652</td>\n",
              "      <td>0.592068</td>\n",
              "      <td>0.620397</td>\n",
              "      <td>0.627479</td>\n",
              "      <td>0.648725</td>\n",
              "      <td>0.648725</td>\n",
              "      <td>0.658640</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3    ...  184  185  186  187\n",
              "69668  0.996830  0.938193  0.679873  0.437401  ...  0.0  0.0  0.0    0\n",
              "74226  1.000000  0.978182  0.374545  0.047273  ...  0.0  0.0  0.0    1\n",
              "80027  0.517751  0.482249  0.301775  0.000000  ...  0.0  0.0  0.0    2\n",
              "80899  1.000000  0.833102  0.556328  0.254520  ...  0.0  0.0  0.0    3\n",
              "82331  0.481586  0.389518  0.291785  0.202550  ...  0.0  0.0  0.0    4\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB80IzMo1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_gaussian_noise(signal):\n",
        "    noise=np.random.normal(0,0.05,186)\n",
        "    return (signal+noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJB5fWu5sWNc",
        "colab_type": "code",
        "outputId": "e791d99a-67ba-46b1-c2c2-d8b53b38a523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tempo=c.iloc[0,:186]\n",
        "bruiter=add_gaussian_noise(tempo)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(c.iloc[0,:186])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(bruiter)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4fXuypr6vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUVlLpKPsQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values\n",
        "# X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
        "# X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexzfSPiD34D",
        "colab_type": "code",
        "outputId": "ad99f730-b151-4696-b3e0-0ea432fefbff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 186)\n",
            "(21892, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzROJp1Fr6q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "import pywt\n",
        "\n",
        "XF_train = np.zeros((X_train.shape[0], 9000))\n",
        "XF_test = np.zeros((X_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_train):\n",
        "  XF_train[index, :] = pywt.pad(row, 4407, 'periodic')\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_test):\n",
        "  XF_test[index, :] = pywt.pad(row, 4407, 'periodic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOzIlNPzr6kY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHbRK3GDr6bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0aEgkhXamJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = train_df.values\n",
        "# testset = test_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Yu65s0adg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def split(dataset, number_of_sample_per_category):\n",
        "  \n",
        "#   new_dataset = np.zeros((np.sum(number_of_sample_per_category), dataset.shape[1]))\n",
        "#   pointer = 0\n",
        "  \n",
        "#   for row in dataset :\n",
        "    \n",
        "#     row_label = int(row[-1])\n",
        "    \n",
        "#     if number_of_sample_per_category[row_label] > 0 :\n",
        "      \n",
        "#       number_of_sample_per_category[row_label] -= 1\n",
        "#       new_dataset[pointer , :] = row\n",
        "#       pointer += 1\n",
        "\n",
        "#     else:\n",
        "\n",
        "#       pass\n",
        "    \n",
        "  \n",
        "#   return new_dataset\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTg8U_rCecMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# temp_trainset = split(trainset, [5500, 2223, 5500, 641, 5500])\n",
        "# temp_testset = split(testset, [500, 500, 500, 500, 500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VixGjo-J1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented = 0\n",
        "# def data_augmentation(dataset, chance):\n",
        "  \n",
        "#   augmented = 0\n",
        "#   number_of_rows = int(dataset.shape[0] + (dataset.shape[0] * (chance*2)))\n",
        "#   new_dataset = np.zeros((number_of_rows, dataset.shape[1]))\n",
        "#   pointer = 0 \n",
        "\n",
        "#   for row in dataset:\n",
        "    \n",
        "#     rand_num = random.uniform(0, 1)\n",
        "#     if rand_num < chance:\n",
        "      \n",
        "#       augmented += 1\n",
        "#       noise = np.random.normal(scale=0.01, size=187)\n",
        "#       new_signal = np.zeros((1, 188))\n",
        "#       new_signal[:, :187] = row[:187] + noise\n",
        "#       new_signal[:, -1:] = row[-1:] \n",
        "#       new_dataset[pointer:pointer+1, :] = new_signal\n",
        "#       pointer += 1\n",
        "\n",
        "#     else :\n",
        "#       pass\n",
        "\n",
        "#     new_dataset[pointer, :] = row \n",
        "#     pointer += 1\n",
        "\n",
        "#   return augmented, new_dataset  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-WNJJaSNYR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented, trainset = data_augmentation(temp_trainset, 0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEkQ1k_zRnYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filled = augmented + temp_trainset.shape[0]\n",
        "# trainset = trainset[:filled , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULVB16ONXuex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = np.take(trainset,np.random.permutation(trainset.shape[0]),axis=0,out=trainset)\n",
        "# testset = np.take(temp_testset,np.random.permutation(temp_testset.shape[0]),axis=0,out=temp_testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXpOUPpHYPQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_temp_train = trainset[:, :-1]\n",
        "# Y_train = trainset[:, -1:]\n",
        "# X_temp_test = testset[:, :-1]\n",
        "# Y_test = testset[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wSnYvXY6AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", XF_train.shape)\n",
        "# print(\"Y_train : \", y_train.shape)\n",
        "# print(\"X_test : \", XF_test.shape)\n",
        "# print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQP8dTlBZw6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# One Hot enoding for target labels \n",
        "# ohe = OneHotEncoder()\n",
        "# Y_train = ohe.fit_transform(Y_train.reshape(-1,1))\n",
        "# Y_test = ohe.transform(Y_test.reshape(-1,1))\n",
        "\n",
        "# # handle sparse matrix for keras \n",
        "# Y_train = csr_matrix.toarray(Y_train)\n",
        "# Y_test = csr_matrix.toarray(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBhFohZUarKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", X_temp_train.shape)\n",
        "# print(\"Y_train : \", Y_train.shape)\n",
        "# print(\"X_test : \", X_temp_test.shape)\n",
        "# print(\"Y_test : \", Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E525NqY3aGSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "# import pywt\n",
        "\n",
        "# XF_train = np.zeros((X_temp_train.shape[0], 9000))\n",
        "# XF_test = np.zeros((X_temp_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_train):\n",
        "#   XF_train[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_train[index, -1:] = 0\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   XF_test[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_test[index, -1:] = 0\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCEcchWo3cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index, row in enumerate(X_temp_train):\n",
        "#   X_temp_train[index] = add_gaussian_noise(row)\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   X_temp_test[index] = add_gaussian_noise(row)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmANeCYtjmgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XF_train = XF_train.reshape((50000, 9000, 1))\n",
        "XF_test = XF_test.reshape((21892, 9000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNvkTDCjyoA",
        "colab_type": "code",
        "outputId": "19735258-ebe7-4176-cefb-1c79b7b9ea5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train : \", XF_train.shape)\n",
        "print(\"Y_train : \", y_train.shape)\n",
        "print(\"X_test : \", XF_test.shape)\n",
        "print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train :  (50000, 9000, 1)\n",
            "Y_train :  (50000, 5)\n",
            "X_test :  (21892, 9000, 1)\n",
            "Y_test :  (21892, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvIW2sWkaoP",
        "colab_type": "code",
        "outputId": "9202f7f9-b57d-4121-d64e-73d33981b3f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_input = Input(shape=(9000, 1))\n",
        "Conv = Conv1D(filters=64, kernel_size=5, strides=3)(X_input)\n",
        "\n",
        "\n",
        "### step 1 \n",
        "\n",
        "Conv1_1 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(Conv)\n",
        "Bn1_1 = BatchNormalization()(Conv1_1)\n",
        "Act1_1 = LeakyReLU()(Bn1_1)\n",
        "Conv1_2 = Conv1D(filters=32, kernel_size=7, strides=1, padding='same')(Act1_1)\n",
        "Bn1_2 = BatchNormalization()(Conv1_2)\n",
        "Act1_2 = LeakyReLU()(Bn1_2)\n",
        "DO1_1 = Dropout(0.2)(Act1_2)\n",
        "Conv1_3 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(DO1_1)\n",
        "Bn1_3 = BatchNormalization()(Conv1_3)\n",
        "shortcut1_1 = Add()([Bn1_3, Conv])\n",
        "Bn1_4 = BatchNormalization()(shortcut1_1)\n",
        "Act1_3 = LeakyReLU()(Bn1_4)\n",
        "##### auxiliary\n",
        "Conv1_4 = Conv1D(filters=128, kernel_size=7, strides=3, padding='same')(Act1_3)\n",
        "Bn1_5 = BatchNormalization()(Conv1_4)\n",
        "Act1_4 = LeakyReLU()(Bn1_5)\n",
        "###############\n",
        "Max1_1 = MaxPooling1D(pool_size=5, strides=2)(Act1_4)\n",
        "\n",
        "\n",
        "## step 2\n",
        "\n",
        "Conv2_1 = Conv1D(filters=256, kernel_size=3, strides=1, padding='same')(Max1_1)\n",
        "Bn2_1 = BatchNormalization()(Conv2_1)\n",
        "Act2_1 = LeakyReLU()(Bn2_1)\n",
        "Conv2_2 = Conv1D(filters=256, kernel_size=5, strides=1, padding='same')(Act2_1)\n",
        "Bn2_2 = BatchNormalization()(Conv2_2)\n",
        "Act2_2 = LeakyReLU()(Bn2_2)\n",
        "DO2_1 = Dropout(0.2)(Act2_2)\n",
        "Conv2_3 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same')(DO2_1)\n",
        "Bn2_3 = BatchNormalization()(Conv2_3)\n",
        "shortcut2_1 = Add()([Bn2_3, Max1_1])\n",
        "Bn2_4 = BatchNormalization()(shortcut2_1)\n",
        "Act2_3 = LeakyReLU()(Bn2_4)\n",
        "##### auxiliary\n",
        "Conv2_4 = Conv1D(filters=512, kernel_size=7, strides=2, padding='same')(Act2_3)\n",
        "Bn2_5 = BatchNormalization()(Conv2_4)\n",
        "Act2_4 = LeakyReLU()(Bn2_5)\n",
        "###############\n",
        "Max2_1 = MaxPooling1D(pool_size=5, strides=3)(Act2_4)\n",
        "\n",
        "\n",
        "\n",
        "Flat1 = Flatten()(Max2_1)\n",
        "\n",
        "D1 = Dense(256)(Flat1)\n",
        "A6 = LeakyReLU()(D1)\n",
        "D_O = Dropout(0.15)(A6)\n",
        "D2 = Dense(128)(D_O)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=A7)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 2999, 64)     384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 2999, 64)     36928       conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2999, 64)     256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 2999, 64)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 2999, 32)     14368       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 2999, 32)     128         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 2999, 32)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2999, 32)     0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 2999, 64)     18496       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2999, 64)     256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 2999, 64)     0           batch_normalization_2[0][0]      \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 2999, 64)     256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1000, 128)    57472       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1000, 128)    512         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 1000, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 498, 128)     0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 498, 256)     98560       max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 498, 256)     1024        conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 498, 256)     327936      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 498, 256)     1024        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 498, 256)     0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 498, 128)     98432       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 498, 128)     512         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 498, 128)     0           batch_normalization_7[0][0]      \n",
            "                                                                 max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 498, 128)     512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 498, 128)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 249, 512)     459264      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 249, 512)     2048        conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 249, 512)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 82, 512)      0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 41984)        0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          10748160    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5)            645         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 5)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,900,069\n",
            "Trainable params: 11,896,805\n",
            "Non-trainable params: 3,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51SxpfQofzM",
        "colab_type": "code",
        "outputId": "ac07c6e9-8899-48e2-af2d-4509b1f8c16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(XF_train, y_train, epochs=4, batch_size=64, validation_data=(XF_test, y_test), callbacks=[es_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "782/782 [==============================] - 5860s 7s/step - loss: 3.4113 - accuracy: 0.6936 - val_loss: 0.4635 - val_accuracy: 0.8571\n",
            "Epoch 2/4\n",
            "782/782 [==============================] - 5801s 7s/step - loss: 0.3393 - accuracy: 0.8832 - val_loss: 0.3073 - val_accuracy: 0.8879\n",
            "Epoch 3/4\n",
            "782/782 [==============================] - 5803s 7s/step - loss: 0.4928 - accuracy: 0.8965 - val_loss: 2311.1814 - val_accuracy: 0.1534\n",
            "Epoch 4/4\n",
            "479/782 [=================>............] - ETA: 33:57 - loss: 0.8965 - accuracy: 0.8335"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUPC94zqTiE",
        "colab_type": "code",
        "outputId": "1db5eee5-aa5b-4b8e-c835-31440c378940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(XF_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"/content/drive/My Drive/Cardio/HeartBeat.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 87.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCecYVrhtbNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht3ltnGvtjlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}