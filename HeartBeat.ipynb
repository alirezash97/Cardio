{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/alirezash97/Cardio/blob/master/HeartBeat.ipynb",
      "authorship_tag": "ABX9TyMeTwJABiMAteUsY7C1tGSB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Cardio/blob/master/HeartBeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUFDobFVvj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"alirezashafaei97\",\"key\":\"9cb262aa0c5658ffc4eb45857c41903c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat -p /content\n",
        "!unzip /content/heartbeat.zip -d /content/heartbeat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sio7SWAwWBLj",
        "colab_type": "code",
        "outputId": "7ffe9619-cb4b-45a9-e67e-59d7d17e536d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, LeakyReLU, Softmax, InputLayer, concatenate, Conv1D, MaxPool1D, Add, MaxPooling1D\n",
        " , Flatten, Dropout, ReLU, BatchNormalization, GlobalAveragePooling1D)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from random import uniform \n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTudiQO8WEXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/heartbeat/mitbih_test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfWxem7CTc50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del train_df\n",
        "# del test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58wFx5vXQS7",
        "colab_type": "code",
        "outputId": "649e9cb0-4fb5-4ec6-f9f3-277c1b40b73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "counter=train_df[187].value_counts()\n",
        "print(counter)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQqNZG2q59y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=10000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=10000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=10000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=10000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=10000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomIXpkCrozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBctv4Tr58D",
        "colab_type": "code",
        "outputId": "fe07bf68-c1ab-4f74-cbd4-6e9cbdbde5ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    10000\n",
            "3    10000\n",
            "2    10000\n",
            "1    10000\n",
            "0    10000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3HJfHYr605",
        "colab_type": "code",
        "outputId": "ffb10cb4-3a90-4f73-99ea-62b242451279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\n",
        "c"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57669</th>\n",
              "      <td>0.949212</td>\n",
              "      <td>0.868652</td>\n",
              "      <td>0.327496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.101576</td>\n",
              "      <td>0.199650</td>\n",
              "      <td>0.218914</td>\n",
              "      <td>0.267951</td>\n",
              "      <td>0.288967</td>\n",
              "      <td>0.276708</td>\n",
              "      <td>0.271454</td>\n",
              "      <td>0.274956</td>\n",
              "      <td>0.280210</td>\n",
              "      <td>0.278459</td>\n",
              "      <td>0.276708</td>\n",
              "      <td>0.281961</td>\n",
              "      <td>0.283713</td>\n",
              "      <td>0.283713</td>\n",
              "      <td>0.280210</td>\n",
              "      <td>0.283713</td>\n",
              "      <td>0.285464</td>\n",
              "      <td>0.283713</td>\n",
              "      <td>0.280210</td>\n",
              "      <td>0.288967</td>\n",
              "      <td>0.294221</td>\n",
              "      <td>0.285464</td>\n",
              "      <td>0.280210</td>\n",
              "      <td>0.283713</td>\n",
              "      <td>0.302977</td>\n",
              "      <td>0.299475</td>\n",
              "      <td>0.308231</td>\n",
              "      <td>0.316988</td>\n",
              "      <td>0.330998</td>\n",
              "      <td>0.334501</td>\n",
              "      <td>0.339755</td>\n",
              "      <td>0.353765</td>\n",
              "      <td>0.369527</td>\n",
              "      <td>0.371278</td>\n",
              "      <td>0.369527</td>\n",
              "      <td>0.387040</td>\n",
              "      <td>...</td>\n",
              "      <td>0.315236</td>\n",
              "      <td>0.308231</td>\n",
              "      <td>0.301226</td>\n",
              "      <td>0.302977</td>\n",
              "      <td>0.313485</td>\n",
              "      <td>0.311734</td>\n",
              "      <td>0.309982</td>\n",
              "      <td>0.30648</td>\n",
              "      <td>0.316988</td>\n",
              "      <td>0.323993</td>\n",
              "      <td>0.322242</td>\n",
              "      <td>0.329247</td>\n",
              "      <td>0.343257</td>\n",
              "      <td>0.348511</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74112</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.251282</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.220513</td>\n",
              "      <td>0.164103</td>\n",
              "      <td>0.143590</td>\n",
              "      <td>0.143590</td>\n",
              "      <td>0.164103</td>\n",
              "      <td>0.169231</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.164103</td>\n",
              "      <td>0.148718</td>\n",
              "      <td>0.138462</td>\n",
              "      <td>0.143590</td>\n",
              "      <td>0.174359</td>\n",
              "      <td>0.158974</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.143590</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.158974</td>\n",
              "      <td>0.138462</td>\n",
              "      <td>0.128205</td>\n",
              "      <td>0.123077</td>\n",
              "      <td>0.128205</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.082051</td>\n",
              "      <td>0.056410</td>\n",
              "      <td>0.046154</td>\n",
              "      <td>0.020513</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035897</td>\n",
              "      <td>0.015385</td>\n",
              "      <td>0.035897</td>\n",
              "      <td>0.030769</td>\n",
              "      <td>0.061538</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79374</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062606</td>\n",
              "      <td>0.150592</td>\n",
              "      <td>0.203046</td>\n",
              "      <td>0.223350</td>\n",
              "      <td>0.228426</td>\n",
              "      <td>0.258883</td>\n",
              "      <td>0.291032</td>\n",
              "      <td>0.306261</td>\n",
              "      <td>0.302876</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.292724</td>\n",
              "      <td>0.285956</td>\n",
              "      <td>0.287648</td>\n",
              "      <td>0.292724</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.292724</td>\n",
              "      <td>0.287648</td>\n",
              "      <td>0.296108</td>\n",
              "      <td>0.299492</td>\n",
              "      <td>0.296108</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.302876</td>\n",
              "      <td>0.313029</td>\n",
              "      <td>0.313029</td>\n",
              "      <td>0.321489</td>\n",
              "      <td>0.335025</td>\n",
              "      <td>0.350254</td>\n",
              "      <td>0.362098</td>\n",
              "      <td>0.373942</td>\n",
              "      <td>0.389171</td>\n",
              "      <td>0.404399</td>\n",
              "      <td>0.407783</td>\n",
              "      <td>0.417936</td>\n",
              "      <td>0.423012</td>\n",
              "      <td>0.417936</td>\n",
              "      <td>0.402707</td>\n",
              "      <td>0.387479</td>\n",
              "      <td>0.373942</td>\n",
              "      <td>0.365482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80487</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.895778</td>\n",
              "      <td>0.633245</td>\n",
              "      <td>0.275726</td>\n",
              "      <td>0.087071</td>\n",
              "      <td>0.116095</td>\n",
              "      <td>0.100264</td>\n",
              "      <td>0.076517</td>\n",
              "      <td>0.067282</td>\n",
              "      <td>0.060686</td>\n",
              "      <td>0.052770</td>\n",
              "      <td>0.039578</td>\n",
              "      <td>0.034301</td>\n",
              "      <td>0.025066</td>\n",
              "      <td>0.010554</td>\n",
              "      <td>0.010554</td>\n",
              "      <td>0.009235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005277</td>\n",
              "      <td>0.010554</td>\n",
              "      <td>0.022427</td>\n",
              "      <td>0.039578</td>\n",
              "      <td>0.055409</td>\n",
              "      <td>0.080475</td>\n",
              "      <td>0.117414</td>\n",
              "      <td>0.143799</td>\n",
              "      <td>0.178100</td>\n",
              "      <td>0.212401</td>\n",
              "      <td>0.242744</td>\n",
              "      <td>0.273087</td>\n",
              "      <td>0.294195</td>\n",
              "      <td>0.319261</td>\n",
              "      <td>0.333773</td>\n",
              "      <td>0.333773</td>\n",
              "      <td>0.333773</td>\n",
              "      <td>0.331135</td>\n",
              "      <td>0.317942</td>\n",
              "      <td>0.298153</td>\n",
              "      <td>0.278364</td>\n",
              "      <td>0.259894</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81430</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.479087</td>\n",
              "      <td>0.494297</td>\n",
              "      <td>0.543726</td>\n",
              "      <td>0.577947</td>\n",
              "      <td>0.585551</td>\n",
              "      <td>0.623574</td>\n",
              "      <td>0.673004</td>\n",
              "      <td>0.657795</td>\n",
              "      <td>0.570342</td>\n",
              "      <td>0.425856</td>\n",
              "      <td>0.201521</td>\n",
              "      <td>0.171103</td>\n",
              "      <td>0.136882</td>\n",
              "      <td>0.064639</td>\n",
              "      <td>0.019011</td>\n",
              "      <td>0.019011</td>\n",
              "      <td>0.011407</td>\n",
              "      <td>0.019011</td>\n",
              "      <td>0.019011</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019011</td>\n",
              "      <td>0.026616</td>\n",
              "      <td>0.034221</td>\n",
              "      <td>0.030418</td>\n",
              "      <td>0.030418</td>\n",
              "      <td>0.026616</td>\n",
              "      <td>0.034221</td>\n",
              "      <td>0.026616</td>\n",
              "      <td>0.030418</td>\n",
              "      <td>0.030418</td>\n",
              "      <td>0.034221</td>\n",
              "      <td>0.022814</td>\n",
              "      <td>0.057034</td>\n",
              "      <td>0.064639</td>\n",
              "      <td>0.076046</td>\n",
              "      <td>0.106464</td>\n",
              "      <td>0.121673</td>\n",
              "      <td>0.140684</td>\n",
              "      <td>0.174905</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3    ...  184  185  186  187\n",
              "57669  0.949212  0.868652  0.327496  0.000000  ...  0.0  0.0  0.0    0\n",
              "74112  1.000000  0.523077  0.251282  0.261538  ...  0.0  0.0  0.0    1\n",
              "79374  0.000000  0.062606  0.150592  0.203046  ...  0.0  0.0  0.0    2\n",
              "80487  1.000000  0.895778  0.633245  0.275726  ...  0.0  0.0  0.0    3\n",
              "81430  1.000000  0.479087  0.494297  0.543726  ...  0.0  0.0  0.0    4\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB80IzMo1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_gaussian_noise(signal):\n",
        "    noise=np.random.normal(0,0.05,186)\n",
        "    return (signal+noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJB5fWu5sWNc",
        "colab_type": "code",
        "outputId": "0ae39a47-5216-44e3-a5eb-55519e9fc42a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tempo=c.iloc[0,:186]\n",
        "bruiter=add_gaussian_noise(tempo)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(c.iloc[0,:186])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(bruiter)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4fXuypr6vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUVlLpKPsQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values\n",
        "# X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
        "# X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexzfSPiD34D",
        "colab_type": "code",
        "outputId": "1506acde-2e37-4f72-e0a3-710b7f889479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 186)\n",
            "(21892, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzROJp1Fr6q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "import pywt\n",
        "\n",
        "XF_train = np.zeros((X_train.shape[0], 9000))\n",
        "XF_test = np.zeros((X_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_train):\n",
        "  XF_train[index, :] = pywt.pad(row, 4407, 'periodic')\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_test):\n",
        "  XF_test[index, :] = pywt.pad(row, 4407, 'periodic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOzIlNPzr6kY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHbRK3GDr6bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0aEgkhXamJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = train_df.values\n",
        "# testset = test_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Yu65s0adg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def split(dataset, number_of_sample_per_category):\n",
        "  \n",
        "#   new_dataset = np.zeros((np.sum(number_of_sample_per_category), dataset.shape[1]))\n",
        "#   pointer = 0\n",
        "  \n",
        "#   for row in dataset :\n",
        "    \n",
        "#     row_label = int(row[-1])\n",
        "    \n",
        "#     if number_of_sample_per_category[row_label] > 0 :\n",
        "      \n",
        "#       number_of_sample_per_category[row_label] -= 1\n",
        "#       new_dataset[pointer , :] = row\n",
        "#       pointer += 1\n",
        "\n",
        "#     else:\n",
        "\n",
        "#       pass\n",
        "    \n",
        "  \n",
        "#   return new_dataset\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTg8U_rCecMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# temp_trainset = split(trainset, [5500, 2223, 5500, 641, 5500])\n",
        "# temp_testset = split(testset, [500, 500, 500, 500, 500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VixGjo-J1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented = 0\n",
        "# def data_augmentation(dataset, chance):\n",
        "  \n",
        "#   augmented = 0\n",
        "#   number_of_rows = int(dataset.shape[0] + (dataset.shape[0] * (chance*2)))\n",
        "#   new_dataset = np.zeros((number_of_rows, dataset.shape[1]))\n",
        "#   pointer = 0 \n",
        "\n",
        "#   for row in dataset:\n",
        "    \n",
        "#     rand_num = random.uniform(0, 1)\n",
        "#     if rand_num < chance:\n",
        "      \n",
        "#       augmented += 1\n",
        "#       noise = np.random.normal(scale=0.01, size=187)\n",
        "#       new_signal = np.zeros((1, 188))\n",
        "#       new_signal[:, :187] = row[:187] + noise\n",
        "#       new_signal[:, -1:] = row[-1:] \n",
        "#       new_dataset[pointer:pointer+1, :] = new_signal\n",
        "#       pointer += 1\n",
        "\n",
        "#     else :\n",
        "#       pass\n",
        "\n",
        "#     new_dataset[pointer, :] = row \n",
        "#     pointer += 1\n",
        "\n",
        "#   return augmented, new_dataset  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-WNJJaSNYR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented, trainset = data_augmentation(temp_trainset, 0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEkQ1k_zRnYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filled = augmented + temp_trainset.shape[0]\n",
        "# trainset = trainset[:filled , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULVB16ONXuex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = np.take(trainset,np.random.permutation(trainset.shape[0]),axis=0,out=trainset)\n",
        "# testset = np.take(temp_testset,np.random.permutation(temp_testset.shape[0]),axis=0,out=temp_testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXpOUPpHYPQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_temp_train = trainset[:, :-1]\n",
        "# Y_train = trainset[:, -1:]\n",
        "# X_temp_test = testset[:, :-1]\n",
        "# Y_test = testset[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wSnYvXY6AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", XF_train.shape)\n",
        "# print(\"Y_train : \", y_train.shape)\n",
        "# print(\"X_test : \", XF_test.shape)\n",
        "# print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQP8dTlBZw6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# One Hot enoding for target labels \n",
        "# ohe = OneHotEncoder()\n",
        "# Y_train = ohe.fit_transform(Y_train.reshape(-1,1))\n",
        "# Y_test = ohe.transform(Y_test.reshape(-1,1))\n",
        "\n",
        "# # handle sparse matrix for keras \n",
        "# Y_train = csr_matrix.toarray(Y_train)\n",
        "# Y_test = csr_matrix.toarray(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBhFohZUarKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", X_temp_train.shape)\n",
        "# print(\"Y_train : \", Y_train.shape)\n",
        "# print(\"X_test : \", X_temp_test.shape)\n",
        "# print(\"Y_test : \", Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E525NqY3aGSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "# import pywt\n",
        "\n",
        "# XF_train = np.zeros((X_temp_train.shape[0], 9000))\n",
        "# XF_test = np.zeros((X_temp_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_train):\n",
        "#   XF_train[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_train[index, -1:] = 0\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   XF_test[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_test[index, -1:] = 0\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCEcchWo3cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index, row in enumerate(X_temp_train):\n",
        "#   X_temp_train[index] = add_gaussian_noise(row)\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   X_temp_test[index] = add_gaussian_noise(row)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmANeCYtjmgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XF_train = XF_train.reshape((50000, 9000, 1))\n",
        "XF_test = XF_test.reshape((21892, 9000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNvkTDCjyoA",
        "colab_type": "code",
        "outputId": "095aff88-c14c-4c87-b1b1-6e8a8a97bf1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train : \", XF_train.shape)\n",
        "print(\"Y_train : \", y_train.shape)\n",
        "print(\"X_test : \", XF_test.shape)\n",
        "print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train :  (50000, 9000, 1)\n",
            "Y_train :  (50000, 5)\n",
            "X_test :  (21892, 9000, 1)\n",
            "Y_test :  (21892, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvIW2sWkaoP",
        "colab_type": "code",
        "outputId": "bc81549b-fa5c-49c1-d672-72355379a0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_input = Input(shape=(9000, 1))\n",
        "Conv = Conv1D(filters=64, kernel_size=5, strides=3)(X_input)\n",
        "\n",
        "\n",
        "### step 1 \n",
        "\n",
        "Conv1_1 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(Conv)\n",
        "Bn1_1 = BatchNormalization()(Conv1_1)\n",
        "Act1_1 = LeakyReLU()(Bn1_1)\n",
        "Conv1_2 = Conv1D(filters=32, kernel_size=7, strides=1, padding='same')(Act1_1)\n",
        "Bn1_2 = BatchNormalization()(Conv1_2)\n",
        "Act1_2 = LeakyReLU()(Bn1_2)\n",
        "DO1_1 = Dropout(0.2)(Act1_2)\n",
        "Conv1_3 = Conv1D(filters=64, kernel_size=9, strides=1, padding='same')(DO1_1)\n",
        "Bn1_3 = BatchNormalization()(Conv1_3)\n",
        "shortcut1_1 = Add()([Bn1_3, Conv])\n",
        "Bn1_4 = BatchNormalization()(shortcut1_1)\n",
        "Act1_3 = LeakyReLU()(Bn1_4)\n",
        "##### auxiliary\n",
        "Conv1_4 = Conv1D(filters=128, kernel_size=7, strides=3, padding='same')(Act1_3)\n",
        "Bn1_4 = BatchNormalization()(Conv1_4)\n",
        "Act1_4 = LeakyReLU()(Bn1_4)\n",
        "###############\n",
        "Max1_1 = MaxPooling1D(pool_size=5, strides=2)(Act1_4)\n",
        "\n",
        "\n",
        "## step 2\n",
        "\n",
        "Conv2_1 = Conv1D(filters=256, kernel_size=3, strides=1, padding='same')(Max1_1)\n",
        "Bn2_1 = BatchNormalization()(Conv2_1)\n",
        "Act2_1 = LeakyReLU()(Bn2_1)\n",
        "Conv2_2 = Conv1D(filters=256, kernel_size=5, strides=1, padding='same')(Act2_1)\n",
        "Bn2_2 = BatchNormalization()(Conv2_2)\n",
        "Act2_2 = LeakyReLU()(Bn2_2)\n",
        "DO2_1 = Dropout(0.2)(Act2_2)\n",
        "Conv2_3 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same')(DO2_1)\n",
        "Bn2_3 = BatchNormalization()(Conv2_3)\n",
        "shortcut2_1 = Add()([Bn2_3, Max1_1])\n",
        "Bn2_4 = BatchNormalization()(shortcut2_1)\n",
        "Act2_3 = LeakyReLU()(Bn2_4)\n",
        "##### auxiliary\n",
        "Conv2_4 = Conv1D(filters=512, kernel_size=7, strides=2, padding='same')(Act2_3)\n",
        "Bn2_4 = BatchNormalization()(Conv2_4)\n",
        "Act2_4 = LeakyReLU()(Bn2_4)\n",
        "###############\n",
        "Max2_1 = MaxPooling1D(pool_size=5, strides=3)(Act2_4)\n",
        "\n",
        "\n",
        "\n",
        "Flat1 = Flatten()(Max2_1)\n",
        "\n",
        "D1 = Dense(256)(Flat1)\n",
        "A6 = LeakyReLU()(D1)\n",
        "D_O = Dropout(0.15)(A6)\n",
        "D2 = Dense(128)(D_O)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=A7)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 2999, 64)     384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 2999, 64)     36928       conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2999, 64)     256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 2999, 64)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 2999, 32)     14368       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 2999, 32)     128         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 2999, 32)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2999, 32)     0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 2999, 64)     18496       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2999, 64)     256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 2999, 64)     0           batch_normalization_2[0][0]      \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 2999, 64)     256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 2999, 64)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1000, 128)    57472       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1000, 128)    512         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 1000, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 498, 128)     0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 498, 256)     98560       max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 498, 256)     1024        conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 498, 256)     327936      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 498, 256)     1024        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 498, 256)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 498, 256)     0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 498, 128)     98432       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 498, 128)     512         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 498, 128)     0           batch_normalization_7[0][0]      \n",
            "                                                                 max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 498, 128)     512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 498, 128)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 249, 512)     459264      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 249, 512)     2048        conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 249, 512)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 82, 512)      0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 41984)        0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          10748160    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5)            645         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 5)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,900,069\n",
            "Trainable params: 11,896,805\n",
            "Non-trainable params: 3,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51SxpfQofzM",
        "colab_type": "code",
        "outputId": "74aece8e-4d56-4ce5-9314-351e85e99a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(XF_train, y_train, epochs=15, batch_size=64, validation_data=(XF_test, y_test), callbacks=[es_callback])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "782/782 [==============================] - 5934s 8s/step - loss: 3.1084 - accuracy: 0.7136 - val_loss: 0.7300 - val_accuracy: 0.6957\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 5978s 8s/step - loss: 0.4272 - accuracy: 0.8733 - val_loss: 0.6119 - val_accuracy: 0.8069\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 6020s 8s/step - loss: 0.4522 - accuracy: 0.8929 - val_loss: 14.6895 - val_accuracy: 0.1214\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 6044s 8s/step - loss: 0.3284 - accuracy: 0.9075 - val_loss: 0.2063 - val_accuracy: 0.9330\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 6051s 8s/step - loss: 0.1602 - accuracy: 0.9474 - val_loss: 0.3217 - val_accuracy: 0.8963\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 6038s 8s/step - loss: 0.9948 - accuracy: 0.8650 - val_loss: 0.3261 - val_accuracy: 0.8775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f24d3c0d6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUPC94zqTiE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1db5eee5-aa5b-4b8e-c835-31440c378940"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(XF_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"/content/drive/My Drive/Cardio/HeartBeat.h5\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 87.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCecYVrhtbNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht3ltnGvtjlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}