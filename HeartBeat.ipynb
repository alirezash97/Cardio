{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNM9/0+ITl1nSmXJnYH5f9A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Cardio/blob/master/HeartBeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUFDobFVvj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"alirezashafaei97\",\"key\":\"9cb262aa0c5658ffc4eb45857c41903c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat -p /content\n",
        "!unzip /content/heartbeat.zip -d /content/heartbeat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sio7SWAwWBLj",
        "colab_type": "code",
        "outputId": "fc1dce2e-a22a-4e34-84e3-b174f8316cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, LeakyReLU, Softmax, InputLayer, concatenate, Conv1D, MaxPool1D, Add, MaxPooling1D\n",
        " , Flatten, Dropout, ReLU, BatchNormalization, GlobalAveragePooling1D)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from random import uniform \n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTudiQO8WEXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/heartbeat/mitbih_test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58wFx5vXQS7",
        "colab_type": "code",
        "outputId": "143ea508-266f-45fa-9016-20128058c949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "counter=train_df[187].value_counts()\n",
        "print(counter)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQqNZG2q59y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=10000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=10000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=10000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=10000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=10000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomIXpkCrozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBctv4Tr58D",
        "colab_type": "code",
        "outputId": "1da83d61-1da2-41b3-d033-78ba00cbbf73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    10000\n",
            "3    10000\n",
            "2    10000\n",
            "1    10000\n",
            "0    10000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3HJfHYr605",
        "colab_type": "code",
        "outputId": "4e524496-8353-45a4-991f-d2c5ad3218ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\n",
        "c"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24456</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.867470</td>\n",
              "      <td>0.510040</td>\n",
              "      <td>0.056225</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156627</td>\n",
              "      <td>0.168675</td>\n",
              "      <td>0.144578</td>\n",
              "      <td>0.108434</td>\n",
              "      <td>0.100402</td>\n",
              "      <td>0.108434</td>\n",
              "      <td>0.132530</td>\n",
              "      <td>0.112450</td>\n",
              "      <td>0.128514</td>\n",
              "      <td>0.120482</td>\n",
              "      <td>0.140562</td>\n",
              "      <td>0.120482</td>\n",
              "      <td>0.144578</td>\n",
              "      <td>0.132530</td>\n",
              "      <td>0.160643</td>\n",
              "      <td>0.140562</td>\n",
              "      <td>0.152610</td>\n",
              "      <td>0.172691</td>\n",
              "      <td>0.200803</td>\n",
              "      <td>0.200803</td>\n",
              "      <td>0.232932</td>\n",
              "      <td>0.240964</td>\n",
              "      <td>0.248996</td>\n",
              "      <td>0.257028</td>\n",
              "      <td>0.281125</td>\n",
              "      <td>0.273092</td>\n",
              "      <td>0.317269</td>\n",
              "      <td>0.317269</td>\n",
              "      <td>0.341365</td>\n",
              "      <td>0.313253</td>\n",
              "      <td>0.325301</td>\n",
              "      <td>0.289157</td>\n",
              "      <td>0.313253</td>\n",
              "      <td>0.277108</td>\n",
              "      <td>0.281125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74551</th>\n",
              "      <td>0.995516</td>\n",
              "      <td>0.977578</td>\n",
              "      <td>0.322870</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.089686</td>\n",
              "      <td>0.165919</td>\n",
              "      <td>0.147982</td>\n",
              "      <td>0.201794</td>\n",
              "      <td>0.264574</td>\n",
              "      <td>0.210762</td>\n",
              "      <td>0.183857</td>\n",
              "      <td>0.224215</td>\n",
              "      <td>0.345291</td>\n",
              "      <td>0.417040</td>\n",
              "      <td>0.385650</td>\n",
              "      <td>0.372197</td>\n",
              "      <td>0.390135</td>\n",
              "      <td>0.390135</td>\n",
              "      <td>0.390135</td>\n",
              "      <td>0.385650</td>\n",
              "      <td>0.408072</td>\n",
              "      <td>0.421525</td>\n",
              "      <td>0.403587</td>\n",
              "      <td>0.408072</td>\n",
              "      <td>0.426009</td>\n",
              "      <td>0.452915</td>\n",
              "      <td>0.439462</td>\n",
              "      <td>0.448430</td>\n",
              "      <td>0.506726</td>\n",
              "      <td>0.538117</td>\n",
              "      <td>0.542601</td>\n",
              "      <td>0.560538</td>\n",
              "      <td>0.614350</td>\n",
              "      <td>0.659193</td>\n",
              "      <td>0.645740</td>\n",
              "      <td>0.645740</td>\n",
              "      <td>0.636771</td>\n",
              "      <td>0.627803</td>\n",
              "      <td>0.560538</td>\n",
              "      <td>0.520179</td>\n",
              "      <td>...</td>\n",
              "      <td>0.403587</td>\n",
              "      <td>0.426009</td>\n",
              "      <td>0.394619</td>\n",
              "      <td>0.394619</td>\n",
              "      <td>0.41704</td>\n",
              "      <td>0.426009</td>\n",
              "      <td>0.412556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75403</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.788770</td>\n",
              "      <td>0.612299</td>\n",
              "      <td>0.433155</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.280749</td>\n",
              "      <td>0.334225</td>\n",
              "      <td>0.358289</td>\n",
              "      <td>0.312834</td>\n",
              "      <td>0.200535</td>\n",
              "      <td>0.098930</td>\n",
              "      <td>0.056150</td>\n",
              "      <td>0.021390</td>\n",
              "      <td>0.010695</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002674</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010695</td>\n",
              "      <td>0.016043</td>\n",
              "      <td>0.018717</td>\n",
              "      <td>0.037433</td>\n",
              "      <td>0.048128</td>\n",
              "      <td>0.061497</td>\n",
              "      <td>0.069519</td>\n",
              "      <td>0.085561</td>\n",
              "      <td>0.101604</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.141711</td>\n",
              "      <td>0.152406</td>\n",
              "      <td>0.179144</td>\n",
              "      <td>0.195187</td>\n",
              "      <td>0.224599</td>\n",
              "      <td>0.219251</td>\n",
              "      <td>0.237968</td>\n",
              "      <td>0.240642</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.240642</td>\n",
              "      <td>0.232620</td>\n",
              "      <td>0.221925</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80641</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.987952</td>\n",
              "      <td>0.566265</td>\n",
              "      <td>0.305221</td>\n",
              "      <td>0.198795</td>\n",
              "      <td>0.220884</td>\n",
              "      <td>0.182731</td>\n",
              "      <td>0.196787</td>\n",
              "      <td>0.182731</td>\n",
              "      <td>0.190763</td>\n",
              "      <td>0.176707</td>\n",
              "      <td>0.186747</td>\n",
              "      <td>0.178715</td>\n",
              "      <td>0.196787</td>\n",
              "      <td>0.190763</td>\n",
              "      <td>0.202811</td>\n",
              "      <td>0.192771</td>\n",
              "      <td>0.204819</td>\n",
              "      <td>0.206827</td>\n",
              "      <td>0.216867</td>\n",
              "      <td>0.224900</td>\n",
              "      <td>0.234940</td>\n",
              "      <td>0.230924</td>\n",
              "      <td>0.257028</td>\n",
              "      <td>0.269076</td>\n",
              "      <td>0.293173</td>\n",
              "      <td>0.299197</td>\n",
              "      <td>0.321285</td>\n",
              "      <td>0.315261</td>\n",
              "      <td>0.327309</td>\n",
              "      <td>0.307229</td>\n",
              "      <td>0.295181</td>\n",
              "      <td>0.257028</td>\n",
              "      <td>0.242972</td>\n",
              "      <td>0.212851</td>\n",
              "      <td>0.218875</td>\n",
              "      <td>0.202811</td>\n",
              "      <td>0.204819</td>\n",
              "      <td>0.190763</td>\n",
              "      <td>0.194779</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86910</th>\n",
              "      <td>0.681750</td>\n",
              "      <td>0.579186</td>\n",
              "      <td>0.457014</td>\n",
              "      <td>0.321267</td>\n",
              "      <td>0.174962</td>\n",
              "      <td>0.085973</td>\n",
              "      <td>0.012066</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018100</td>\n",
              "      <td>0.072398</td>\n",
              "      <td>0.188537</td>\n",
              "      <td>0.304676</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.398190</td>\n",
              "      <td>0.452489</td>\n",
              "      <td>0.521870</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.601810</td>\n",
              "      <td>0.619910</td>\n",
              "      <td>0.633484</td>\n",
              "      <td>0.630468</td>\n",
              "      <td>0.642534</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.660634</td>\n",
              "      <td>0.659125</td>\n",
              "      <td>0.672700</td>\n",
              "      <td>0.683258</td>\n",
              "      <td>0.701357</td>\n",
              "      <td>0.723982</td>\n",
              "      <td>0.746606</td>\n",
              "      <td>0.760181</td>\n",
              "      <td>0.779789</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.822021</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.883861</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3    ...  184  185  186  187\n",
              "24456  1.000000  0.867470  0.510040  0.056225  ...  0.0  0.0  0.0    0\n",
              "74551  0.995516  0.977578  0.322870  0.000000  ...  0.0  0.0  0.0    1\n",
              "75403  1.000000  0.941176  0.788770  0.612299  ...  0.0  0.0  0.0    2\n",
              "80641  1.000000  0.987952  0.566265  0.305221  ...  0.0  0.0  0.0    3\n",
              "86910  0.681750  0.579186  0.457014  0.321267  ...  0.0  0.0  0.0    4\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB80IzMo1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_gaussian_noise(signal):\n",
        "    noise=np.random.normal(0,0.05,186)\n",
        "    return (signal+noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJB5fWu5sWNc",
        "colab_type": "code",
        "outputId": "0bcd6ad1-e9ef-4c5d-9058-fc63f2f420c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tempo=c.iloc[0,:186]\n",
        "bruiter=add_gaussian_noise(tempo)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(c.iloc[0,:186])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(bruiter)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4fXuypr6vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUVlLpKPsQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values\n",
        "# X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
        "# X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexzfSPiD34D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fbe8c332-1111-4c10-9a05-af57bad95732"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 186)\n",
            "(21892, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzROJp1Fr6q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "import pywt\n",
        "\n",
        "XF_train = np.zeros((X_train.shape[0], 9000))\n",
        "XF_test = np.zeros((X_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_train):\n",
        "  XF_train[index, :] = pywt.pad(row, 4407, 'periodic')\n",
        "\n",
        "\n",
        "for index, row in enumerate(X_test):\n",
        "  XF_test[index, :] = pywt.pad(row, 4407, 'periodic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOzIlNPzr6kY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHbRK3GDr6bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0aEgkhXamJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = train_df.values\n",
        "# testset = test_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Yu65s0adg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def split(dataset, number_of_sample_per_category):\n",
        "  \n",
        "#   new_dataset = np.zeros((np.sum(number_of_sample_per_category), dataset.shape[1]))\n",
        "#   pointer = 0\n",
        "  \n",
        "#   for row in dataset :\n",
        "    \n",
        "#     row_label = int(row[-1])\n",
        "    \n",
        "#     if number_of_sample_per_category[row_label] > 0 :\n",
        "      \n",
        "#       number_of_sample_per_category[row_label] -= 1\n",
        "#       new_dataset[pointer , :] = row\n",
        "#       pointer += 1\n",
        "\n",
        "#     else:\n",
        "\n",
        "#       pass\n",
        "    \n",
        "  \n",
        "#   return new_dataset\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTg8U_rCecMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# temp_trainset = split(trainset, [5500, 2223, 5500, 641, 5500])\n",
        "# temp_testset = split(testset, [500, 500, 500, 500, 500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VixGjo-J1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented = 0\n",
        "# def data_augmentation(dataset, chance):\n",
        "  \n",
        "#   augmented = 0\n",
        "#   number_of_rows = int(dataset.shape[0] + (dataset.shape[0] * (chance*2)))\n",
        "#   new_dataset = np.zeros((number_of_rows, dataset.shape[1]))\n",
        "#   pointer = 0 \n",
        "\n",
        "#   for row in dataset:\n",
        "    \n",
        "#     rand_num = random.uniform(0, 1)\n",
        "#     if rand_num < chance:\n",
        "      \n",
        "#       augmented += 1\n",
        "#       noise = np.random.normal(scale=0.01, size=187)\n",
        "#       new_signal = np.zeros((1, 188))\n",
        "#       new_signal[:, :187] = row[:187] + noise\n",
        "#       new_signal[:, -1:] = row[-1:] \n",
        "#       new_dataset[pointer:pointer+1, :] = new_signal\n",
        "#       pointer += 1\n",
        "\n",
        "#     else :\n",
        "#       pass\n",
        "\n",
        "#     new_dataset[pointer, :] = row \n",
        "#     pointer += 1\n",
        "\n",
        "#   return augmented, new_dataset  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-WNJJaSNYR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augmented, trainset = data_augmentation(temp_trainset, 0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEkQ1k_zRnYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filled = augmented + temp_trainset.shape[0]\n",
        "# trainset = trainset[:filled , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULVB16ONXuex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = np.take(trainset,np.random.permutation(trainset.shape[0]),axis=0,out=trainset)\n",
        "# testset = np.take(temp_testset,np.random.permutation(temp_testset.shape[0]),axis=0,out=temp_testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXpOUPpHYPQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_temp_train = trainset[:, :-1]\n",
        "# Y_train = trainset[:, -1:]\n",
        "# X_temp_test = testset[:, :-1]\n",
        "# Y_test = testset[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wSnYvXY6AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", XF_train.shape)\n",
        "# print(\"Y_train : \", y_train.shape)\n",
        "# print(\"X_test : \", XF_test.shape)\n",
        "# print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQP8dTlBZw6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# One Hot enoding for target labels \n",
        "# ohe = OneHotEncoder()\n",
        "# Y_train = ohe.fit_transform(Y_train.reshape(-1,1))\n",
        "# Y_test = ohe.transform(Y_test.reshape(-1,1))\n",
        "\n",
        "# # handle sparse matrix for keras \n",
        "# Y_train = csr_matrix.toarray(Y_train)\n",
        "# Y_test = csr_matrix.toarray(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBhFohZUarKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_train : \", X_temp_train.shape)\n",
        "# print(\"Y_train : \", Y_train.shape)\n",
        "# print(\"X_test : \", X_temp_test.shape)\n",
        "# print(\"Y_test : \", Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E525NqY3aGSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# periodic signal extend \n",
        "\n",
        "# import pywt\n",
        "\n",
        "# XF_train = np.zeros((X_temp_train.shape[0], 9000))\n",
        "# XF_test = np.zeros((X_temp_test.shape[0], 9000))\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_train):\n",
        "#   XF_train[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_train[index, -1:] = 0\n",
        "\n",
        "\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   XF_test[index, :-1] = pywt.pad(row, 4406, 'symmetric')\n",
        "#   XF_test[index, -1:] = 0\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCEcchWo3cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index, row in enumerate(X_temp_train):\n",
        "#   X_temp_train[index] = add_gaussian_noise(row)\n",
        "# for index, row in enumerate(X_temp_test):\n",
        "#   X_temp_test[index] = add_gaussian_noise(row)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmANeCYtjmgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XF_train = XF_train.reshape((50000, 9000, 1))\n",
        "XF_test = XF_test.reshape((21892, 9000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNvkTDCjyoA",
        "colab_type": "code",
        "outputId": "3c6f342d-6089-4544-fa0b-536230a41440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train : \", XF_train.shape)\n",
        "print(\"Y_train : \", y_train.shape)\n",
        "print(\"X_test : \", XF_test.shape)\n",
        "print(\"Y_test : \", y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train :  (50000, 9000, 1)\n",
            "Y_train :  (50000, 5)\n",
            "X_test :  (21892, 9000, 1)\n",
            "Y_test :  (21892, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvIW2sWkaoP",
        "colab_type": "code",
        "outputId": "330395bb-3f11-4303-df90-3f2be4fc84e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_input = Input(shape=(9000, 1))\n",
        "Conv = Conv1D(filters=16, kernel_size=5, strides=2)(X_input)\n",
        "\n",
        "\n",
        "### step 1 \n",
        "\n",
        "Conv1_1 = Conv1D(filters=32, kernel_size=9, strides=1, padding='same')(Conv)\n",
        "Bn1_1 = BatchNormalization()(Conv1_1)\n",
        "Act1_1 = LeakyReLU()(Bn1_1)\n",
        "Conv1_2 = Conv1D(filters=32, kernel_size=7, strides=1, padding='same')(Act1_1)\n",
        "Bn1_2 = BatchNormalization()(Conv1_2)\n",
        "Act1_2 = LeakyReLU()(Bn1_2)\n",
        "DO1_1 = Dropout(0.2)(Act1_2)\n",
        "Conv1_3 = Conv1D(filters=16, kernel_size=9, strides=1, padding='same')(DO1_1)\n",
        "Bn1_3 = BatchNormalization()(Conv1_3)\n",
        "shortcut1_1 = Add()([Bn1_3, Conv])\n",
        "Bn1_4 = BatchNormalization()(shortcut1_1)\n",
        "Act1_3 = LeakyReLU()(Bn1_4)\n",
        "##### auxiliary\n",
        "Conv1_4 = Conv1D(filters=32, kernel_size=7, strides=1, padding='same')(Act1_3)\n",
        "Bn1_4 = BatchNormalization()(Conv1_4)\n",
        "Act1_4 = LeakyReLU()(Bn1_4)\n",
        "###############\n",
        "Max1_1 = MaxPooling1D(pool_size=5, strides=2)(Act1_4)\n",
        "\n",
        "\n",
        "## step 2\n",
        "\n",
        "Conv2_1 = Conv1D(filters=16, kernel_size=3, strides=1, padding='same')(Max1_1)\n",
        "Bn2_1 = BatchNormalization()(Conv2_1)\n",
        "Act2_1 = LeakyReLU()(Bn2_1)\n",
        "Conv2_2 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(Act2_1)\n",
        "Bn2_2 = BatchNormalization()(Conv2_2)\n",
        "Act2_2 = LeakyReLU()(Bn2_2)\n",
        "DO2_1 = Dropout(0.2)(Act2_2)\n",
        "Conv2_3 = Conv1D(filters=32, kernel_size=3, strides=1, padding='same')(DO2_1)\n",
        "Bn2_3 = BatchNormalization()(Conv2_3)\n",
        "shortcut2_1 = Add()([Bn2_3, Max1_1])\n",
        "Bn2_4 = BatchNormalization()(shortcut2_1)\n",
        "Act2_3 = LeakyReLU()(Bn2_4)\n",
        "##### auxiliary\n",
        "Conv2_4 = Conv1D(filters=64, kernel_size=7, strides=1, padding='same')(Act2_3)\n",
        "Bn2_4 = BatchNormalization()(Conv2_4)\n",
        "Act2_4 = LeakyReLU()(Bn2_4)\n",
        "###############\n",
        "Max2_1 = MaxPooling1D(pool_size=5, strides=3)(Act2_4)\n",
        "\n",
        "\n",
        "## step 3\n",
        "\n",
        "Conv3_1 = Conv1D(filters=32, kernel_size=16, strides=1, padding='same')(Max2_1)\n",
        "Bn3_1 = BatchNormalization()(Conv3_1)\n",
        "Act3_1 = LeakyReLU()(Bn3_1)\n",
        "Conv3_2 = Conv1D(filters=64, kernel_size=32, strides=1, padding='same')(Act3_1)\n",
        "Bn3_2 = BatchNormalization()(Conv3_2)\n",
        "Act3_2 = LeakyReLU()(Bn3_2)\n",
        "Conv3_3 = Conv1D(filters=64, kernel_size=16, strides=1, padding='same')(Act3_2)\n",
        "Bn3_3 = BatchNormalization()(Conv3_3)\n",
        "shortcut3_1 = Add()([Bn3_3, Max2_1])\n",
        "Bn3_4 = BatchNormalization()(shortcut3_1)\n",
        "Act3_3 = LeakyReLU()(Bn3_4)\n",
        "##### auxiliary\n",
        "Conv3_4 = Conv1D(filters=128, kernel_size=7, strides=1, padding='same')(Act3_3)\n",
        "Bn3_4 = BatchNormalization()(Conv3_4)\n",
        "Act3_4 = LeakyReLU()(Bn3_4)\n",
        "###############\n",
        "Max3_1 = MaxPooling1D(pool_size=5, strides=2)(Act3_4)\n",
        "\n",
        "\n",
        "## step 4\n",
        "\n",
        "Conv4_1 = Conv1D(filters=64, kernel_size=64, strides=1, padding='same')(Max3_1)\n",
        "Bn4_1 = BatchNormalization()(Conv4_1)\n",
        "Act4_1 = LeakyReLU()(Bn4_1)\n",
        "Conv4_2 = Conv1D(filters=64, kernel_size=128, strides=1, padding='same')(Act4_1)\n",
        "Bn4_2 = BatchNormalization()(Conv4_2)\n",
        "Act4_2 = LeakyReLU()(Bn4_2)\n",
        "DO4_1 = Dropout(0.2)(Act4_2)\n",
        "Conv4_3 = Conv1D(filters=128, kernel_size=64, strides=1, padding='same')(DO4_1)\n",
        "Bn4_3 = BatchNormalization()(Conv4_3)\n",
        "shortcut4_1 = Add()([Bn4_3, Max3_1])\n",
        "Bn4_4 = BatchNormalization()(shortcut4_1)\n",
        "Act4_3 = LeakyReLU()(Bn4_4)\n",
        "##### auxiliary\n",
        "Conv4_4 = Conv1D(filters=256, kernel_size=7, strides=1, padding='same')(Act4_3)\n",
        "Bn4_4 = BatchNormalization()(Conv4_4)\n",
        "Act4_4 = LeakyReLU()(Bn4_4)\n",
        "###############\n",
        "Max4_1 = MaxPooling1D(pool_size=5, strides=3)(Act4_4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Flat1 = Flatten()(Max4_1)\n",
        "\n",
        "D1 = Dense(256)(Flat1)\n",
        "A6 = LeakyReLU()(D1)\n",
        "D_O = Dropout(0.15)(A6)\n",
        "D2 = Dense(128)(D_O)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=A7)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 4498, 16)     96          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 4498, 32)     4640        conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 4498, 32)     128         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 4498, 32)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 4498, 32)     7200        leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 4498, 32)     128         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 4498, 32)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 4498, 32)     0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 4498, 16)     4624        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 4498, 16)     64          conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 4498, 16)     0           batch_normalization_2[0][0]      \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 4498, 16)     64          add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 4498, 16)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 4498, 32)     3616        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 4498, 32)     128         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 4498, 32)     0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 2247, 32)     0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 2247, 16)     1552        max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 2247, 16)     64          conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 2247, 16)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 2247, 32)     2592        leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 2247, 32)     128         conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 2247, 32)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2247, 32)     0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 2247, 32)     3104        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 2247, 32)     128         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 2247, 32)     0           batch_normalization_7[0][0]      \n",
            "                                                                 max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 2247, 32)     128         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 2247, 32)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 2247, 64)     14400       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 2247, 64)     256         conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 2247, 64)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 748, 64)      0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 748, 32)      32800       max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 748, 32)      128         conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 748, 32)      0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 748, 64)      65600       leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 748, 64)      256         conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 748, 64)      0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 748, 64)      65600       leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 748, 64)      256         conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 748, 64)      0           batch_normalization_12[0][0]     \n",
            "                                                                 max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 748, 64)      256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 748, 64)      0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 748, 128)     57472       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 748, 128)     512         conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 748, 128)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 372, 128)     0           leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 372, 64)      524352      max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 372, 64)      256         conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 372, 64)      0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 372, 64)      524352      leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 372, 64)      256         conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 372, 64)      0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 372, 64)      0           leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 372, 128)     524416      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 372, 128)     512         conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 372, 128)     0           batch_normalization_17[0][0]     \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 372, 128)     512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 372, 128)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 372, 256)     229632      leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 372, 256)     1024        conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 372, 256)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 123, 256)     0           leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 31488)        0           max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          8061184     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 256)          0           leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5)            645         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 5)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 10,165,957\n",
            "Trainable params: 10,163,365\n",
            "Non-trainable params: 2,592\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51SxpfQofzM",
        "colab_type": "code",
        "outputId": "93510e61-9e6b-4531-f2e5-ceed870dd511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(XF_train, y_train, epochs=20, batch_size=128, validation_data=(XF_test, y_test), callbacks=[es_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 10146s 26s/step - loss: 2.3714 - accuracy: 0.6482 - val_loss: 2.8535 - val_accuracy: 0.0328\n",
            "Epoch 2/20\n",
            "374/391 [===========================>..] - ETA: 6:43 - loss: 0.6098 - accuracy: 0.8023"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUPC94zqTiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}